<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"enpsl.github.io",root:"/",scheme:"Muse",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!1,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="my blog"><meta property="og:type" content="website"><meta property="og:title" content="彭诗亮的博客"><meta property="og:url" content="https://enpsl.github.io/page/4/index.html"><meta property="og:site_name" content="彭诗亮的博客"><meta property="og:description" content="my blog"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="enpsl"><meta property="article:tag" content="彭诗亮 psl pengshiliang blog"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://enpsl.github.io/page/4/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!0,isPost:!1,lang:"zh-CN"}</script><title>彭诗亮的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">彭诗亮的博客</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li></ul></nav></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content index posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2021/03/02/2021-03-02-vagrant/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2021/03/02/2021-03-02-vagrant/" class="post-title-link" itemprop="url">Vagrant基本命令</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-03-02 21:30:00" itemprop="dateCreated datePublished" datetime="2021-03-02T21:30:00+08:00">2021-03-02</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="vagrant-使用"><a href="#vagrant-使用" class="headerlink" title="vagrant 使用"></a>vagrant 使用</h2><h2 id="init-centos"><a href="#init-centos" class="headerlink" title="init centos"></a>init centos</h2><p>centos7 box 下载地址<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1kVlAz59">centos7</a></p><p><strong>添加vagrant box到box list</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box add centos7 Vagrant-CentOS-7.box</span><br></pre></td></tr></table></figure><p><strong>初始化一个虚拟机使用刚才添加的vagrant box</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> centos</span><br><span class="line"><span class="built_in">cd</span> centos</span><br><span class="line">vim Vagrantfile</span><br></pre></td></tr></table></figure><p><strong>添加下面内容到Vagrantfile中</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- mode: ruby -*-</span></span><br><span class="line"><span class="comment"># vi: set ft=ruby :</span></span><br><span class="line"></span><br><span class="line">Vagrant.require_version <span class="string">&quot;&gt;= 1.6.0&quot;</span></span><br><span class="line"></span><br><span class="line">boxes = [</span><br><span class="line">    &#123;</span><br><span class="line">        :name =&gt; <span class="string">&quot;docker-node1&quot;</span>,</span><br><span class="line">        :eth1 =&gt; <span class="string">&quot;192.168.205.10&quot;</span>,</span><br><span class="line">        :mem =&gt; <span class="string">&quot;1024&quot;</span>,</span><br><span class="line">        :cpu =&gt; <span class="string">&quot;1&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        :name =&gt; <span class="string">&quot;docker-node2&quot;</span>,</span><br><span class="line">        :eth1 =&gt; <span class="string">&quot;192.168.205.11&quot;</span>,</span><br><span class="line">        :mem =&gt; <span class="string">&quot;1024&quot;</span>,</span><br><span class="line">        :cpu =&gt; <span class="string">&quot;1&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">Vagrant.configure(2) <span class="keyword">do</span> |config|</span><br><span class="line"></span><br><span class="line">  config.vm.box = <span class="string">&quot;centos7&quot;</span></span><br><span class="line"></span><br><span class="line">  boxes.each <span class="keyword">do</span> |opts|</span><br><span class="line">      config.vm.define opts[:name] <span class="keyword">do</span> |config|</span><br><span class="line">        config.vm.hostname = opts[:name]</span><br><span class="line">        config.vm.provider <span class="string">&quot;vmware_fusion&quot;</span> <span class="keyword">do</span> |v|</span><br><span class="line">          v.vmx[<span class="string">&quot;memsize&quot;</span>] = opts[:mem]</span><br><span class="line">          v.vmx[<span class="string">&quot;numvcpus&quot;</span>] = opts[:cpu]</span><br><span class="line">        end</span><br><span class="line"></span><br><span class="line">        config.vm.provider <span class="string">&quot;virtualbox&quot;</span> <span class="keyword">do</span> |v|</span><br><span class="line">          v.customize [<span class="string">&quot;modifyvm&quot;</span>, :<span class="built_in">id</span>, <span class="string">&quot;--memory&quot;</span>, opts[:mem]]</span><br><span class="line">          v.customize [<span class="string">&quot;modifyvm&quot;</span>, :<span class="built_in">id</span>, <span class="string">&quot;--cpus&quot;</span>, opts[:cpu]]</span><br><span class="line">        end</span><br><span class="line"></span><br><span class="line">        config.vm.network :private_network, ip: opts[:eth1]</span><br><span class="line">      end</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.provision <span class="string">&quot;shell&quot;</span>, privileged: <span class="literal">true</span>, path: <span class="string">&quot;./setup.sh&quot;</span></span><br><span class="line"></span><br><span class="line">end</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>install docker的setup.sh文件</strong></p><p>在当前目录创建setup.sh文件并添加如下内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># install some tools</span></span><br><span class="line">sudo yum install -y git vim gcc glibc-static telnet bridge-utils</span><br><span class="line"></span><br><span class="line"><span class="comment"># install docker</span></span><br><span class="line">curl -fsSL get.docker.com -o get-docker.sh</span><br><span class="line">sh get-docker.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># start docker service</span></span><br><span class="line">sudo groupadd docker</span><br><span class="line">sudo usermod -aG docker vagrant</span><br><span class="line">sudo systemctl start docker</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> -rf get-docker.sh</span><br></pre></td></tr></table></figure><p><strong>启动安装</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant up</span><br></pre></td></tr></table></figure><h2 id="vagrant-报unknown-filesystem-type-‘vboxsf’-解决方案"><a href="#vagrant-报unknown-filesystem-type-‘vboxsf’-解决方案" class="headerlink" title="vagrant 报unknown filesystem type ‘vboxsf’ 解决方案"></a>vagrant 报unknown filesystem type ‘vboxsf’ 解决方案</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vagrant plugin install vagrant-vbguest</span><br><span class="line">vagrant destroy &amp;&amp; vagrant up</span><br></pre></td></tr></table></figure><h2 id="init-ubuntu"><a href="#init-ubuntu" class="headerlink" title="init ubuntu"></a>init ubuntu</h2><p>使用<a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/bionic/current/">清华源</a></p><p><strong>ubuntu18的box，终端运行如下命令</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vagrant box add \</span><br><span class="line">https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/bionic/current/bionic-server-cloudimg-amd64-vagrant.box \</span><br><span class="line">--name ubuntu/bionic</span><br></pre></td></tr></table></figure><p>Vagrantfile这样写：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">config.vm.box = <span class="string">&quot;ubuntu/bionic&quot;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>接着就是<code>vagrant up &amp;&amp; vagrant ssh</code>了</p><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><h3 id="列出所有Box"><a href="#列出所有Box" class="headerlink" title="列出所有Box"></a>列出所有Box</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box list</span><br></pre></td></tr></table></figure><h3 id="添加一个Box"><a href="#添加一个Box" class="headerlink" title="添加一个Box"></a>添加一个Box</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box add [options] &lt;name, url, or path</span><br></pre></td></tr></table></figure><h3 id="可以从https-app-vagrantup-com-boxes-search下载各种Vagrant映像文件"><a href="#可以从https-app-vagrantup-com-boxes-search下载各种Vagrant映像文件" class="headerlink" title="可以从https://app.vagrantup.com/boxes/search下载各种Vagrant映像文件"></a>可以从<a target="_blank" rel="noopener" href="https://app.vagrantup.com/boxes/search%E4%B8%8B%E8%BD%BD%E5%90%84%E7%A7%8DVagrant%E6%98%A0%E5%83%8F%E6%96%87%E4%BB%B6">https://app.vagrantup.com/boxes/search下载各种Vagrant映像文件</a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box add ubuntu/trusty64</span><br></pre></td></tr></table></figure><h3 id="通过指定的URL添加远程box"><a href="#通过指定的URL添加远程box" class="headerlink" title="通过指定的URL添加远程box"></a>通过指定的URL添加远程box</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box add https://atlas.hashicorp.com/ubuntu/boxes/trusty64</span><br></pre></td></tr></table></figure><h3 id="添加一个本地box"><a href="#添加一个本地box" class="headerlink" title="添加一个本地box"></a>添加一个本地box</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box add &#123;box_name&#125; &#123;file_path&#125;</span><br></pre></td></tr></table></figure><h3 id="初始化一个新VM"><a href="#初始化一个新VM" class="headerlink" title="初始化一个新VM"></a>初始化一个新VM</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant init ubuntu/trustry64</span><br></pre></td></tr></table></figure><p>此命令会在当前目录创建一个名为Vagrantfile的配置文件，内容大致如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Vagrant.configure(<span class="string">&quot;2&quot;</span>) <span class="keyword">do</span> |config|</span><br><span class="line">  config.vm.box = <span class="string">&quot;ubuntu/trusty64&quot;</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure><h3 id="初始化一个新VM-1"><a href="#初始化一个新VM-1" class="headerlink" title="初始化一个新VM"></a>初始化一个新VM</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant up</span><br></pre></td></tr></table></figure><h3 id="启用SSH登陆VM"><a href="#启用SSH登陆VM" class="headerlink" title="启用SSH登陆VM"></a>启用SSH登陆VM</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant ssh &lt;node_name&gt;</span><br></pre></td></tr></table></figure><p>如果需要从虚拟机中退出，直接在虚拟机中的命令行输入exit命令即可</p><h3 id="查看VM当前的状态"><a href="#查看VM当前的状态" class="headerlink" title="查看VM当前的状态"></a>查看VM当前的状态</h3><p>进入Vagrantfile配置文件所在的目录，执行以下命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant status</span><br></pre></td></tr></table></figure><h3 id="关闭VM"><a href="#关闭VM" class="headerlink" title="关闭VM"></a>关闭VM</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant halt</span><br></pre></td></tr></table></figure><h3 id="销毁VM"><a href="#销毁VM" class="headerlink" title="销毁VM"></a>销毁VM</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant destory [name|<span class="built_in">id</span>]</span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2021/03/02/2021-03-02-dockerfile/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2021/03/02/2021-03-02-dockerfile/" class="post-title-link" itemprop="url">Dockerfile 语法梳理</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-03-02 13:30:00" itemprop="dateCreated datePublished" datetime="2021-03-02T13:30:00+08:00">2021-03-02</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="Dockerfile语法梳理"><a href="#Dockerfile语法梳理" class="headerlink" title="Dockerfile语法梳理"></a>Dockerfile语法梳理</h2><h3 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h3><p>from 后面接base image</p><p>eg:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">FROM</span> centos</span><br><span class="line"><span class="keyword">FROM</span> ubuntu</span><br></pre></td></tr></table></figure><blockquote><p>尽量使用官方的image 作为base image</p></blockquote><h3 id="LABEL"><a href="#LABEL" class="headerlink" title="LABEL"></a>LABEL</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LABEL</span><span class="language-bash"> maintainer=<span class="string">&quot;username@gmail.com&quot;</span> </span></span><br><span class="line"><span class="keyword">LABEL</span><span class="language-bash"> version=<span class="string">&quot;1.0&quot;</span> </span></span><br><span class="line"><span class="keyword">LABEL</span><span class="language-bash"> description=<span class="string">&quot;this is description&quot;</span> </span></span><br></pre></td></tr></table></figure><blockquote><p>MetaData 不可少</p></blockquote><h3 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h3><p>执行命令并创建新的IMAGE LAYER</p><p>为了美观，复杂的RUN用反斜杠换行，避免无用分层，合并多条命令成一行。</p><h4 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h4><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="language-bash"> yum update &amp;&amp; yum install -y vim \</span></span><br><span class="line"><span class="language-bash">python-dev</span></span><br></pre></td></tr></table></figure><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; apt-get install -y perl \</span></span><br><span class="line"><span class="language-bash">pwgen --no-install-recommends &amp;&amp; <span class="built_in">rm</span> -rf \</span></span><br><span class="line"><span class="language-bash">/var/lib/apt/lists/*     <span class="comment">#清理cache</span></span></span><br></pre></td></tr></table></figure><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="language-bash"> /bin/bash -c <span class="string">&#x27;source $HOME/.bashrc;echo #HOME&#x27;</span></span></span><br></pre></td></tr></table></figure><h3 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> <span class="built_in">test</span>       <span class="comment"># 如果没有会自动创建test文件夹</span></span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> demo</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">pwd</span>            <span class="comment"># 打印/test/demo</span></span></span><br></pre></td></tr></table></figure><blockquote><p>尽量使用WORKDIR,不要使用RUN cd,尽量使用绝对路径</p></blockquote><h3 id="ADD-and-COPY"><a href="#ADD-and-COPY" class="headerlink" title="ADD and COPY"></a>ADD and COPY</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ADD</span><span class="language-bash"> hello /</span></span><br><span class="line"><span class="keyword">ADD</span><span class="language-bash"> test.tar.gz / <span class="comment"># 添加到根目录并解压缩</span></span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /root</span></span><br><span class="line"><span class="keyword">ADD</span><span class="language-bash"> hello <span class="built_in">test</span> /    <span class="comment"># /root/test/hello</span></span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /root</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> hello <span class="built_in">test</span> /</span></span><br></pre></td></tr></table></figure><blockquote><p>大部分情况COPY优于，ADD有额外的解压功能，添加远程文件或目录用curl或wget</p></blockquote><h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ENV</span> MYSQL_VERSION <span class="number">5.6</span> <span class="comment">#常量</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get install -y mysql-server= <span class="string">&quot;<span class="variable">$&#123;MYSQL_VERSION&#125;</span>&quot;</span> \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; <span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span></span><br></pre></td></tr></table></figure><h3 id="CMD-amp-ENTRYPOINT"><a href="#CMD-amp-ENTRYPOINT" class="headerlink" title="CMD &amp; ENTRYPOINT"></a>CMD &amp; ENTRYPOINT</h3><p>CMD:设置容器启动后默认执行的命令和参数<br>如果docker run指定了其它的命令，则忽略CMD命令<br>定义多个CMD,只有最后一个会执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run &lt;image&gt;</span><br><span class="line">docker run -it &lt;image&gt; /bin/bash    //此命令会忽略CMD中的命令</span><br></pre></td></tr></table></figure><p>ENTRYPOINT:设置容器启动时运行的命令<br>让容器已应用程序或者服务的方式执行<br>不会被忽略，一定会执行</p><h4 id="SHELL-amp-EXEC"><a href="#SHELL-amp-EXEC" class="headerlink" title="SHELL &amp; EXEC"></a>SHELL &amp; EXEC</h4><p>SHELL:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get install -y vim</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> <span class="built_in">echo</span> <span class="string">&quot;hello docker&quot;</span></span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> <span class="built_in">echo</span> <span class="string">&quot;hello docker&quot;</span></span></span><br></pre></td></tr></table></figure><p>EXEC:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="language-bash"> [<span class="string">&quot;apt-get&quot;</span>, <span class="string">&quot;install&quot;</span>, <span class="string">&quot;y&quot;</span>, <span class="string">&quot;vim&quot;</span>]</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;/bin/echo&quot;</span>, <span class="string">&quot;hello docker&quot;</span>]</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="string">&quot;/bin/echo&quot;</span>, <span class="string">&quot;hello docker&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>EXEC方式需要指明运行环境，eg:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos</span><br><span class="line"><span class="keyword">ENV</span> name word</span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="string">&quot;/bin/bash&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;echo hello <span class="variable">$name</span>&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>更多详见<a target="_blank" rel="noopener" href="https://docs.docker.com/engine/reference/builder/">扩展阅读</a></p><h2 id="Dockerfile实战"><a href="#Dockerfile实战" class="headerlink" title="Dockerfile实战"></a>Dockerfile实战</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> flask-hello-word</span><br><span class="line"><span class="built_in">cd</span> flask-hello-word</span><br><span class="line">vim app.py</span><br></pre></td></tr></table></figure><p>app.py内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line">app = Flask(__name__)</span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hello</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;hello docker&quot;</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run(host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">5000</span>)</span><br></pre></td></tr></table></figure><p>编写Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> python:<span class="number">2.7</span></span><br><span class="line"><span class="keyword">LABEL</span><span class="language-bash"> maintainer=<span class="string">&quot;peng.shiliang&lt;1390509500@qq.com&gt;&quot;</span></span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install flask</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> app.py /app/       <span class="comment"># app后面必须接/，否则会当作文件</span></span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /app</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">5000</span>             <span class="comment"># 端口映射,保证远程能够访问</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;python&quot;</span>, <span class="string">&quot;app.py&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker build -t pengshiliang/flask-hello-word .</span><br><span class="line">docker push pengshiliang/flask-hello-word:latest</span><br></pre></td></tr></table></figure><p>运行flask-hello-word</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name=demo pengshiliang/flask-hello-word     //--name 便于docker container 操作</span><br><span class="line">docker <span class="built_in">exec</span> -it demo ip a       //查看docker容器ip</span><br><span class="line">curl &lt;demo ip&gt;      //输出hello docker</span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2021/03/02/2021-03-02-docker/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2021/03/02/2021-03-02-docker/" class="post-title-link" itemprop="url">Docker入门</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-03-02 10:30:00" itemprop="dateCreated datePublished" datetime="2021-03-02T10:30:00+08:00">2021-03-02</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="赋予docker权限"><a href="#赋予docker权限" class="headerlink" title="赋予docker权限"></a>赋予docker权限</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vagrant@ubuntu-bionic:~$ sudo groupadd docker</span><br><span class="line">groupadd: group <span class="string">&#x27;docker&#x27;</span> already exists</span><br><span class="line">vagrant@ubuntu-bionic:~$ sudo gpasswd -a vagrant docker</span><br><span class="line">Adding user vagrant to group docker</span><br><span class="line">vagrant@ubuntu-bionic:~$ sudo service docker restart</span><br></pre></td></tr></table></figure><p>退出vagrant在重新进入</p><h2 id="docker基本命令"><a href="#docker基本命令" class="headerlink" title="docker基本命令"></a>docker基本命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// 列举所有镜像</span><br><span class="line">docker image <span class="built_in">ls</span></span><br><span class="line">// 查看image build 历史</span><br><span class="line">docker <span class="built_in">history</span> &lt;image <span class="built_in">id</span>&gt;</span><br><span class="line">// 运行一个image</span><br><span class="line">docker run &lt;image <span class="built_in">id</span>&gt;</span><br><span class="line">// 列举所有正在运行的容器</span><br><span class="line">docker container <span class="built_in">ls</span></span><br><span class="line">// 列举所有的容器</span><br><span class="line">docker container <span class="built_in">ls</span> -a</span><br><span class="line">// 交互式运行运行（常驻运行）</span><br><span class="line">docker run -it &lt;image&gt;</span><br></pre></td></tr></table></figure><h2 id="docker-image-命令"><a href="#docker-image-命令" class="headerlink" title="docker image 命令"></a>docker image 命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker images   (docker image <span class="built_in">ls</span>缩写)</span><br><span class="line">docker rmi &lt;image <span class="built_in">id</span>&gt;   (docker image <span class="built_in">rm</span> &lt;image <span class="built_in">id</span>&gt;缩写)//移除一个镜像</span><br></pre></td></tr></table></figure><h2 id="docker-container命令"><a href="#docker-container命令" class="headerlink" title="docker container命令"></a>docker container命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker ps -a    (docker container <span class="built_in">ls</span> -a缩写)</span><br><span class="line">docker <span class="built_in">rm</span> &lt;image <span class="built_in">id</span>&gt;    (docker container <span class="built_in">rm</span> &lt;image <span class="built_in">id</span>&gt;缩写)  //删除一个容器</span><br><span class="line">docker ps -aq   //列举所有容器<span class="built_in">id</span></span><br><span class="line">docker ps -f <span class="string">&quot;status=exited&quot;</span> -q     //列举所有已退出的容器</span><br><span class="line">docker <span class="built_in">rm</span> $(docker ps -aq)</span><br><span class="line">docker <span class="built_in">rm</span> $(docker ps -f <span class="string">&quot;status=exited&quot;</span> -q)</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-03-02/3.png" alt="avatar"><br><img src="/img/in-post/2019-03-02/4.png" alt="avatar"></p><h2 id="build一个hello-word-image"><a href="#build一个hello-word-image" class="headerlink" title="build一个hello word image"></a>build一个hello word image</h2><h3 id="生成hello-word程序"><a href="#生成hello-word程序" class="headerlink" title="生成hello-word程序"></a>生成hello-word程序</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> hello-word</span><br><span class="line"><span class="built_in">cd</span> hello-word</span><br><span class="line">vim hello.c</span><br></pre></td></tr></table></figure><p>hello.c内容</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;hello word\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install gcc</span><br><span class="line">sudo apt-get install build-essential</span><br><span class="line">gcc -static hello.c -o hello</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-03-02/1.png" alt="avatar"></p><h3 id="编写Dockerfile"><a href="#编写Dockerfile" class="headerlink" title="编写Dockerfile"></a>编写Dockerfile</h3><p>执行<code>vim Dockerfile</code></p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">ADD</span><span class="language-bash"> hello /</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;/hello&quot;</span>]</span></span><br></pre></td></tr></table></figure><h3 id="build命令"><a href="#build命令" class="headerlink" title="build命令"></a>build命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t &lt;tag&gt; &lt;<span class="built_in">dir</span>&gt;</span><br></pre></td></tr></table></figure><p>eg:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t pengshiliang/hello-word .</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-03-02/2.png" alt="avatar"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run pengshiliang/hello-word</span><br></pre></td></tr></table></figure><p>出现hello word 即为正常build</p><h2 id="发布"><a href="#发布" class="headerlink" title="发布"></a>发布</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push pengshiliang/hello-word:latest</span><br></pre></td></tr></table></figure><h2 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h2><ol><li>通过image创建</li><li>在Image layer之上建立一个Cotainer layer</li><li>类面向对象：类和实例</li><li>image复制存储和分发，container负责运行app</li></ol></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2021/02/17/2021-02-17-CAP&BASE/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2021/02/17/2021-02-17-CAP&BASE/" class="post-title-link" itemprop="url">CAP&BASE理论</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-02-17 19:30:00" itemprop="dateCreated datePublished" datetime="2021-02-17T19:30:00+08:00">2021-02-17</time></span></div></header><div class="post-body" itemprop="articleBody"><p>经历过技术面试的小伙伴想必对 CAP &amp; BASE 这个两个理论已经再熟悉不过了！</p><p>我当年参加面试的时候，不夸张地说，只要问到分布式相关的内容，面试官几乎是必定会问这两个分布式相关的理论。一是因为这两个分布式基础理论是学习分布式知识的必备前置基础，二是因为很多面试官自己比较熟悉这两个理论（方便提问）。</p><p>我们非常有必要将这两个理论搞懂，并且能够用自己的理解给别人讲出来。</p><h2 id="CAP-理论"><a href="#CAP-理论" class="headerlink" title="# CAP 理论"></a><a href="#cap-%E7%90%86%E8%AE%BA">#</a> CAP 理论</h2><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86">CAP 理论&#x2F;定理open in new window</a>起源于 2000 年，由加州大学伯克利分校的 Eric Brewer 教授在分布式计算原理研讨会（PODC）上提出，因此 CAP 定理又被称作 <strong>布鲁尔定理（Brewer’s theorem）</strong></p><p>2 年后，麻省理工学院的 Seth Gilbert 和 Nancy Lynch 发表了布鲁尔猜想的证明，CAP 理论正式成为分布式领域的定理。</p><h3 id="简介"><a href="#简介" class="headerlink" title="# 简介"></a><a href="#%E7%AE%80%E4%BB%8B">#</a> 简介</h3><p><strong>CAP</strong> 也就是 <strong>Consistency（一致性）</strong>、<strong>Availability（可用性）</strong>、<strong>Partition Tolerance（分区容错性）</strong> 这三个单词首字母组合。</p><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/2020-11/cap.png" alt="img"></p><p>CAP 理论的提出者布鲁尔在提出 CAP 猜想的时候，并没有详细定义 <strong>Consistency</strong>、<strong>Availability</strong>、<strong>Partition Tolerance</strong> 三个单词的明确定义。</p><p>因此，对于 CAP 的民间解读有很多，一般比较被大家推荐的是下面 👇 这种版本的解读。</p><p>在理论计算机科学中，CAP 定理（CAP theorem）指出对于一个分布式系统来说，当设计读写操作时，只能同时满足以下三点中的两个：</p><ul><li><strong>一致性（Consistency）</strong> : 所有节点访问同一份最新的数据副本</li><li><strong>可用性（Availability）</strong>: 非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。</li><li><strong>分区容错性（Partition Tolerance）</strong> : 分布式系统出现网络分区的时候，仍然能够对外提供服务。</li></ul><p><strong>什么是网络分区？</strong></p><p>分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫 <strong>网络分区</strong>。</p><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/2020-11/partition-tolerance.png" alt="partition-tolerance"></p><h3 id="不是所谓的“3-选-2”"><a href="#不是所谓的“3-选-2”" class="headerlink" title="# 不是所谓的“3 选 2”"></a><a href="#%E4%B8%8D%E6%98%AF%E6%89%80%E8%B0%93%E7%9A%84-3-%E9%80%89-2">#</a> 不是所谓的“3 选 2”</h3><p>大部分人解释这一定律时，常常简单的表述为：“一致性、可用性、分区容忍性三者你只能同时达到其中两个，不可能同时达到”。实际上这是一个非常具有误导性质的说法，而且在 CAP 理论诞生 12 年之后，CAP 之父也在 2012 年重写了之前的论文。</p><blockquote><p><strong>当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。</strong></p><p>简而言之就是：CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者一致性 C。</p></blockquote><p>因此，<strong>分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。</strong> 比如 ZooKeeper、HBase 就是 CP 架构，Cassandra、Eureka 就是 AP 架构，Nacos 不仅支持 CP 架构也支持 AP 架构。</p><p><strong>为啥不可能选择 CA 架构呢？</strong> 举个例子：若系统出现“分区”，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。</p><p><strong>选择 CP 还是 AP 的关键在于当前的业务场景，没有定论，比如对于需要确保强一致性的场景如银行一般会选择保证 CP 。</strong></p><p>另外，需要补充说明的一点是： <strong>如果网络分区正常的话（系统在绝大部分时候所处的状态），也就说不需要保证 P 的时候，C 和 A 能够同时保证。</strong></p><h3 id="CAP-实际应用案例"><a href="#CAP-实际应用案例" class="headerlink" title="# CAP 实际应用案例"></a><a href="#cap-%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B">#</a> CAP 实际应用案例</h3><p>我这里以注册中心来探讨一下 CAP 的实际应用。考虑到很多小伙伴不知道注册中心是干嘛的，这里简单以 Dubbo 为例说一说。</p><p>下图是 Dubbo 的架构图。<strong>注册中心 Registry 在其中扮演了什么角色呢？提供了什么服务呢？</strong></p><p>注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。</p><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/2020-11/dubbo-architecture.png" alt="img"></p><p>常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos…。</p><ol><li><strong>ZooKeeper 保证的是 CP。</strong> 任何时刻对 ZooKeeper 的读请求都能得到一致性的结果，但是， ZooKeeper 不保证每次请求的可用性比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。</li><li><strong>Eureka 保证的则是 AP。</strong> Eureka 在设计的时候就是优先保证 A （可用性）。在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。 Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。</li><li><strong>Nacos 不仅支持 CP 也支持 AP。</strong></li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="# 总结"></a><a href="#%E6%80%BB%E7%BB%93">#</a> 总结</h3><p>在进行分布式系统设计和开发时，我们不应该仅仅局限在 CAP 问题上，还要关注系统的扩展性、可用性等等</p><p>在系统发生“分区”的情况下，CAP 理论只能满足 CP 或者 AP。要注意的是，这里的前提是系统发生了“分区”</p><p>如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。</p><p>总结：<strong>如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。</strong></p><h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="# 推荐阅读"></a><a href="#%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB">#</a> 推荐阅读</h3><ol><li><a target="_blank" rel="noopener" href="https://medium.com/@ravindraprasad/cap-theorem-simplified-28499a67eab4">CAP 定理简化open in new window</a> （英文，有趣的案例）</li><li><a target="_blank" rel="noopener" href="https://juejin.im/post/6844903936718012430">神一样的 CAP 理论被应用在何方open in new window</a> （中文，列举了很多实际的例子）</li><li><a target="_blank" rel="noopener" href="https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html">请停止呼叫数据库 CP 或 AP open in new window</a> （英文，带给你不一样的思考）</li></ol><h2 id="BASE-理论"><a href="#BASE-理论" class="headerlink" title="# BASE 理论"></a><a href="#base-%E7%90%86%E8%AE%BA">#</a> BASE 理论</h2><p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/1394127.1394128">BASE 理论open in new window</a>起源于 2008 年， 由 eBay 的架构师 Dan Pritchett 在 ACM 上发表。</p><h3 id="简介-1"><a href="#简介-1" class="headerlink" title="# 简介"></a><a href="#%E7%AE%80%E4%BB%8B-1">#</a> 简介</h3><p><strong>BASE</strong> 是 <strong>Basically Available（基本可用）</strong> 、<strong>Soft-state（软状态）</strong> 和 <strong>Eventually Consistent（最终一致性）</strong> 三个短语的缩写。BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求。</p><h3 id="BASE-理论的核心思想"><a href="#BASE-理论的核心思想" class="headerlink" title="# BASE 理论的核心思想"></a><a href="#base-%E7%90%86%E8%AE%BA%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3">#</a> BASE 理论的核心思想</h3><p>即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。</p><blockquote><p>也就是牺牲数据的一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统整体“主要可用”。</p></blockquote><p><strong>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。</strong></p><p><strong>为什么这样说呢？</strong></p><p>CAP 理论这节我们也说过了：</p><blockquote><p>如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。因此，<strong>如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。</strong></p></blockquote><p>因此，AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。</p><h3 id="BASE-理论三要素"><a href="#BASE-理论三要素" class="headerlink" title="# BASE 理论三要素"></a><a href="#base-%E7%90%86%E8%AE%BA%E4%B8%89%E8%A6%81%E7%B4%A0">#</a> BASE 理论三要素</h3><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC81LzI0LzE2MzkxNDgwNmQ5ZTE1YzY?x-oss-process=image/format,png" alt="BASE理论三要素"></p><h4 id="基本可用"><a href="#基本可用" class="headerlink" title="# 基本可用"></a><a href="#%E5%9F%BA%E6%9C%AC%E5%8F%AF%E7%94%A8">#</a> 基本可用</h4><p>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。</p><p><strong>什么叫允许损失部分可用性呢？</strong></p><ul><li><strong>响应时间上的损失</strong>: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。</li><li><strong>系统功能上的损失</strong>：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。</li></ul><h4 id="软状态"><a href="#软状态" class="headerlink" title="# 软状态"></a><a href="#%E8%BD%AF%E7%8A%B6%E6%80%81">#</a> 软状态</h4><p>软状态指允许系统中的数据存在中间状态（<strong>CAP 理论中的数据不一致</strong>），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</p><h4 id="最终一致性"><a href="#最终一致性" class="headerlink" title="# 最终一致性"></a><a href="#%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7">#</a> 最终一致性</h4><p>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。</p><blockquote><p>分布式一致性的 3 种级别：</p><ol><li><strong>强一致性</strong> ：系统写入了什么，读出来的就是什么。</li><li><strong>弱一致性</strong> ：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。</li><li><strong>最终一致性</strong> ：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。</li></ol><p><strong>业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。</strong></p></blockquote><p>那实现最终一致性的具体方式是什么呢? <a target="_blank" rel="noopener" href="http://gk.link/a/10rZM">《分布式协议与算法实战》open in new window</a> 中是这样介绍：</p><blockquote><ul><li><strong>读时修复</strong> : 在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点 的副本数据不一致，系统就自动修复数据。</li><li><strong>写时修复</strong> : 在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性。</li><li><strong>异步修复</strong> : 这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。</li></ul></blockquote><p>比较推荐 <strong>写时修复</strong>，这种方式对性能消耗比较低。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="# 总结"></a><a href="#%E6%80%BB%E7%BB%93-1">#</a> 总结</h3><p><strong>ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。</strong></p></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2021/02/17/2021-12-30-ZooKeeper%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%BA%8C%EF%BC%89/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2021/02/17/2021-12-30-ZooKeeper%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%BA%8C%EF%BC%89/" class="post-title-link" itemprop="url">分布式场景下的数据一致性</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-02-17 19:30:00" itemprop="dateCreated datePublished" datetime="2021-02-17T19:30:00+08:00">2021-02-17</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="1-2PC（两阶段提交）"><a href="#1-2PC（两阶段提交）" class="headerlink" title="1. 2PC（两阶段提交）"></a>1. 2PC（两阶段提交）</h2><p>两阶段提交是一种保证分布式系统数据一致性的协议，现在很多数据库都是采用的两阶段提交协议来完成 <strong>分布式事务</strong> 的处理。</p><p>在介绍2PC之前，我们先来想想分布式事务到底有什么问题呢？</p><p>还拿秒杀系统的下订单和加积分两个系统来举例吧（我想你们可能都吐了🤮🤮🤮），我们此时下完订单会发个消息给积分系统告诉它下面该增加积分了。如果我们仅仅是发送一个消息也不收回复，那么我们的订单系统怎么能知道积分系统的收到消息的情况呢？如果我们增加一个收回复的过程，那么当积分系统收到消息后返回给订单系统一个 <code>Response</code> ，但在中间出现了网络波动，那个回复消息没有发送成功，订单系统是不是以为积分系统消息接收失败了？它是不是会回滚事务？但此时积分系统是成功收到消息的，它就会去处理消息然后给用户增加积分，这个时候就会出现积分加了但是订单没下成功。</p><p>所以我们所需要解决的是在分布式系统中，整个调用链中，我们所有服务的数据处理要么都成功要么都失败，即所有服务的 <strong>原子性问题</strong> 。</p><p>在两阶段提交中，主要涉及到两个角色，分别是协调者和参与者。</p><p>第一阶段：当要执行一个分布式事务的时候，事务发起者首先向协调者发起事务请求，然后协调者会给所有参与者发送 <code>prepare</code> 请求（其中包括事务内容）告诉参与者你们需要执行事务了，如果能执行我发的事务内容那么就先执行但不提交，执行后请给我回复。然后参与者收到 <code>prepare</code> 消息后，他们会开始执行事务（但不提交），并将 <code>Undo</code> 和 <code>Redo</code> 信息记入事务日志中，之后参与者就向协调者反馈是否准备好了。</p><p>第二阶段：第二阶段主要是协调者根据参与者反馈的情况来决定接下来是否可以进行事务的提交操作，即提交事务或者回滚事务。</p><p>比如这个时候 <strong>所有的参与者</strong> 都返回了准备好了的消息，这个时候就进行事务的提交，协调者此时会给所有的参与者发送 <strong><code>Commit</code> 请求</strong> ，当参与者收到 <code>Commit</code> 请求的时候会执行前面执行的事务的 <strong>提交操作</strong> ，提交完毕之后将给协调者发送提交成功的响应。</p><p>而如果在第一阶段并不是所有参与者都返回了准备好了的消息，那么此时协调者将会给所有参与者发送 <strong>回滚事务的 <code>rollback</code> 请求</strong>，参与者收到之后将会 <strong>回滚它在第一阶段所做的事务处理</strong> ，然后再将处理情况返回给协调者，最终协调者收到响应后便给事务发起者返回处理失败的结果。</p><p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/36a877fb15e7da608af2f12c5279424b796782ff1075e2fffd1351e8180af7db/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f37636534653430623638643632353637366262343263323965666365303436612e706e67"><img src="https://camo.githubusercontent.com/36a877fb15e7da608af2f12c5279424b796782ff1075e2fffd1351e8180af7db/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f37636534653430623638643632353637366262343263323965666365303436612e706e67" alt="2PC流程"></a></p><p>个人觉得 2PC 实现得还是比较鸡肋的，因为事实上它只解决了各个事务的原子性问题，随之也带来了很多的问题。</p><ul><li><strong>单点故障问题</strong>，如果协调者挂了那么整个系统都处于不可用的状态了。</li><li><strong>阻塞问题</strong>，即当协调者发送 <code>prepare</code> 请求，参与者收到之后如果能处理那么它将会进行事务的处理但并不提交，这个时候会一直占用着资源不释放，如果此时协调者挂了，那么这些资源都不会再释放了，这会极大影响性能。</li><li><strong>数据不一致问题</strong>，比如当第二阶段，协调者只发送了一部分的 <code>commit</code> 请求就挂了，那么也就意味着，收到消息的参与者会进行事务的提交，而后面没收到的则不会进行事务提交，那么这时候就会产生数据不一致性问题。</li></ul><h2 id="2-3PC（三阶段提交）"><a href="#2-3PC（三阶段提交）" class="headerlink" title="2. 3PC（三阶段提交）"></a>2. 3PC（三阶段提交）</h2><p>因为2PC存在的一系列问题，比如单点，容错机制缺陷等等，从而产生了 <strong>3PC（三阶段提交）</strong> 。那么这三阶段又分别是什么呢？</p><blockquote><p>千万不要吧PC理解成个人电脑了，其实他们是 phase-commit 的缩写，即阶段提交。</p></blockquote><ol><li><strong>CanCommit阶段</strong>：协调者向所有参与者发送 <code>CanCommit</code> 请求，参与者收到请求后会根据自身情况查看是否能执行事务，如果可以则返回 YES 响应并进入预备状态，否则返回 NO 。</li><li><strong>PreCommit阶段</strong>：协调者根据参与者返回的响应来决定是否可以进行下面的 <code>PreCommit</code> 操作。如果上面参与者返回的都是 YES，那么协调者将向所有参与者发送 <code>PreCommit</code> 预提交请求，<strong>参与者收到预提交请求后，会进行事务的执行操作，并将 <code>Undo</code> 和 <code>Redo</code> 信息写入事务日志中</strong> ，最后如果参与者顺利执行了事务则给协调者返回成功的响应。如果在第一阶段协调者收到了 <strong>任何一个 NO</strong> 的信息，或者 <strong>在一定时间内</strong> 并没有收到全部的参与者的响应，那么就会中断事务，它会向所有参与者发送中断请求（abort），参与者收到中断请求之后会立即中断事务，或者在一定时间内没有收到协调者的请求，它也会中断事务。</li><li><strong>DoCommit阶段</strong>：这个阶段其实和 <code>2PC</code> 的第二阶段差不多，如果协调者收到了所有参与者在 <code>PreCommit</code> 阶段的 YES 响应，那么协调者将会给所有参与者发送 <code>DoCommit</code> 请求，<strong>参与者收到 <code>DoCommit</code> 请求后则会进行事务的提交工作</strong>，完成后则会给协调者返回响应，协调者收到所有参与者返回的事务提交成功的响应之后则完成事务。若协调者在 <code>PreCommit</code> 阶段 <strong>收到了任何一个 NO 或者在一定时间内没有收到所有参与者的响应</strong> ，那么就会进行中断请求的发送，参与者收到中断请求后则会 <strong>通过上面记录的回滚日志</strong> 来进行事务的回滚操作，并向协调者反馈回滚状况，协调者收到参与者返回的消息后，中断事务。</li></ol><p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/1f5526f43f64af9da097a3e968567288354283c2abb7f997c90ed24ca969350f/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f64306234343336316337343635393366373061366534326332393862343133612e706e67"><img src="https://camo.githubusercontent.com/1f5526f43f64af9da097a3e968567288354283c2abb7f997c90ed24ca969350f/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f64306234343336316337343635393366373061366534326332393862343133612e706e67" alt="3PC流程"></a></p><blockquote><p>这里是 <code>3PC</code> 在成功的环境下的流程图，你可以看到 <code>3PC</code> 在很多地方进行了超时中断的处理，比如协调者在指定时间内为收到全部的确认消息则进行事务中断的处理，这样能 <strong>减少同步阻塞的时间</strong> 。还有需要注意的是，**<code>3PC</code> 在 <code>DoCommit</code> 阶段参与者如未收到协调者发送的提交事务的请求，它会在一定时间内进行事务的提交<strong>。为什么这么做呢？是因为这个时候我们肯定</strong>保证了在第一阶段所有的协调者全部返回了可以执行事务的响应<strong>，这个时候我们有理由</strong>相信其他系统都能进行事务的执行和提交<strong>，所以</strong>不管**协调者有没有发消息给参与者，进入第三阶段参与者都会进行事务的提交操作。</p></blockquote><p>总之，<code>3PC</code> 通过一系列的超时机制很好的缓解了阻塞问题，但是最重要的一致性并没有得到根本的解决，比如在 <code>PreCommit</code> 阶段，当一个参与者收到了请求之后其他参与者和协调者挂了或者出现了网络分区，这个时候收到消息的参与者都会进行事务提交，这就会出现数据不一致性问题。</p><p>所以，要解决一致性问题还需要靠 <code>Paxos</code> 算法⭐️ ⭐️ ⭐️ 。</p><h2 id="3-Paxos-算法"><a href="#3-Paxos-算法" class="headerlink" title="3.Paxos 算法"></a>3.<code>Paxos</code> 算法</h2><p><code>Paxos</code> 算法是基于<strong>消息传递且具有高度容错特性的一致性算法</strong>，是目前公认的解决分布式一致性问题最有效的算法之一，<strong>其解决的问题就是在分布式系统中如何就某个值（决议）达成一致</strong> 。</p><p>在 <code>Paxos</code> 中主要有三个角色，分别为 <code>Proposer提案者</code>、<code>Acceptor表决者</code>、<code>Learner学习者</code>。<code>Paxos</code> 算法和 <code>2PC</code> 一样，也有两个阶段，分别为 <code>Prepare</code> 和 <code>accept</code> 阶段。</p><h3 id="3-1-prepare-阶段"><a href="#3-1-prepare-阶段" class="headerlink" title="3.1. prepare 阶段"></a>3.1. prepare 阶段</h3><ul><li><code>Proposer提案者</code>：负责提出 <code>proposal</code>，每个提案者在提出提案时都会首先获取到一个 <strong>具有全局唯一性的、递增的提案编号N</strong>，即在整个集群中是唯一的编号 N，然后将该编号赋予其要提出的提案，在<strong>第一阶段是只将提案编号发送给所有的表决者</strong>。</li><li><code>Acceptor表决者</code>：每个表决者在 <code>accept</code> 某提案后，会将该提案编号N记录在本地，这样每个表决者中保存的已经被 accept 的提案中会存在一个<strong>编号最大的提案</strong>，其编号假设为 <code>maxN</code>。每个表决者仅会 <code>accept</code> 编号大于自己本地 <code>maxN</code> 的提案，在批准提案时表决者会将以前接受过的最大编号的提案作为响应反馈给 <code>Proposer</code> 。</li></ul><blockquote><p>下面是 <code>prepare</code> 阶段的流程图，你可以对照着参考一下。</p></blockquote><p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/958acf97caf9cb2405b7004dceb966a4c587f43bcc78af3bf150c932dbdf53e8/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f32326538643531326439353436373662646630636339326432303061663865662e706e67"><img src="https://camo.githubusercontent.com/958acf97caf9cb2405b7004dceb966a4c587f43bcc78af3bf150c932dbdf53e8/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f32326538643531326439353436373662646630636339326432303061663865662e706e67" alt="paxos第一阶段"></a></p><h3 id="3-2-accept-阶段"><a href="#3-2-accept-阶段" class="headerlink" title="3.2. accept 阶段"></a>3.2. accept 阶段</h3><p>当一个提案被 <code>Proposer</code> 提出后，如果 <code>Proposer</code> 收到了超过半数的 <code>Acceptor</code> 的批准（<code>Proposer</code> 本身同意），那么此时 <code>Proposer</code> 会给所有的 <code>Acceptor</code> 发送真正的提案（你可以理解为第一阶段为试探），这个时候 <code>Proposer</code> 就会发送提案的内容和提案编号。</p><p>表决者收到提案请求后会再次比较本身已经批准过的最大提案编号和该提案编号，如果该提案编号 <strong>大于等于</strong> 已经批准过的最大提案编号，那么就 <code>accept</code> 该提案（此时执行提案内容但不提交），随后将情况返回给 <code>Proposer</code> 。如果不满足则不回应或者返回 NO 。</p><p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/b14a7f3dbb14ca52f7c2c16ec32f607c16319a11da5e512b2270fdf7691c42de/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f62383235333666393536663730613538346336613230633130313133663232352e706e67"><img src="https://camo.githubusercontent.com/b14a7f3dbb14ca52f7c2c16ec32f607c16319a11da5e512b2270fdf7691c42de/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f62383235333666393536663730613538346336613230633130313133663232352e706e67" alt="paxos第二阶段1"></a></p><p>当 <code>Proposer</code> 收到超过半数的 <code>accept</code> ，那么它这个时候会向所有的 <code>acceptor</code> 发送提案的提交请求。需要注意的是，因为上述仅仅是超过半数的 <code>acceptor</code> 批准执行了该提案内容，其他没有批准的并没有执行该提案内容，所以这个时候需要<strong>向未批准的 <code>acceptor</code> 发送提案内容和提案编号并让它无条件执行和提交</strong>，而对于前面已经批准过该提案的 <code>acceptor</code> 来说 <strong>仅仅需要发送该提案的编号</strong> ，让 <code>acceptor</code> 执行提交就行了。</p><p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/b52244dcbd9969bdf2938521312ab29333a6a9b2d6264335e0e430f2dcf3f4f0/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f37343338383962393734383566646665323039346535656630616636623134312e706e67"><img src="https://camo.githubusercontent.com/b52244dcbd9969bdf2938521312ab29333a6a9b2d6264335e0e430f2dcf3f4f0/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f37343338383962393734383566646665323039346535656630616636623134312e706e67" alt="paxos第二阶段2"></a></p><p>而如果 <code>Proposer</code> 如果没有收到超过半数的 <code>accept</code> 那么它将会将 <strong>递增</strong> 该 <code>Proposal</code> 的编号，然后 <strong>重新进入 <code>Prepare</code> 阶段</strong> 。</p><blockquote><p>对于 <code>Learner</code> 来说如何去学习 <code>Acceptor</code> 批准的提案内容，这有很多方式，读者可以自己去了解一下，这里不做过多解释。</p></blockquote><h3 id="3-3-paxos-算法的死循环问题"><a href="#3-3-paxos-算法的死循环问题" class="headerlink" title="3.3. paxos 算法的死循环问题"></a>3.3. <code>paxos</code> 算法的死循环问题</h3><p>其实就有点类似于两个人吵架，小明说我是对的，小红说我才是对的，两个人据理力争的谁也不让谁🤬🤬。</p><p>比如说，此时提案者 P1 提出一个方案 M1，完成了 <code>Prepare</code> 阶段的工作，这个时候 <code>acceptor</code> 则批准了 M1，但是此时提案者 P2 同时也提出了一个方案 M2，它也完成了 <code>Prepare</code> 阶段的工作。然后 P1 的方案已经不能在第二阶段被批准了（因为 <code>acceptor</code> 已经批准了比 M1 更大的 M2），所以 P1 自增方案变为 M3 重新进入 <code>Prepare</code> 阶段，然后 <code>acceptor</code> ，又批准了新的 M3 方案，它又不能批准 M2 了，这个时候 M2 又自增进入 <code>Prepare</code> 阶段。。。</p><p>就这样无休无止的永远提案下去，这就是 <code>paxos</code> 算法的死循环问题。</p><p>那么如何解决呢？很简单，人多了容易吵架，我现在 <strong>就允许一个能提案</strong> 就行了。</p></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2021/02/15/2021-02-15-kafka%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2021/02/15/2021-02-15-kafka%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">Kafka面试问题总结</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-02-15 19:30:00" itemprop="dateCreated datePublished" datetime="2021-02-15T19:30:00+08:00">2021-02-15</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="1-Apache-Kafka是什么？"><a href="#1-Apache-Kafka是什么？" class="headerlink" title="1. Apache Kafka是什么？"></a>1. Apache Kafka是什么？</h2><p>Apach Kafka是一款分布式流处理平台，用于实时构建流处理应用。它有一个核心的功能广为人知，即作为企业级的消息引擎被广泛使用（通常也会称之为消息总线message bus）。</p><h2 id="2-Kafka-的设计是什么样的？"><a href="#2-Kafka-的设计是什么样的？" class="headerlink" title="2. Kafka 的设计是什么样的？"></a>2. Kafka 的设计是什么样的？</h2><p>Kafka 将消息以 topic 为单位进行归纳</p><p>将向 Kafka topic 发布消息的程序成为 producers.</p><p>将预订 topics 并消费消息的程序成为 consumer.</p><p>Kafka 以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个 broker.</p><p>producers 通过网络将消息发送到 Kafka 集群，集群向消费者提供消息</p><h2 id="3-Kafka-如何保证高可用？"><a href="#3-Kafka-如何保证高可用？" class="headerlink" title="3. Kafka 如何保证高可用？"></a>3. Kafka 如何保证高可用？</h2><p><code>Kafka</code> 的基本架构组成是：由多个 <code>broker</code> 组成一个集群，每个 <code>broker</code> 是一个节点；当创建一个 <code>topic</code> 时，这个 <code>topic</code> 会被划分为多个 <code>partition</code>，每个 <code>partition</code> 可以存在于不同的 <code>broker</code> 上，每个 <code>partition</code> 只存放一部分数据。</p><p>这就是<strong>天然的分布式消息队列</strong>，就是说一个 <code>topic</code> 的数据，是<strong>分散放在多个机器上的，每个机器就放一部分数据</strong>。</p><p>在 <code>Kafka 0.8</code> 版本之前，是没有 <code>HA</code> 机制的，当任何一个 <code>broker</code> 所在节点宕机了，这个 <code>broker</code> 上的 <code>partition</code> 就无法提供读写服务，所以这个版本之前，<code>Kafka</code> 没有什么高可用性可言。</p><p>在 <code>Kafka 0.8</code> 以后，提供了 <code>HA</code> 机制，就是 <code>replica</code> 副本机制。每个 <code>partition</code> 上的数据都会同步到其它机器，形成自己的多个 <code>replica</code> 副本。所有 <code>replica</code> 会选举一个 <code>leader</code> 出来，消息的生产者和消费者都跟这个 <code>leader</code> 打交道，其他 <code>replica</code> 作为 <code>follower</code>。写的时候，<code>leader</code> 会负责把数据同步到所有 <code>follower</code> 上去，读的时候就直接读 <code>leader</code> 上的数据即可。<code>Kafka</code> 负责均匀的将一个 <code>partition</code> 的所有 <code>replica</code> 分布在不同的机器上，这样才可以提高容错性。</p><p><img src="http://blog-img.coolsen.cn/img/Solve-MQ-Problem-With-Kafka-01.png" alt="img"></p><p>拥有了 <code>replica</code> 副本机制，如果某个 <code>broker</code> 宕机了，这个 <code>broker</code> 上的 <code>partition</code> 在其他机器上还存在副本。如果这个宕机的 <code>broker</code> 上面有某个 <code>partition</code> 的 <code>leader</code>，那么此时会从其 <code>follower</code> 中重新选举一个新的 <code>leader</code> 出来，这个新的 <code>leader</code> 会继续提供读写服务，这就有达到了所谓的高可用性。</p><p>写数据的时候，生产者只将数据写入 <code>leader</code> 节点，<code>leader</code> 会将数据写入本地磁盘，接着其他 <code>follower</code> 会主动从 <code>leader</code> 来拉取数据，<code>follower</code> 同步好数据了，就会发送 <code>ack</code> 给 <code>leader</code>，<code>leader</code> 收到所有 <code>follower</code> 的 <code>ack</code> 之后，就会返回写成功的消息给生产者。</p><p>消费数据的时候，消费者只会从 <code>leader</code> 节点去读取消息，但是只有当一个消息已经被所有 <code>follower</code> 都同步成功返回 <code>ack</code> 的时候，这个消息才会被消费者读到。</p><p><img src="https://gitee.com/dongzl/article-images/raw/master/2020/13-Solve-MQ-Problem-With-Kafka/Solve-MQ-Problem-With-Kafka-02.png" alt="img"></p><h2 id="4-Kafka-消息是采用-Pull-模式，还是-Push-模式？"><a href="#4-Kafka-消息是采用-Pull-模式，还是-Push-模式？" class="headerlink" title="4. Kafka 消息是采用 Pull 模式，还是 Push 模式？"></a>4. Kafka 消息是采用 Pull 模式，还是 Push 模式？</h2><p>生产者使用push模式将消息发布到Broker，消费者使用pull模式从Broker订阅消息。</p><p>push模式很难适应消费速率不同的消费者，如果push的速度太快，容易造成消费者拒绝服务或网络拥塞；如果push的速度太慢，容易造成消费者性能浪费。但是采用pull的方式也有一个缺点，就是当Broker没有消息时，消费者会陷入不断地轮询中，为了避免这点，kafka有个参数可以让消费者阻塞知道是否有新消息到达。</p><h2 id="5-Kafka-与传统消息系统之间的区别"><a href="#5-Kafka-与传统消息系统之间的区别" class="headerlink" title="5. Kafka 与传统消息系统之间的区别"></a>5. Kafka 与传统消息系统之间的区别</h2><ul><li><p>Kafka 持久化日志，这些日志可以被重复读取和无限期保留</p></li><li><p>Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性</p></li><li><p>Kafka 支持实时的流式处理</p></li></ul><h2 id="6-什么是消费者组？"><a href="#6-什么是消费者组？" class="headerlink" title="6. 什么是消费者组？"></a>6. 什么是消费者组？</h2><p>消费者组是Kafka独有的概念，即消费者组是Kafka提供的可扩展且具有容错性的消费者机制。</p><p>但实际上，消费者组（Consumer Group）其实包含两个概念，作为队列，消费者组允许你分割数据处理到一组进程集合上（即一个消费者组中可以包含多个消费者进程，他们共同消费该topic的数据），这有助于你的消费能力的动态调整；作为发布-订阅模型（publish-subscribe），Kafka允许你将同一份消息广播到多个消费者组里，以此来丰富多种数据使用场景。</p><p>需要注意的是：在消费者组中，多个实例共同订阅若干个主题，实现共同消费。同一个组下的每个实例都配置有相同的组ID，被分配不同的订阅分区。当某个实例挂掉的时候，其他实例会自动地承担起它负责消费的分区。 因此，消费者组在一定程度上也保证了消费者程序的高可用性。</p><p><a target="_blank" rel="noopener" href="http://dockone.io/uploads/article/20201024/7b359b7a1381541fbacf3ecf20dfb347.jpg"><img src="http://dockone.io/uploads/article/20201024/7b359b7a1381541fbacf3ecf20dfb347.jpg" alt="1.jpg"></a></p><h2 id="7-在Kafka中，ZooKeeper的作用是什么？"><a href="#7-在Kafka中，ZooKeeper的作用是什么？" class="headerlink" title="7. 在Kafka中，ZooKeeper的作用是什么？"></a>7. 在Kafka中，ZooKeeper的作用是什么？</h2><p>目前，Kafka使用ZooKeeper存放集群元数据、成员管理、Controller选举，以及其他一些管理类任务。之后，等KIP-500提案完成后，Kafka将完全不再依赖于ZooKeeper。</p><ul><li>“存放元数据”是指主题分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他 “人” 都要与它保持对齐。</li><li>“成员管理” 是指 Broker 节点的注册、注销以及属性变更，等等。</li><li>“Controller 选举” 是指选举集群 Controller，而其他管理类任务包括但不限于主题删除、参数配置等。</li></ul><p>KIP-500 思想，是使用社区自研的基于Raft的共识算法，替代ZooKeeper，实现Controller自选举。</p><h2 id="8-解释下Kafka中位移（offset）的作用"><a href="#8-解释下Kafka中位移（offset）的作用" class="headerlink" title="8. 解释下Kafka中位移（offset）的作用"></a>8. 解释下Kafka中位移（offset）的作用</h2><p>在Kafka中，每个主题分区下的每条消息都被赋予了一个唯一的ID数值，用于标识它在分区中的位置。这个ID数值，就被称为位移，或者叫偏移量。一旦消息被写入到分区日志，它的位移值将不能被修改。</p><h2 id="9-kafka-为什么那么快？"><a href="#9-kafka-为什么那么快？" class="headerlink" title="9. kafka 为什么那么快？"></a>9. kafka 为什么那么快？</h2><ul><li>Cache Filesystem Cache PageCache缓存</li><li><code>顺序写</code>：由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。</li><li><code>Zero-copy</code>：零拷技术减少拷贝次数</li><li><code>Batching of Messages</code>：批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。</li><li><code>Pull 拉模式</code>：使用拉模式进行消息的获取消费，与消费端处理能力相符。</li></ul><h2 id="10-kafka-producer发送数据，ack为0，1，-1分别是什么意思？"><a href="#10-kafka-producer发送数据，ack为0，1，-1分别是什么意思？" class="headerlink" title="10. kafka producer发送数据，ack为0，1，-1分别是什么意思？"></a>10. kafka producer发送数据，ack为0，1，-1分别是什么意思？</h2><ul><li><code>1</code>（默认） 数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。在这种情况下，如果leader宕机了，则会丢失数据。</li><li><code>0</code> 生产者将数据发送出去就不管了，不去等待任何返回。这种情况下数据传输效率最高，但是数据可靠性确是最低的。</li><li><code>-1</code>producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。当ISR中所有Replica都向Leader发送ACK时，leader才commit，这时候producer才能认为一个请求中的消息都commit了。</li></ul><h2 id="11-Kafka如何保证消息不丢失"><a href="#11-Kafka如何保证消息不丢失" class="headerlink" title="11. Kafka如何保证消息不丢失?"></a>11. Kafka如何保证消息不丢失?</h2><p>首先需要弄明白消息为什么会丢失，对于一个消息队列，会有 <code>生产者</code>、<code>MQ</code>、<code>消费者</code> 这三个角色，在这三个角色数据处理和传输过程中，都有可能会出现消息丢失。</p><p><img src="http://blog-img.coolsen.cn/img/Solve-MQ-Problem-With-Kafka-03.png" alt="img"></p><p>消息丢失的原因以及解决办法：</p><h3 id="消费者异常导致的消息丢失"><a href="#消费者异常导致的消息丢失" class="headerlink" title="消费者异常导致的消息丢失"></a>消费者异常导致的消息丢失</h3><p>消费者可能导致数据丢失的情况是：消费者获取到了这条消息后，还未处理，<code>Kafka</code> 就自动提交了 <code>offset</code>，这时 <code>Kafka</code> 就认为消费者已经处理完这条消息，其实消费者才刚准备处理这条消息，这时如果消费者宕机，那这条消息就丢失了。</p><p>消费者引起消息丢失的主要原因就是消息还未处理完 <code>Kafka</code> 会自动提交了 <code>offset</code>，那么只要关闭自动提交 <code>offset</code>，消费者在处理完之后手动提交 <code>offset</code>，就可以保证消息不会丢失。但是此时需要注意重复消费问题，比如消费者刚处理完，还没提交 <code>offset</code>，这时自己宕机了，此时这条消息肯定会被重复消费一次，这就需要消费者根据实际情况保证幂等性。</p><h3 id="生产者数据传输导致的消息丢失"><a href="#生产者数据传输导致的消息丢失" class="headerlink" title="生产者数据传输导致的消息丢失"></a>生产者数据传输导致的消息丢失</h3><p>对于生产者数据传输导致的数据丢失主常见情况是生产者发送消息给 <code>Kafka</code>，由于网络等原因导致消息丢失，对于这种情况也是通过在 <strong>producer</strong> 端设置 <strong>acks&#x3D;all</strong> 来处理，这个参数是要求 <code>leader</code> 接收到消息后，需要等到所有的 <code>follower</code> 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试。</p><h3 id="Kafka-导致的消息丢失"><a href="#Kafka-导致的消息丢失" class="headerlink" title="Kafka 导致的消息丢失"></a>Kafka 导致的消息丢失</h3><p><code>Kafka</code> 导致的数据丢失一个常见的场景就是 <code>Kafka</code> 某个 <code>broker</code> 宕机，，而这个节点正好是某个 <code>partition</code> 的 <code>leader</code> 节点，这时需要重新重新选举该 <code>partition</code> 的 <code>leader</code>。如果该 <code>partition</code> 的 <code>leader</code> 在宕机时刚好还有些数据没有同步到 <code>follower</code>，此时 <code>leader</code> 挂了，在选举某个 <code>follower</code> 成 <code>leader</code> 之后，就会丢失一部分数据。</p><p>对于这个问题，<code>Kafka</code> 可以设置如下 4 个参数，来尽量避免消息丢失：</p><ul><li>给 <code>topic</code> 设置 <code>replication.factor</code> 参数：这个值必须大于 <code>1</code>，要求每个 <code>partition</code> 必须有至少 <code>2</code> 个副本；</li><li>在 <code>Kafka</code> 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 <code>1</code>，这个参数的含义是一个 <code>leader</code> 至少感知到有至少一个 <code>follower</code> 还跟自己保持联系，没掉队，这样才能确保 <code>leader</code> 挂了还有一个 <code>follower</code> 节点。</li><li>在 <code>producer</code> 端设置 <code>acks=all</code>，这个是要求每条数据，必须是写入所有 <code>replica</code> 之后，才能认为是写成功了；</li><li>在 <code>producer</code> 端设置 <code>retries=MAX</code>（很大很大很大的一个值，无限次重试的意思）：这个参数的含义是一旦写入失败，就无限重试，卡在这里了。</li></ul><h2 id="13-Kafka-如何保证消息的顺序性"><a href="#13-Kafka-如何保证消息的顺序性" class="headerlink" title="13. Kafka 如何保证消息的顺序性"></a>13. Kafka 如何保证消息的顺序性</h2><p>在某些业务场景下，我们需要保证对于有逻辑关联的多条MQ消息被按顺序处理，比如对于某一条数据，正常处理顺序是<code>新增-更新-删除</code>，最终结果是数据被删除；如果消息没有按序消费，处理顺序可能是<code>删除-新增-更新</code>，最终数据没有被删掉，可能会产生一些逻辑错误。对于如何保证消息的顺序性，主要需要考虑如下两点：</p><ul><li>如何保证消息在 <code>Kafka</code> 中顺序性；</li><li>如何保证消费者处理消费的顺序性。</li></ul><h3 id="如何保证消息在-Kafka-中顺序性"><a href="#如何保证消息在-Kafka-中顺序性" class="headerlink" title="如何保证消息在 Kafka 中顺序性"></a>如何保证消息在 Kafka 中顺序性</h3><p>对于 <code>Kafka</code>，如果我们创建了一个 <code>topic</code>，默认有三个 <code>partition</code>。生产者在写数据的时候，可以指定一个 <code>key</code>，比如在订单 <code>topic</code> 中我们可以指定订单 <code>id</code> 作为 <code>key</code>，那么相同订单 <code>id</code> 的数据，一定会被分发到同一个 <code>partition</code> 中去，而且这个 <code>partition</code> 中的数据一定是有顺序的。消费者从 <code>partition</code> 中取出来数据的时候，也一定是有顺序的。通过制定 <code>key</code> 的方式首先可以保证在 <code>kafka</code> 内部消息是有序的。</p><h3 id="如何保证消费者处理消费的顺序性"><a href="#如何保证消费者处理消费的顺序性" class="headerlink" title="如何保证消费者处理消费的顺序性"></a>如何保证消费者处理消费的顺序性</h3><p>对于某个 <code>topic</code> 的一个 <code>partition</code>，只能被同组内部的一个 <code>consumer</code> 消费，如果这个 <code>consumer</code> 内部还是单线程处理，那么其实只要保证消息在 <code>MQ</code> 内部是有顺序的就可以保证消费也是有顺序的。但是单线程吞吐量太低，在处理大量 <code>MQ</code> 消息时，我们一般会开启多线程消费机制，那么如何保证消息在多个线程之间是被顺序处理的呢？对于多线程消费我们可以预先设置 <code>N</code> 个内存 <code>Queue</code>，具有相同 <code>key</code> 的数据都放到同一个内存 <code>Queue</code> 中；然后开启 <code>N</code> 个线程，每个线程分别消费一个内存 <code>Queue</code> 的数据即可，这样就能保证顺序性。当然，消息放到内存 <code>Queue</code> 中，有可能还未被处理，<code>consumer</code> 发生宕机，内存 <code>Queue</code> 中的数据会全部丢失，这就转变为上面提到的<strong>如何保证消息的可靠传输</strong>的问题了。</p><h2 id="14-Kafka中的ISR、AR代表什么？ISR的伸缩指什么？"><a href="#14-Kafka中的ISR、AR代表什么？ISR的伸缩指什么？" class="headerlink" title="14. Kafka中的ISR、AR代表什么？ISR的伸缩指什么？"></a>14. Kafka中的ISR、AR代表什么？ISR的伸缩指什么？</h2><ul><li><code>ISR</code>：In-Sync Replicas 副本同步队列</li><li><code>AR</code>:Assigned Replicas 所有副本</li></ul><p>ISR是由leader维护，follower从leader同步数据有一些延迟（包括<code>延迟时间replica.lag.time.max.ms</code>和<code>延迟条数replica.lag.max.messages</code>两个维度，当前最新的版本0.10.x中只支持<code>replica.lag.time.max.ms</code>这个维度），任意一个超过阈值都会把follower剔除出ISR，存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。</p><blockquote><p>AR&#x3D;ISR+OSR。</p></blockquote><h2 id="15-描述下-Kafka-中的领导者副本（Leader-Replica）和追随者副本（Follower-Replica）的区别"><a href="#15-描述下-Kafka-中的领导者副本（Leader-Replica）和追随者副本（Follower-Replica）的区别" class="headerlink" title="15. 描述下 Kafka 中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别"></a>15. 描述下 Kafka 中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别</h2><p>Kafka副本当前分为领导者副本和追随者副本。只有Leader副本才能对外提供读写服务，响应Clients端的请求。Follower副本只是采用拉（PULL）的方式，被动地同步Leader副本中的数据，并且在Leader副本所在的Broker宕机后，随时准备应聘Leader副本。</p><p>加分点：</p><ul><li>强调Follower副本也能对外提供读服务。自Kafka 2.4版本开始，社区通过引入新的Broker端参数，允许Follower副本有限度地提供读服务。</li><li>强调Leader和Follower的消息序列在实际场景中不一致。通常情况下，很多因素可能造成Leader和Follower之间的不同步，比如程序问题，网络问题，broker问题等，短暂的不同步我们可以关注（秒级别），但长时间的不同步可能就需要深入排查了，因为一旦Leader所在节点异常，可能直接影响可用性。</li></ul><p>注意：之前确保一致性的主要手段是高水位机制（HW），但高水位值无法保证Leader连续变更场景下的数据一致性，因此，社区引入了Leader Epoch机制，来修复高水位值的弊端。</p><h2 id="16-分区Leader选举策略有几种？"><a href="#16-分区Leader选举策略有几种？" class="headerlink" title="16. 分区Leader选举策略有几种？"></a>16. 分区Leader选举策略有几种？</h2><p>分区的Leader副本选举对用户是完全透明的，它是由Controller独立完成的。你需要回答的是，在哪些场景下，需要执行分区Leader选举。每一种场景对应于一种选举策略。</p><ul><li>OfflinePartition Leader选举：每当有分区上线时，就需要执行Leader选举。所谓的分区上线，可能是创建了新分区，也可能是之前的下线分区重新上线。这是最常见的分区Leader选举场景。</li><li>ReassignPartition Leader选举：当你手动运行kafka-reassign-partitions命令，或者是调用Admin的alterPartitionReassignments方法执行分区副本重分配时，可能触发此类选举。假设原来的AR是[1，2，3]，Leader是1，当执行副本重分配后，副本集合AR被设置成[4，5，6]，显然，Leader必须要变更，此时会发生Reassign Partition Leader选举。</li><li>PreferredReplicaPartition Leader选举：当你手动运行kafka-preferred-replica-election命令，或自动触发了Preferred Leader选举时，该类策略被激活。所谓的Preferred Leader，指的是AR中的第一个副本。比如AR是[3，2，1]，那么，Preferred Leader就是3。</li><li>ControlledShutdownPartition Leader选举：当Broker正常关闭时，该Broker上的所有Leader副本都会下线，因此，需要为受影响的分区执行相应的Leader选举。</li></ul><p>这4类选举策略的大致思想是类似的，即从AR中挑选首个在ISR中的副本，作为新Leader。</p><h2 id="17-Kafka的哪些场景中使用了零拷贝（Zero-Copy）？"><a href="#17-Kafka的哪些场景中使用了零拷贝（Zero-Copy）？" class="headerlink" title="17. Kafka的哪些场景中使用了零拷贝（Zero Copy）？"></a>17. Kafka的哪些场景中使用了零拷贝（Zero Copy）？</h2><p>在Kafka中，体现Zero Copy使用场景的地方有两处：基于mmap的索引和日志文件读写所用的TransportLayer。</p><p>先说第一个。索引都是基于MappedByteBuffer的，也就是让用户态和内核态共享内核态的数据缓冲区，此时，数据不需要复制到用户态空间。不过，mmap虽然避免了不必要的拷贝，但不一定就能保证很高的性能。在不同的操作系统下，mmap的创建和销毁成本可能是不一样的。很高的创建和销毁开销会抵消Zero Copy带来的性能优势。由于这种不确定性，在Kafka中，只有索引应用了mmap，最核心的日志并未使用mmap机制。</p><p>再说第二个。TransportLayer是Kafka传输层的接口。它的某个实现类使用了FileChannel的transferTo方法。该方法底层使用sendfile实现了Zero Copy。对Kafka而言，如果I&#x2F;O通道使用普通的PLAINTEXT，那么，Kafka就可以利用Zero Copy特性，直接将页缓存中的数据发送到网卡的Buffer中，避免中间的多次拷贝。相反，如果I&#x2F;O通道启用了SSL，那么，Kafka便无法利用Zero Copy特性了。</p><h2 id="18-为什么Kafka不支持读写分离？"><a href="#18-为什么Kafka不支持读写分离？" class="headerlink" title="18. 为什么Kafka不支持读写分离？"></a>18. 为什么Kafka不支持读写分离？</h2><p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。</p><p>Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:</p><ul><li><strong>数据一致性问题</strong>。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。</li><li><strong>延时问题</strong>。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历<code>网络→主节点内存→网络→从节点内存</code>这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历<code>网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘</code>这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="http://dockone.io/article/10853">http://dockone.io/article/10853</a></p><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000023716306">https://segmentfault.com/a/1190000023716306</a></p><p><a target="_blank" rel="noopener" href="https://dongzl.github.io/2020/03/16/13-Solve-MQ-Problem-With-Kafka/index.html">https://dongzl.github.io/2020/03/16/13-Solve-MQ-Problem-With-Kafka/index.html</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2021/01/16/2021-01-16-RAFT%E7%AE%97%E6%B3%95/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2021/01/16/2021-01-16-RAFT%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">RAFT算法</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-01-16 19:30:00" itemprop="dateCreated datePublished" datetime="2021-01-16T19:30:00+08:00">2021-01-16</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>当今的数据中心和应用程序在高度动态的环境中运行，为了应对高度动态的环境，它们通过额外的服务器进行横向扩展，并且根据需求进行扩展和收缩。同时，服务器和网络故障也很常见。</p><p>因此，系统必须在正常操作期间处理服务器的上下线。它们必须对变故做出反应并在几秒钟内自动适应；对客户来说的话，明显的中断通常是不可接受的。</p><p>幸运的是，分布式共识可以帮助应对这些挑战。</p><h3 id="1-1-拜占庭将军"><a href="#1-1-拜占庭将军" class="headerlink" title="# 1.1 拜占庭将军"></a><a href="#_1-1-%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B">#</a> 1.1 拜占庭将军</h3><p>在介绍共识算法之前，先介绍一个简化版拜占庭将军的例子来帮助理解共识算法。</p><blockquote><p>假设多位拜占庭将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成是否要进攻的一致性决定？</p></blockquote><p>解决方案大致可以理解成：先在所有的将军中选出一个大将军，用来做出所有的决定。</p><p>举例如下：假如现在一共有 3 个将军 A，B 和 C，每个将军都有一个随机时间的倒计时器，倒计时一结束，这个将军就把自己当成大将军候选人，然后派信使传递选举投票的信息给将军 B 和 C，如果将军 B 和 C 还没有把自己当作候选人（自己的倒计时还没有结束），并且没有把选举票投给其他人，它们就会把票投给将军 A，信使回到将军 A 时，将军 A 知道自己收到了足够的票数，成为大将军。在有了大将军之后，是否需要进攻就由大将军 A 决定，然后再去派信使通知另外两个将军，自己已经成为了大将军。如果一段时间还没收到将军 B 和 C 的回复（信使可能会被暗杀），那就再重派一个信使，直到收到回复。</p><h3 id="1-2-共识算法"><a href="#1-2-共识算法" class="headerlink" title="# 1.2 共识算法"></a><a href="#_1-2-%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95">#</a> 1.2 共识算法</h3><p>共识是可容错系统中的一个基本问题：即使面对故障，服务器也可以在共享状态上达成一致。</p><p>共识算法允许一组节点像一个整体一样一起工作，即使其中的一些节点出现故障也能够继续工作下去，其正确性主要是源于复制状态机的性质：一组<code>Server</code>的状态机计算相同状态的副本，即使有一部分的<code>Server</code>宕机了它们仍然能够继续运行。</p><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/paxos-rsm-architecture.png" alt="rsm-architecture.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图-1 复制状态机架构</span><br></pre></td></tr></table></figure><p>一般通过使用复制日志来实现复制状态机。每个<code>Server</code>存储着一份包括命令序列的日志文件，状态机会按顺序执行这些命令。因为每个日志包含相同的命令，并且顺序也相同，所以每个状态机处理相同的命令序列。由于状态机是确定性的，所以处理相同的状态，得到相同的输出。</p><p>因此共识算法的工作就是保持复制日志的一致性。服务器上的共识模块从客户端接收命令并将它们添加到日志中。它与其他服务器上的共识模块通信，以确保即使某些服务器发生故障。每个日志最终包含相同顺序的请求。一旦命令被正确地复制，它们就被称为已提交。每个服务器的状态机按照日志顺序处理已提交的命令，并将输出返回给客户端，因此，这些服务器形成了一个单一的、高度可靠的状态机。</p><p>适用于实际系统的共识算法通常具有以下特性：</p><ul><li>安全。确保在非拜占庭条件（也就是上文中提到的简易版拜占庭）下的安全性，包括网络延迟、分区、包丢失、复制和重新排序。</li><li>高可用。只要大多数服务器都是可操作的，并且可以相互通信，也可以与客户端进行通信，那么这些服务器就可以看作完全功能可用的。因此，一个典型的由五台服务器组成的集群可以容忍任何两台服务器端故障。假设服务器因停止而发生故障；它们稍后可能会从稳定存储上的状态中恢复并重新加入集群。</li><li>一致性不依赖时序。错误的时钟和极端的消息延迟，在最坏的情况下也只会造成可用性问题，而不会产生一致性问题。</li><li>在集群中大多数服务器响应，命令就可以完成，不会被少数运行缓慢的服务器来影响整体系统性能。</li></ul><h2 id="2-基础"><a href="#2-基础" class="headerlink" title="# 2 基础"></a><a href="#_2-%E5%9F%BA%E7%A1%80">#</a> 2 基础</h2><h3 id="2-1-节点类型"><a href="#2-1-节点类型" class="headerlink" title="# 2.1 节点类型"></a><a href="#_2-1-%E8%8A%82%E7%82%B9%E7%B1%BB%E5%9E%8B">#</a> 2.1 节点类型</h3><p>一个 Raft 集群包括若干服务器，以典型的 5 服务器集群举例。在任意的时间，每个服务器一定会处于以下三个状态中的一个：</p><ul><li><code>Leader</code>：负责发起心跳，响应客户端，创建日志，同步日志。</li><li><code>Candidate</code>：Leader 选举过程中的临时角色，由 Follower 转化而来，发起投票参与竞选。</li><li><code>Follower</code>：接受 Leader 的心跳和日志同步数据，投票给 Candidate。</li></ul><p>在正常的情况下，只有一个服务器是 Leader，剩下的服务器是 Follower。Follower 是被动的，它们不会发送任何请求，只是响应来自 Leader 和 Candidate 的请求。</p><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/paxos-server-state.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图-2：服务器的状态</span><br></pre></td></tr></table></figure><h3 id="2-2-任期"><a href="#2-2-任期" class="headerlink" title="# 2.2 任期"></a><a href="#_2-2-%E4%BB%BB%E6%9C%9F">#</a> 2.2 任期</h3><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/paxos-term.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图-3：任期</span><br></pre></td></tr></table></figure><p>如图 3 所示，raft 算法将时间划分为任意长度的任期（term），任期用连续的数字表示，看作当前 term 号。每一个任期的开始都是一次选举，在选举开始时，一个或多个 Candidate 会尝试成为 Leader。如果一个 Candidate 赢得了选举，它就会在该任期内担任 Leader。如果没有选出 Leader，将会开启另一个任期，并立刻开始下一次选举。raft 算法保证在给定的一个任期最少要有一个 Leader。</p><p>每个节点都会存储当前的 term 号，当服务器之间进行通信时会交换当前的 term 号；如果有服务器发现自己的 term 号比其他人小，那么他会更新到较大的 term 值。如果一个 Candidate 或者 Leader 发现自己的 term 过期了，他会立即退回成 Follower。如果一台服务器收到的请求的 term 号是过期的，那么它会拒绝此次请求。</p><h3 id="2-3-日志"><a href="#2-3-日志" class="headerlink" title="# 2.3 日志"></a><a href="#_2-3-%E6%97%A5%E5%BF%97">#</a> 2.3 日志</h3><ul><li><code>entry</code>：每一个事件成为 entry，只有 Leader 可以创建 entry。entry 的内容为<code>&lt;term,index,cmd&gt;</code>其中 cmd 是可以应用到状态机的操作。</li><li><code>log</code>：由 entry 构成的数组，每一个 entry 都有一个表明自己在 log 中的 index。只有 Leader 才可以改变其他节点的 log。entry 总是先被 Leader 添加到自己的 log 数组中，然后再发起共识请求，获得同意后才会被 Leader 提交给状态机。Follower 只能从 Leader 获取新日志和当前的 commitIndex，然后把对应的 entry 应用到自己的状态机中。</li></ul><h2 id="3-领导人选举"><a href="#3-领导人选举" class="headerlink" title="# 3 领导人选举"></a><a href="#_3-%E9%A2%86%E5%AF%BC%E4%BA%BA%E9%80%89%E4%B8%BE">#</a> 3 领导人选举</h2><p>raft 使用心跳机制来触发 Leader 的选举。</p><p>如果一台服务器能够收到来自 Leader 或者 Candidate 的有效信息，那么它会一直保持为 Follower 状态，并且刷新自己的 electionElapsed，重新计时。</p><p>Leader 会向所有的 Follower 周期性发送心跳来保证自己的 Leader 地位。如果一个 Follower 在一个周期内没有收到心跳信息，就叫做选举超时，然后它就会认为此时没有可用的 Leader，并且开始进行一次选举以选出一个新的 Leader。</p><p>为了开始新的选举，Follower 会自增自己的 term 号并且转换状态为 Candidate。然后他会向所有节点发起 RequestVoteRPC 请求， Candidate 的状态会持续到以下情况发生：</p><ul><li>赢得选举</li><li>其他节点赢得选举</li><li>一轮选举结束，无人胜出</li></ul><p>赢得选举的条件是：一个 Candidate 在一个任期内收到了来自集群内的多数选票<code>（N/2+1）</code>，就可以成为 Leader。</p><p>在 Candidate 等待选票的时候，它可能收到其他节点声明自己是 Leader 的心跳，此时有两种情况：</p><ul><li>该 Leader 的 term 号大于等于自己的 term 号，说明对方已经成为 Leader，则自己回退为 Follower。</li><li>该 Leader 的 term 号小于自己的 term 号，那么会拒绝该请求并让该节点更新 term。</li></ul><p>由于可能同一时刻出现多个 Candidate，导致没有 Candidate 获得大多数选票，如果没有其他手段来重新分配选票的话，那么可能会无限重复下去。</p><p>raft 使用了随机的选举超时时间来避免上述情况。每一个 Candidate 在发起选举后，都会随机化一个新的枚举超时时间，这种机制使得各个服务器能够分散开来，在大多数情况下只有一个服务器会率先超时；它会在其他服务器超时之前赢得选举。</p><h2 id="4-日志复制"><a href="#4-日志复制" class="headerlink" title="# 4 日志复制"></a><a href="#_4-%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6">#</a> 4 日志复制</h2><p>一旦选出了 Leader，它就开始接受客户端的请求。每一个客户端的请求都包含一条需要被复制状态机（<code>Replicated State Mechine</code>）执行的命令。</p><p>Leader 收到客户端请求后，会生成一个 entry，包含<code>&lt;index,term,cmd&gt;</code>，再将这个 entry 添加到自己的日志末尾后，向所有的节点广播该 entry，要求其他服务器复制这条 entry。</p><p>如果 Follower 接受该 entry，则会将 entry 添加到自己的日志后面，同时返回给 Leader 同意。</p><p>如果 Leader 收到了多数的成功响应，Leader 会将这个 entry 应用到自己的状态机中，之后可以成为这个 entry 是 committed 的，并且向客户端返回执行结果。</p><p>raft 保证以下两个性质：</p><ul><li>在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们一定有相同的 cmd</li><li>在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们前面的 entry 也一定相同</li></ul><p>通过“仅有 Leader 可以生存 entry”来保证第一个性质，第二个性质需要一致性检查来进行保证。</p><p>一般情况下，Leader 和 Follower 的日志保持一致，然后，Leader 的崩溃会导致日志不一样，这样一致性检查会产生失败。Leader 通过强制 Follower 复制自己的日志来处理日志的不一致。这就意味着，在 Follower 上的冲突日志会被领导者的日志覆盖。</p><p>为了使得 Follower 的日志和自己的日志一致，Leader 需要找到 Follower 与它日志一致的地方，然后删除 Follower 在该位置之后的日志，接着把这之后的日志发送给 Follower。</p><p><code>Leader</code> 给每一个<code>Follower</code> 维护了一个 <code>nextIndex</code>，它表示 <code>Leader</code> 将要发送给该追随者的下一条日志条目的索引。当一个 <code>Leader</code> 开始掌权时，它会将 <code>nextIndex</code> 初始化为它的最新的日志条目索引数+1。如果一个 <code>Follower</code> 的日志和 <code>Leader</code> 的不一致，<code>AppendEntries</code> 一致性检查会在下一次 <code>AppendEntries RPC</code> 时返回失败。在失败之后，<code>Leader</code> 会将 <code>nextIndex</code> 递减然后重试 <code>AppendEntries RPC</code>。最终 <code>nextIndex</code> 会达到一个 <code>Leader</code> 和 <code>Follower</code> 日志一致的地方。这时，<code>AppendEntries</code> 会返回成功，<code>Follower</code> 中冲突的日志条目都被移除了，并且添加所缺少的上了 <code>Leader</code> 的日志条目。一旦 <code>AppendEntries</code> 返回成功，<code>Follower</code> 和 <code>Leader</code> 的日志就一致了，这样的状态会保持到该任期结束。</p><h2 id="5-安全性"><a href="#5-安全性" class="headerlink" title="# 5 安全性"></a><a href="#_5-%E5%AE%89%E5%85%A8%E6%80%A7">#</a> 5 安全性</h2><h3 id="5-1-选举限制"><a href="#5-1-选举限制" class="headerlink" title="# 5.1 选举限制"></a><a href="#_5-1-%E9%80%89%E4%B8%BE%E9%99%90%E5%88%B6">#</a> 5.1 选举限制</h3><p>Leader 需要保证自己存储全部已经提交的日志条目。这样才可以使日志条目只有一个流向：从 Leader 流向 Follower，Leader 永远不会覆盖已经存在的日志条目。</p><p>每个 Candidate 发送 RequestVoteRPC 时，都会带上最后一个 entry 的信息。所有节点收到投票信息时，会对该 entry 进行比较，如果发现自己的更新，则拒绝投票给该 Candidate。</p><p>判断日志新旧的方式：如果两个日志的 term 不同，term 大的更新；如果 term 相同，更长的 index 更新。</p><h3 id="5-2-节点崩溃"><a href="#5-2-节点崩溃" class="headerlink" title="# 5.2 节点崩溃"></a><a href="#_5-2-%E8%8A%82%E7%82%B9%E5%B4%A9%E6%BA%83">#</a> 5.2 节点崩溃</h3><p>如果 Leader 崩溃，集群中的节点在 electionTimeout 时间内没有收到 Leader 的心跳信息就会触发新一轮的选主，在选主期间整个集群对外是不可用的。</p><p>如果 Follower 和 Candidate 崩溃，处理方式会简单很多。之后发送给它的 RequestVoteRPC 和 AppendEntriesRPC 会失败。由于 raft 的所有请求都是幂等的，所以失败的话会无限的重试。如果崩溃恢复后，就可以收到新的请求，然后选择追加或者拒绝 entry。</p><h3 id="5-3-时间与可用性"><a href="#5-3-时间与可用性" class="headerlink" title="# 5.3 时间与可用性"></a><a href="#_5-3-%E6%97%B6%E9%97%B4%E4%B8%8E%E5%8F%AF%E7%94%A8%E6%80%A7">#</a> 5.3 时间与可用性</h3><p>raft 的要求之一就是安全性不依赖于时间：系统不能仅仅因为一些事件发生的比预想的快一些或者慢一些就产生错误。为了保证上述要求，最好能满足以下的时间条件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">broadcastTime &lt;&lt; electionTimeout &lt;&lt; MTBF</span><br></pre></td></tr></table></figure><ul><li><code>broadcastTime</code>：向其他节点并发发送消息的平均响应时间；</li><li><code>electionTimeout</code>：选举超时时间；</li><li><code>MTBF(mean time between failures)</code>：单台机器的平均健康时间；</li></ul><p><code>broadcastTime</code>应该比<code>electionTimeout</code>小一个数量级，为的是使<code>Leader</code>能够持续发送心跳信息（heartbeat）来阻止<code>Follower</code>开始选举；</p><p><code>electionTimeout</code>也要比<code>MTBF</code>小几个数量级，为的是使得系统稳定运行。当<code>Leader</code>崩溃时，大约会在整个<code>electionTimeout</code>的时间内不可用；我们希望这种情况仅占全部时间的很小一部分。</p><p>由于<code>broadcastTime</code>和<code>MTBF</code>是由系统决定的属性，因此需要决定<code>electionTimeout</code>的时间。</p><p>一般来说，broadcastTime 一般为 <code>0.5～20ms</code>，electionTimeout 可以设置为 <code>10～500ms</code>，MTBF 一般为一两个月。</p><h2 id="6-参考"><a href="#6-参考" class="headerlink" title="# 6 参考"></a><a href="#_6-%E5%8F%82%E8%80%83">#</a> 6 参考</h2><ul><li><a target="_blank" rel="noopener" href="https://tanxinyu.work/raft/">https://tanxinyu.work/raft/</a></li><li><a target="_blank" rel="noopener" href="https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn/blob/master/raft-thesis-zh_cn.md">https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn/blob/master/raft-thesis-zh_cn.md</a></li><li><a target="_blank" rel="noopener" href="https://github.com/ongardie/dissertation/blob/master/stanford.pdf">https://github.com/ongardie/dissertation/blob/master/stanford.pdf</a></li><li><a target="_blank" rel="noopener" href="https://knowledge-sharing.gitbooks.io/raft/content/chapter5.html">https://knowledge-sharing.gitbooks.io/raft/content/chapter5.html</a></li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2020/10/02/2020-01-10-redis-slave/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2020/10/02/2020-01-10-redis-slave/" class="post-title-link" itemprop="url">Redis高可用</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-10-02 13:30:00" itemprop="dateCreated datePublished" datetime="2020-10-02T13:30:00+08:00">2020-10-02</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="单机版Redis问题"><a href="#单机版Redis问题" class="headerlink" title="单机版Redis问题"></a>单机版Redis问题</h2><ul><li>机器故障需要做数据手动迁移</li><li>容量瓶颈</li><li>QPS瓶颈</li></ul><h2 id="引入正题"><a href="#引入正题" class="headerlink" title="引入正题"></a>引入正题</h2><p>前面列出的容量瓶颈和QPS瓶颈是redis分布式要解决的问题，本篇还是主要解决<br>redis怎么实现高可用，机器故障的问题</p><h2 id="主从复制介绍"><a href="#主从复制介绍" class="headerlink" title="主从复制介绍"></a>主从复制介绍</h2><p>作用：</p><ul><li>流量分流和负载均衡</li><li>提供多个数据分布</li><li>扩展redis读性能</li></ul><h3 id="简单总结"><a href="#简单总结" class="headerlink" title="简单总结"></a>简单总结</h3><ul><li>一个master可以有多个slave</li><li>一个slave只能有一个master</li><li>数据流向是单向的，master到slave</li></ul><h2 id="主从复制操作"><a href="#主从复制操作" class="headerlink" title="主从复制操作"></a>主从复制操作</h2><p>master节点:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp $&#123;redis_src&#125;/redis.conf redis-6379.conf</span><br><span class="line">vim redis-6379.conf</span><br></pre></td></tr></table></figure><p>改动项：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">daemonize yes</span><br><span class="line">pidfile /var/run/redis-6379.pid</span><br><span class="line">logfile &quot;6379.log&quot;</span><br><span class="line">logfile &quot;6379.log&quot;</span><br><span class="line">#save 900 1</span><br><span class="line">#save 300 10</span><br><span class="line">#save 60 10000</span><br><span class="line">dbfilename dump-6379.rdb</span><br><span class="line">dir /opt/soft/data</span><br></pre></td></tr></table></figure><p>slave节点:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp $&#123;redis_src&#125;/redis.conf redis-6380.conf</span><br><span class="line">vim redis-6380.conf</span><br></pre></td></tr></table></figure><p>改动项：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">daemonize yes</span><br><span class="line">pidfile /var/run/redis-6380.pid</span><br><span class="line">logfile &quot;6380.log&quot;</span><br><span class="line">logfile &quot;6380.log&quot;</span><br><span class="line">#save 900 1</span><br><span class="line">#save 300 10</span><br><span class="line">#save 60 10000</span><br><span class="line">dbfilename dump-6380.rdb</span><br><span class="line">dir /opt/soft/data</span><br><span class="line">salveof 127.0.0.1 6379  #master节点 ip port</span><br><span class="line">masterauth  #主节点设置密码时需要配置</span><br></pre></td></tr></table></figure><p>启动:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-server 6379.conf</span><br><span class="line">redis-server 6380.conf</span><br></pre></td></tr></table></figure><p>检查主从状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">redis-cli</span><br><span class="line">127.0.0.1:6379&gt; info replication</span><br><span class="line">127.0.0.1:6380&gt; info replication</span><br><span class="line">127.0.0.1:6379&gt; set hello world</span><br><span class="line">127.0.0.1:6380&gt; get hello</span><br></pre></td></tr></table></figure><h2 id="runid和复制偏移量"><a href="#runid和复制偏移量" class="headerlink" title="runid和复制偏移量"></a>runid和复制偏移量</h2><h3 id="runid"><a href="#runid" class="headerlink" title="runid"></a>runid</h3><p>redis每次启动后都会随机生成一个runid执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 6379 info server |grep run</span><br><span class="line">redis-cli -p 6380 info server |grep run</span><br></pre></td></tr></table></figure><blockquote><p>redis每次重启runid会发生变化，redis从节点每次会检测主节点runid变化来进行一次全量复制</p></blockquote><h3 id="偏移量"><a href="#偏移量" class="headerlink" title="偏移量"></a>偏移量</h3><p>主节点和从节点都会记录执行一条命令时数据写入的字节数，当偏移量达到一致时，数据才会同步完成</p><h2 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h2><p><img src="/img/in-post/2018-01-10/1.png"></p><p><strong>全量复制开销</strong></p><ul><li>bgsave时间</li><li>RDB文件网络传输时间</li><li>从节点清空数据时间</li><li>从节点加载RDB时间</li><li>如果配置AOF开启会有AOF重写时间</li></ul><h2 id="部分复制"><a href="#部分复制" class="headerlink" title="部分复制"></a>部分复制</h2><p><img src="/img/in-post/2018-01-10/2.png"></p><h2 id="开发运维中的问题"><a href="#开发运维中的问题" class="headerlink" title="开发运维中的问题"></a>开发运维中的问题</h2><p><strong>规避全量复制：</strong></p><p>1：第一次全量复制</p><ul><li>问题：第一次不可避免</li><li>解决：小主节点，低峰</li></ul><p>2：节点运行ID不匹配</p><ul><li>问题：主节点重启runid变化</li><li>解决：故障转移，例如哨兵或集群</li></ul><p>3：复制积压缓冲区不足</p><ul><li>问题：网络中断，部分复制无法满足</li><li>解决：增大复制缓冲区配置rel_backlog_size</li></ul><p><strong>规避复制风暴：</strong></p><p>1：单主节点复制风暴</p><ul><li>问题：主节点重启，多从节点复制</li><li>解决：更换复制拓扑(树形架构)</li></ul><p>1：单机器复制风暴</p><ul><li>问题：机器宕机后，大量全量复制</li><li>解决：主节点分散多机器</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2020/10/01/2020-01-08-redis/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2020/10/01/2020-01-08-redis/" class="post-title-link" itemprop="url">Redis持久化</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-10-01 13:30:00" itemprop="dateCreated datePublished" datetime="2020-10-01T13:30:00+08:00">2020-10-01</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>话不多说直奔主题…</p><h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><h3 id="主要触发机制"><a href="#主要触发机制" class="headerlink" title="主要触发机制"></a>主要触发机制</h3><h4 id="save"><a href="#save" class="headerlink" title="save"></a>save</h4><p><strong>cli命令:</strong> save</p><p><strong>文件策略：</strong> 如果存在老的RDB文件，新的将其替换掉</p><p><strong>时间复杂度：</strong> O(n)</p><p>我们把客户端和服务端用一个图来表示，save时会帮我们生成一个RDB文件<br><img src="/img/in-post/2019-01-08/1.png"></p><blockquote><p>由于它是同步命令，并且在单线程中执行,在数据量非常多的时候，此时执行save命令，他会将数据进行完整拷贝，可能会造成redis阻塞。</p></blockquote><h4 id="bgsave"><a href="#bgsave" class="headerlink" title="bgsave"></a>bgsave</h4><p><img src="/img/in-post/2019-01-08/2.png"></p><blockquote><p>通过在后台fork一个子进程完成复制</p></blockquote><h4 id="自动"><a href="#自动" class="headerlink" title="自动"></a>自动</h4><p>根据REDIS配置定时同步数据到RDB文件</p><table><tr><th>配置</th><th>Seconds</th><th>Changes</th></tr><tr><td>save</td><td>900</td><td>1</td></tr><tr><td>save</td><td>300</td><td>10</td></tr><tr><td>save</td><td>60</td><td>10000</td></tr></table><blockquote><p>eg:60秒中改变了10000次会发生备份RDB</p></blockquote><h4 id="触发机制-不容忽略的方式"><a href="#触发机制-不容忽略的方式" class="headerlink" title="触发机制-不容忽略的方式"></a>触发机制-不容忽略的方式</h4><ul><li>全量复制</li><li>Debug Reload</li><li>shutdown</li></ul><h3 id="save-or-bgsave"><a href="#save-or-bgsave" class="headerlink" title="save or bgsave ?"></a>save or bgsave ?</h3><table><tr><th>命令</th><th>save</th><th>bgsave</th></tr><tr><td>IO类型</td><td>同步</td><td>异步</td></tr><tr><td>阻塞</td><td>是</td><td>发生在fork时</td></tr><tr><td>复杂度</td><td>O(N)</td><td>O(N)</td></tr><tr><td>优点</td><td>不会消耗内存</td><td>不阻塞客户端命令</td></tr><tr><td>缺点</td><td>阻塞客户端命令</td><td>消耗内存</td></tr></table> ### 配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line">dir ./</span><br><span class="line">stop-writes-on-bgsave-error yes //bgsave出现问题会停止写入</span><br><span class="line">rdbcompression yes  //压缩模式</span><br><span class="line">rdbchecksum yes //对RDB进行校验和检验</span><br></pre></td></tr></table></figure> #### 最佳配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dbfilename dump-$&#123;port&#125;.rdb</span><br><span class="line">dir bigdiskpath //选择大的硬盘</span><br><span class="line">stop-writes-on-bgsave-error yes //bgsave出现问题会停止写入</span><br><span class="line">rdbcompression yes  //压缩模式</span><br><span class="line">rdbchecksum yes //对RDB进行校验和检验</span><br></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>RDB是Redis内存到硬盘的快照，用于持久化</li><li>save通常会阻塞Redis</li><li>bgsave不会阻塞Redis，但是会fork子进程</li><li>save自动配置满足其一就会被执行</li><li>有些触发机制不容忽视</li></ul><h3 id="RDB问题"><a href="#RDB问题" class="headerlink" title="RDB问题"></a>RDB问题</h3><p><strong>耗时耗性能</strong></p><blockquote><p>O(N)数据耗时<br><br>fork耗内存<br><br>Disk I&#x2F;O:IO性能</p></blockquote><p><strong>不可控丢失数据</strong></p><table><tr><th>时间戳</th><th>save</th></tr><tr><td>T1</td><td>执行多个命令</td></tr><tr><td>T2</td><td>满足RDB自动创建条件</td></tr><tr><td>T3</td><td>再次执行多条命令</td></tr><tr><td>T4</td><td>宕机</td></tr></table><blockquote><p>宕机会发生数据丢失</p></blockquote><h2 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h2><h3 id="三种策略"><a href="#三种策略" class="headerlink" title="三种策略"></a>三种策略</h3><h4 id="everysec"><a href="#everysec" class="headerlink" title="everysec"></a>everysec</h4><p><img src="/img/in-post/2019-01-08/4.png"></p><h4 id="always"><a href="#always" class="headerlink" title="always"></a>always</h4><p>同everysec流程，只不过always会把每条命令都写入到AOF文件中</p><h4 id="no"><a href="#no" class="headerlink" title="no"></a>no</h4><p>由操作系统来决定是否刷新</p><h4 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h4><table><tr><th>命令</th><th>always</th><th>everysec</th><th>no</th></tr><tr><td>优点</td><td>不丢失数据</td><td>每秒一次fsync丢1秒数据</td><td>不用管理</td></tr><tr><td>缺点</td><td>IO开销比较大</td><td>丢1秒数据</td><td>不可控</td></tr></table> ### AOF重写<h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><ul><li>减少硬盘占用量</li><li>加快回复速度</li></ul><h3 id="重写两种方式"><a href="#重写两种方式" class="headerlink" title="重写两种方式"></a>重写两种方式</h3><h4 id="bgrewriteaof"><a href="#bgrewriteaof" class="headerlink" title="bgrewriteaof"></a>bgrewriteaof</h4><p><strong>命令：bgrewriteaof</strong></p><p><img src="/img/in-post/2019-01-08/6.png"></p><p><strong>重写配置</strong></p><table><tr><th>配置名</th><th>含义</th></tr><tr><td>auto-aof-rewirte-min-size</td><td>auto-aof-rewirte-percentage</td></tr><tr><td>AOF文件重写尺寸</td><td>AOF文件增长率</td></tr></table> **统计**<table><tr><th>统计名</th><th>含义</th></tr><tr><td>auto-current-size</td><td>auto-base-size</td></tr><tr><td>AOF当前尺寸</td><td>AOF上次启动和重写的尺寸</td></tr></table> #### 自动触发时机<ul><li>auto-current-size &gt; auto-aof-rewirte-min-size</li><li>(auto-current-size - auto-base-size) &#x2F; auto-base-size &gt; auto-aof-rewirte-percentage</li></ul><h3 id="AOF重写流程"><a href="#AOF重写流程" class="headerlink" title="AOF重写流程"></a>AOF重写流程</h3><p><img src="/img/in-post/2019-01-08/8.jpg"></p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul><li>appendonly yes</li><li>appendfilename “appendonly-${port}.aof”</li><li>appendfsync everysec</li><li>dir &#x2F;bigdisk</li><li>no-appendfsync-on-rewrite no &#x2F;&#x2F;aof重写失败是否允许丢失数据</li><li>auto-aof-rewrite-percentage 100 &#x2F;&#x2F;增长率</li><li>auto-aof-rewrite-min-size 64mb &#x2F;&#x2F;最小尺寸</li></ul><h2 id="RDB-和-AOF-抉择"><a href="#RDB-和-AOF-抉择" class="headerlink" title="RDB 和 AOF 抉择"></a>RDB 和 AOF 抉择</h2><table><tr><th>命令</th><th>RDB</th><th>AOF</th></tr><tr><td>启动优先级</td><td>低</td><td>高</td></tr><tr><td>体积</td><td>小</td><td>大</td></tr><tr><td>恢复速度</td><td>快</td><td>慢</td></tr><tr><td>数据安全性</td><td>丢数据</td><td>根据策略决定</td></tr><tr><td>轻重</td><td>重</td><td>轻</td></tr></table></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2020/01/25/2020-01-25-redis-cluster-out/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2020/01/25/2020-01-25-redis-cluster-out/" class="post-title-link" itemprop="url">Redis cluster 故障转移</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-25 21:30:00" itemprop="dateCreated datePublished" datetime="2020-01-25T21:30:00+08:00">2020-01-25</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="故障发现"><a href="#故障发现" class="headerlink" title="故障发现"></a>故障发现</h2><p>通过ping&#x2F;pong消息实现故障发现，不依赖sentinel</p><h2 id="主观下线"><a href="#主观下线" class="headerlink" title="主观下线"></a>主观下线</h2><p>定义：某个节点认为另外一个节点不可用“偏见”</p><p>主观下线流程：<br><img src="/img/in-post/2019-01-25/1.png"></p><h2 id="客观下线"><a href="#客观下线" class="headerlink" title="客观下线"></a>客观下线</h2><p>定义：当半数以上持有槽的主节点都标记某节点主观下线</p><p>客观下线流程：<br><img src="/img/in-post/2019-01-25/2.png"></p><h2 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h2><h3 id="资格检查"><a href="#资格检查" class="headerlink" title="资格检查"></a>资格检查</h3><ul><li>每个从节点检查与故障节点的断线时间</li><li>超过cluster-node-timeout*cluster-slave-validity-factor取消资格</li><li>cluster-slave-validity-factor：默认为10</li></ul><h3 id="准备选举时间"><a href="#准备选举时间" class="headerlink" title="准备选举时间"></a>准备选举时间</h3><p><img src="/img/in-post/2019-01-25/3.png"></p><h3 id="选举投票"><a href="#选举投票" class="headerlink" title="选举投票"></a>选举投票</h3><p><img src="/img/in-post/2019-01-25/4.png"></p><h3 id="替换主节点"><a href="#替换主节点" class="headerlink" title="替换主节点"></a>替换主节点</h3><ul><li>当前从节点复制变为主节点。(slaveof no one)</li><li>执行clusterDelSlot撤销故障主节点负责的槽，并执行clusterAddSlot<br>把这些槽分配给自己</li><li>向群广播自己的pong消息，表明已替换了故障从节点</li></ul><h2 id="redis-cluster-开发常见问题"><a href="#redis-cluster-开发常见问题" class="headerlink" title="redis cluster 开发常见问题"></a>redis cluster 开发常见问题</h2><h3 id="集群完整性"><a href="#集群完整性" class="headerlink" title="集群完整性"></a>集群完整性</h3><p><code>cluster-require-full-coverage</code>默认为yes<br>问题：</p><ul><li>集群中16384个槽全部可用，保证完整性</li><li>节点故障转移或正在转移<br>大多数业务无法容忍，建议设置为no<blockquote><p>当其中一台机器发生故障，此时集群状态不可用，不可以set ket,不建议设置为yes</p></blockquote></li></ul><h3 id="宽带消耗"><a href="#宽带消耗" class="headerlink" title="宽带消耗"></a>宽带消耗</h3><p>官方建议：1000个节点</p><ul><li>消息频率 节点发现和节点最后通信时间超过cluster-node-timeout&#x2F;2时会发送ping消息</li><li>消息数据量 slots数据组(2k)和整个集群1&#x2F;10的状态数据(10个节点状态数据约1k)</li><li>节点部署机器规模 分布机器越多且每台机器划分的节点越均匀，整体的可用带宽越高<br>例子：200个节点，20个物理机器（每台10个节点）</li></ul><p>cluster-node-timeout&#x3D;15000 ping&#x2F;pong带宽约25MB</p><p>cluster-node-timeout&#x3D;20000 ping&#x2F;pong带低于15MB</p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><ul><li>避免多业务使用多集群，大业务可以多集群</li><li>cluster-node-timeout 带宽和故障转移速度的均衡</li><li>尽量均匀分配多个机器，保证带宽</li></ul><h3 id="PUB-x2F-SUB广播"><a href="#PUB-x2F-SUB广播" class="headerlink" title="PUB&#x2F;SUB广播"></a>PUB&#x2F;SUB广播</h3><p>问题：publish在集群每个节点广播：加重带宽<br>解决：单独走一套redis sentinel</p><h3 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h3><p><strong>数据倾斜：内存不均匀</strong></p><p><strong>节点和槽分配不均匀</strong></p><p><strong>不同槽对应键值数差异大</strong></p><ul><li>可能存在has_tag</li><li>cluster countkeysinslot {slot}获取槽对应键值个数</li></ul><p><strong>包含bigkey</strong></p><ul><li>例如大字符串，几百万元素的hash,set等</li><li>从节点，redis-cli –bigkeys</li><li>优化数据结构，拆分key</li></ul><p><strong>内存相关配置不一致</strong></p><ul><li>hash-max-ziplist-value, set-max-intset-entries等</li></ul><p><strong>请求倾斜：key热点</strong>重要的key或者bigkey<br>优化：</p><ul><li>避免big_key</li><li>热键不要使用hash_tag（避免落在一个节点）</li><li>当一致性不高时可以使用本地缓存+MQ</li></ul><h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>只读连接：集群模式的从节点不接受任何读写请求</p><ul><li>重定向到负责槽的主节点</li><li>readonly命令可以读：连接级的命令<br>读写分离：更加复杂</li><li>复制延迟，从节点故障，读取过期数据</li><li>修改客户端：cluster slaves {nodeid}</li></ul><h3 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h3><p>官方工具：redis-trib.rb import</p><ul><li>只能从单机迁移到集群</li><li>不支持在线迁移，source需要停写</li><li>不支持断点续传</li><li>单线程迁移，影响速度<br>在线迁移：</li></ul><p>唯品会：redis-migrate-tool</p><p>豌豆荚：redis-port</p><h3 id="集群VS单机"><a href="#集群VS单机" class="headerlink" title="集群VS单机"></a>集群VS单机</h3><p>集群限制<br></p><ul><li>key批量操作限制</li><li>key事物和lua支持有限，操作的key必须在同一个节点</li><li>key是数据分区的最小粒度：不支持bigkey分区</li><li>不支持多个数据库：集群模式下只有一个db0</li><li>复制只支持一层，不支持树形</li></ul><ol><li>Redis Cluster: 满足容量和性能的扩展性：很多业务不需要</li><li>很多场景Redis Sentinel足够好</li></ol></div><footer class="post-footer"><div class="post-eof"></div></footer></article><nav class="pagination"><a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="上一页"></i></a> <a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="下一页"></i></a></nav></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">enpsl</p><div class="site-description" itemprop="description">my blog</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">45</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">标签</span></a></div></nav></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">enpsl</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script></body></html>
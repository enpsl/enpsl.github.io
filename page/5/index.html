<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"enpsl.github.io",root:"/",scheme:"Muse",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!1,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="my blog"><meta property="og:type" content="website"><meta property="og:title" content="彭诗亮的博客"><meta property="og:url" content="https://enpsl.github.io/page/5/index.html"><meta property="og:site_name" content="彭诗亮的博客"><meta property="og:description" content="my blog"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="enpsl"><meta property="article:tag" content="彭诗亮 psl pengshiliang blog"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://enpsl.github.io/page/5/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!0,isPost:!1,lang:"zh-CN"}</script><title>彭诗亮的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">彭诗亮的博客</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li></ul></nav></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content index posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2021/02/15/2021-02-15-kafka%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2021/02/15/2021-02-15-kafka%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">Kafka面试问题总结</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-02-15 19:30:00" itemprop="dateCreated datePublished" datetime="2021-02-15T19:30:00+08:00">2021-02-15</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="1-Apache-Kafka是什么？"><a href="#1-Apache-Kafka是什么？" class="headerlink" title="1. Apache Kafka是什么？"></a>1. Apache Kafka是什么？</h2><p>Apach Kafka是一款分布式流处理平台，用于实时构建流处理应用。它有一个核心的功能广为人知，即作为企业级的消息引擎被广泛使用（通常也会称之为消息总线message bus）。</p><h2 id="2-Kafka-的设计是什么样的？"><a href="#2-Kafka-的设计是什么样的？" class="headerlink" title="2. Kafka 的设计是什么样的？"></a>2. Kafka 的设计是什么样的？</h2><p>Kafka 将消息以 topic 为单位进行归纳</p><p>将向 Kafka topic 发布消息的程序成为 producers.</p><p>将预订 topics 并消费消息的程序成为 consumer.</p><p>Kafka 以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个 broker.</p><p>producers 通过网络将消息发送到 Kafka 集群，集群向消费者提供消息</p><h2 id="3-Kafka-如何保证高可用？"><a href="#3-Kafka-如何保证高可用？" class="headerlink" title="3. Kafka 如何保证高可用？"></a>3. Kafka 如何保证高可用？</h2><p><code>Kafka</code> 的基本架构组成是：由多个 <code>broker</code> 组成一个集群，每个 <code>broker</code> 是一个节点；当创建一个 <code>topic</code> 时，这个 <code>topic</code> 会被划分为多个 <code>partition</code>，每个 <code>partition</code> 可以存在于不同的 <code>broker</code> 上，每个 <code>partition</code> 只存放一部分数据。</p><p>这就是<strong>天然的分布式消息队列</strong>，就是说一个 <code>topic</code> 的数据，是<strong>分散放在多个机器上的，每个机器就放一部分数据</strong>。</p><p>在 <code>Kafka 0.8</code> 版本之前，是没有 <code>HA</code> 机制的，当任何一个 <code>broker</code> 所在节点宕机了，这个 <code>broker</code> 上的 <code>partition</code> 就无法提供读写服务，所以这个版本之前，<code>Kafka</code> 没有什么高可用性可言。</p><p>在 <code>Kafka 0.8</code> 以后，提供了 <code>HA</code> 机制，就是 <code>replica</code> 副本机制。每个 <code>partition</code> 上的数据都会同步到其它机器，形成自己的多个 <code>replica</code> 副本。所有 <code>replica</code> 会选举一个 <code>leader</code> 出来，消息的生产者和消费者都跟这个 <code>leader</code> 打交道，其他 <code>replica</code> 作为 <code>follower</code>。写的时候，<code>leader</code> 会负责把数据同步到所有 <code>follower</code> 上去，读的时候就直接读 <code>leader</code> 上的数据即可。<code>Kafka</code> 负责均匀的将一个 <code>partition</code> 的所有 <code>replica</code> 分布在不同的机器上，这样才可以提高容错性。</p><p><img src="http://blog-img.coolsen.cn/img/Solve-MQ-Problem-With-Kafka-01.png" alt="img"></p><p>拥有了 <code>replica</code> 副本机制，如果某个 <code>broker</code> 宕机了，这个 <code>broker</code> 上的 <code>partition</code> 在其他机器上还存在副本。如果这个宕机的 <code>broker</code> 上面有某个 <code>partition</code> 的 <code>leader</code>，那么此时会从其 <code>follower</code> 中重新选举一个新的 <code>leader</code> 出来，这个新的 <code>leader</code> 会继续提供读写服务，这就有达到了所谓的高可用性。</p><p>写数据的时候，生产者只将数据写入 <code>leader</code> 节点，<code>leader</code> 会将数据写入本地磁盘，接着其他 <code>follower</code> 会主动从 <code>leader</code> 来拉取数据，<code>follower</code> 同步好数据了，就会发送 <code>ack</code> 给 <code>leader</code>，<code>leader</code> 收到所有 <code>follower</code> 的 <code>ack</code> 之后，就会返回写成功的消息给生产者。</p><p>消费数据的时候，消费者只会从 <code>leader</code> 节点去读取消息，但是只有当一个消息已经被所有 <code>follower</code> 都同步成功返回 <code>ack</code> 的时候，这个消息才会被消费者读到。</p><p><img src="https://gitee.com/dongzl/article-images/raw/master/2020/13-Solve-MQ-Problem-With-Kafka/Solve-MQ-Problem-With-Kafka-02.png" alt="img"></p><h2 id="4-Kafka-消息是采用-Pull-模式，还是-Push-模式？"><a href="#4-Kafka-消息是采用-Pull-模式，还是-Push-模式？" class="headerlink" title="4. Kafka 消息是采用 Pull 模式，还是 Push 模式？"></a>4. Kafka 消息是采用 Pull 模式，还是 Push 模式？</h2><p>生产者使用push模式将消息发布到Broker，消费者使用pull模式从Broker订阅消息。</p><p>push模式很难适应消费速率不同的消费者，如果push的速度太快，容易造成消费者拒绝服务或网络拥塞；如果push的速度太慢，容易造成消费者性能浪费。但是采用pull的方式也有一个缺点，就是当Broker没有消息时，消费者会陷入不断地轮询中，为了避免这点，kafka有个参数可以让消费者阻塞知道是否有新消息到达。</p><h2 id="5-Kafka-与传统消息系统之间的区别"><a href="#5-Kafka-与传统消息系统之间的区别" class="headerlink" title="5. Kafka 与传统消息系统之间的区别"></a>5. Kafka 与传统消息系统之间的区别</h2><ul><li><p>Kafka 持久化日志，这些日志可以被重复读取和无限期保留</p></li><li><p>Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性</p></li><li><p>Kafka 支持实时的流式处理</p></li></ul><h2 id="6-什么是消费者组？"><a href="#6-什么是消费者组？" class="headerlink" title="6. 什么是消费者组？"></a>6. 什么是消费者组？</h2><p>消费者组是Kafka独有的概念，即消费者组是Kafka提供的可扩展且具有容错性的消费者机制。</p><p>但实际上，消费者组（Consumer Group）其实包含两个概念，作为队列，消费者组允许你分割数据处理到一组进程集合上（即一个消费者组中可以包含多个消费者进程，他们共同消费该topic的数据），这有助于你的消费能力的动态调整；作为发布-订阅模型（publish-subscribe），Kafka允许你将同一份消息广播到多个消费者组里，以此来丰富多种数据使用场景。</p><p>需要注意的是：在消费者组中，多个实例共同订阅若干个主题，实现共同消费。同一个组下的每个实例都配置有相同的组ID，被分配不同的订阅分区。当某个实例挂掉的时候，其他实例会自动地承担起它负责消费的分区。 因此，消费者组在一定程度上也保证了消费者程序的高可用性。</p><p><a target="_blank" rel="noopener" href="http://dockone.io/uploads/article/20201024/7b359b7a1381541fbacf3ecf20dfb347.jpg"><img src="http://dockone.io/uploads/article/20201024/7b359b7a1381541fbacf3ecf20dfb347.jpg" alt="1.jpg"></a></p><h2 id="7-在Kafka中，ZooKeeper的作用是什么？"><a href="#7-在Kafka中，ZooKeeper的作用是什么？" class="headerlink" title="7. 在Kafka中，ZooKeeper的作用是什么？"></a>7. 在Kafka中，ZooKeeper的作用是什么？</h2><p>目前，Kafka使用ZooKeeper存放集群元数据、成员管理、Controller选举，以及其他一些管理类任务。之后，等KIP-500提案完成后，Kafka将完全不再依赖于ZooKeeper。</p><ul><li>“存放元数据”是指主题分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他 “人” 都要与它保持对齐。</li><li>“成员管理” 是指 Broker 节点的注册、注销以及属性变更，等等。</li><li>“Controller 选举” 是指选举集群 Controller，而其他管理类任务包括但不限于主题删除、参数配置等。</li></ul><p>KIP-500 思想，是使用社区自研的基于Raft的共识算法，替代ZooKeeper，实现Controller自选举。</p><h2 id="8-解释下Kafka中位移（offset）的作用"><a href="#8-解释下Kafka中位移（offset）的作用" class="headerlink" title="8. 解释下Kafka中位移（offset）的作用"></a>8. 解释下Kafka中位移（offset）的作用</h2><p>在Kafka中，每个主题分区下的每条消息都被赋予了一个唯一的ID数值，用于标识它在分区中的位置。这个ID数值，就被称为位移，或者叫偏移量。一旦消息被写入到分区日志，它的位移值将不能被修改。</p><h2 id="9-kafka-为什么那么快？"><a href="#9-kafka-为什么那么快？" class="headerlink" title="9. kafka 为什么那么快？"></a>9. kafka 为什么那么快？</h2><ul><li>Cache Filesystem Cache PageCache缓存</li><li><code>顺序写</code>：由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。</li><li><code>Zero-copy</code>：零拷技术减少拷贝次数</li><li><code>Batching of Messages</code>：批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。</li><li><code>Pull 拉模式</code>：使用拉模式进行消息的获取消费，与消费端处理能力相符。</li></ul><h2 id="10-kafka-producer发送数据，ack为0，1，-1分别是什么意思？"><a href="#10-kafka-producer发送数据，ack为0，1，-1分别是什么意思？" class="headerlink" title="10. kafka producer发送数据，ack为0，1，-1分别是什么意思？"></a>10. kafka producer发送数据，ack为0，1，-1分别是什么意思？</h2><ul><li><code>1</code>（默认） 数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。在这种情况下，如果leader宕机了，则会丢失数据。</li><li><code>0</code> 生产者将数据发送出去就不管了，不去等待任何返回。这种情况下数据传输效率最高，但是数据可靠性确是最低的。</li><li><code>-1</code>producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。当ISR中所有Replica都向Leader发送ACK时，leader才commit，这时候producer才能认为一个请求中的消息都commit了。</li></ul><h2 id="11-Kafka如何保证消息不丢失"><a href="#11-Kafka如何保证消息不丢失" class="headerlink" title="11. Kafka如何保证消息不丢失?"></a>11. Kafka如何保证消息不丢失?</h2><p>首先需要弄明白消息为什么会丢失，对于一个消息队列，会有 <code>生产者</code>、<code>MQ</code>、<code>消费者</code> 这三个角色，在这三个角色数据处理和传输过程中，都有可能会出现消息丢失。</p><p><img src="http://blog-img.coolsen.cn/img/Solve-MQ-Problem-With-Kafka-03.png" alt="img"></p><p>消息丢失的原因以及解决办法：</p><h3 id="消费者异常导致的消息丢失"><a href="#消费者异常导致的消息丢失" class="headerlink" title="消费者异常导致的消息丢失"></a>消费者异常导致的消息丢失</h3><p>消费者可能导致数据丢失的情况是：消费者获取到了这条消息后，还未处理，<code>Kafka</code> 就自动提交了 <code>offset</code>，这时 <code>Kafka</code> 就认为消费者已经处理完这条消息，其实消费者才刚准备处理这条消息，这时如果消费者宕机，那这条消息就丢失了。</p><p>消费者引起消息丢失的主要原因就是消息还未处理完 <code>Kafka</code> 会自动提交了 <code>offset</code>，那么只要关闭自动提交 <code>offset</code>，消费者在处理完之后手动提交 <code>offset</code>，就可以保证消息不会丢失。但是此时需要注意重复消费问题，比如消费者刚处理完，还没提交 <code>offset</code>，这时自己宕机了，此时这条消息肯定会被重复消费一次，这就需要消费者根据实际情况保证幂等性。</p><h3 id="生产者数据传输导致的消息丢失"><a href="#生产者数据传输导致的消息丢失" class="headerlink" title="生产者数据传输导致的消息丢失"></a>生产者数据传输导致的消息丢失</h3><p>对于生产者数据传输导致的数据丢失主常见情况是生产者发送消息给 <code>Kafka</code>，由于网络等原因导致消息丢失，对于这种情况也是通过在 <strong>producer</strong> 端设置 <strong>acks&#x3D;all</strong> 来处理，这个参数是要求 <code>leader</code> 接收到消息后，需要等到所有的 <code>follower</code> 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试。</p><h3 id="Kafka-导致的消息丢失"><a href="#Kafka-导致的消息丢失" class="headerlink" title="Kafka 导致的消息丢失"></a>Kafka 导致的消息丢失</h3><p><code>Kafka</code> 导致的数据丢失一个常见的场景就是 <code>Kafka</code> 某个 <code>broker</code> 宕机，，而这个节点正好是某个 <code>partition</code> 的 <code>leader</code> 节点，这时需要重新重新选举该 <code>partition</code> 的 <code>leader</code>。如果该 <code>partition</code> 的 <code>leader</code> 在宕机时刚好还有些数据没有同步到 <code>follower</code>，此时 <code>leader</code> 挂了，在选举某个 <code>follower</code> 成 <code>leader</code> 之后，就会丢失一部分数据。</p><p>对于这个问题，<code>Kafka</code> 可以设置如下 4 个参数，来尽量避免消息丢失：</p><ul><li>给 <code>topic</code> 设置 <code>replication.factor</code> 参数：这个值必须大于 <code>1</code>，要求每个 <code>partition</code> 必须有至少 <code>2</code> 个副本；</li><li>在 <code>Kafka</code> 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 <code>1</code>，这个参数的含义是一个 <code>leader</code> 至少感知到有至少一个 <code>follower</code> 还跟自己保持联系，没掉队，这样才能确保 <code>leader</code> 挂了还有一个 <code>follower</code> 节点。</li><li>在 <code>producer</code> 端设置 <code>acks=all</code>，这个是要求每条数据，必须是写入所有 <code>replica</code> 之后，才能认为是写成功了；</li><li>在 <code>producer</code> 端设置 <code>retries=MAX</code>（很大很大很大的一个值，无限次重试的意思）：这个参数的含义是一旦写入失败，就无限重试，卡在这里了。</li></ul><h2 id="13-Kafka-如何保证消息的顺序性"><a href="#13-Kafka-如何保证消息的顺序性" class="headerlink" title="13. Kafka 如何保证消息的顺序性"></a>13. Kafka 如何保证消息的顺序性</h2><p>在某些业务场景下，我们需要保证对于有逻辑关联的多条MQ消息被按顺序处理，比如对于某一条数据，正常处理顺序是<code>新增-更新-删除</code>，最终结果是数据被删除；如果消息没有按序消费，处理顺序可能是<code>删除-新增-更新</code>，最终数据没有被删掉，可能会产生一些逻辑错误。对于如何保证消息的顺序性，主要需要考虑如下两点：</p><ul><li>如何保证消息在 <code>Kafka</code> 中顺序性；</li><li>如何保证消费者处理消费的顺序性。</li></ul><h3 id="如何保证消息在-Kafka-中顺序性"><a href="#如何保证消息在-Kafka-中顺序性" class="headerlink" title="如何保证消息在 Kafka 中顺序性"></a>如何保证消息在 Kafka 中顺序性</h3><p>对于 <code>Kafka</code>，如果我们创建了一个 <code>topic</code>，默认有三个 <code>partition</code>。生产者在写数据的时候，可以指定一个 <code>key</code>，比如在订单 <code>topic</code> 中我们可以指定订单 <code>id</code> 作为 <code>key</code>，那么相同订单 <code>id</code> 的数据，一定会被分发到同一个 <code>partition</code> 中去，而且这个 <code>partition</code> 中的数据一定是有顺序的。消费者从 <code>partition</code> 中取出来数据的时候，也一定是有顺序的。通过制定 <code>key</code> 的方式首先可以保证在 <code>kafka</code> 内部消息是有序的。</p><h3 id="如何保证消费者处理消费的顺序性"><a href="#如何保证消费者处理消费的顺序性" class="headerlink" title="如何保证消费者处理消费的顺序性"></a>如何保证消费者处理消费的顺序性</h3><p>对于某个 <code>topic</code> 的一个 <code>partition</code>，只能被同组内部的一个 <code>consumer</code> 消费，如果这个 <code>consumer</code> 内部还是单线程处理，那么其实只要保证消息在 <code>MQ</code> 内部是有顺序的就可以保证消费也是有顺序的。但是单线程吞吐量太低，在处理大量 <code>MQ</code> 消息时，我们一般会开启多线程消费机制，那么如何保证消息在多个线程之间是被顺序处理的呢？对于多线程消费我们可以预先设置 <code>N</code> 个内存 <code>Queue</code>，具有相同 <code>key</code> 的数据都放到同一个内存 <code>Queue</code> 中；然后开启 <code>N</code> 个线程，每个线程分别消费一个内存 <code>Queue</code> 的数据即可，这样就能保证顺序性。当然，消息放到内存 <code>Queue</code> 中，有可能还未被处理，<code>consumer</code> 发生宕机，内存 <code>Queue</code> 中的数据会全部丢失，这就转变为上面提到的<strong>如何保证消息的可靠传输</strong>的问题了。</p><h2 id="14-Kafka中的ISR、AR代表什么？ISR的伸缩指什么？"><a href="#14-Kafka中的ISR、AR代表什么？ISR的伸缩指什么？" class="headerlink" title="14. Kafka中的ISR、AR代表什么？ISR的伸缩指什么？"></a>14. Kafka中的ISR、AR代表什么？ISR的伸缩指什么？</h2><ul><li><code>ISR</code>：In-Sync Replicas 副本同步队列</li><li><code>AR</code>:Assigned Replicas 所有副本</li></ul><p>ISR是由leader维护，follower从leader同步数据有一些延迟（包括<code>延迟时间replica.lag.time.max.ms</code>和<code>延迟条数replica.lag.max.messages</code>两个维度，当前最新的版本0.10.x中只支持<code>replica.lag.time.max.ms</code>这个维度），任意一个超过阈值都会把follower剔除出ISR，存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。</p><blockquote><p>AR&#x3D;ISR+OSR。</p></blockquote><h2 id="15-描述下-Kafka-中的领导者副本（Leader-Replica）和追随者副本（Follower-Replica）的区别"><a href="#15-描述下-Kafka-中的领导者副本（Leader-Replica）和追随者副本（Follower-Replica）的区别" class="headerlink" title="15. 描述下 Kafka 中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别"></a>15. 描述下 Kafka 中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别</h2><p>Kafka副本当前分为领导者副本和追随者副本。只有Leader副本才能对外提供读写服务，响应Clients端的请求。Follower副本只是采用拉（PULL）的方式，被动地同步Leader副本中的数据，并且在Leader副本所在的Broker宕机后，随时准备应聘Leader副本。</p><p>加分点：</p><ul><li>强调Follower副本也能对外提供读服务。自Kafka 2.4版本开始，社区通过引入新的Broker端参数，允许Follower副本有限度地提供读服务。</li><li>强调Leader和Follower的消息序列在实际场景中不一致。通常情况下，很多因素可能造成Leader和Follower之间的不同步，比如程序问题，网络问题，broker问题等，短暂的不同步我们可以关注（秒级别），但长时间的不同步可能就需要深入排查了，因为一旦Leader所在节点异常，可能直接影响可用性。</li></ul><p>注意：之前确保一致性的主要手段是高水位机制（HW），但高水位值无法保证Leader连续变更场景下的数据一致性，因此，社区引入了Leader Epoch机制，来修复高水位值的弊端。</p><h2 id="16-分区Leader选举策略有几种？"><a href="#16-分区Leader选举策略有几种？" class="headerlink" title="16. 分区Leader选举策略有几种？"></a>16. 分区Leader选举策略有几种？</h2><p>分区的Leader副本选举对用户是完全透明的，它是由Controller独立完成的。你需要回答的是，在哪些场景下，需要执行分区Leader选举。每一种场景对应于一种选举策略。</p><ul><li>OfflinePartition Leader选举：每当有分区上线时，就需要执行Leader选举。所谓的分区上线，可能是创建了新分区，也可能是之前的下线分区重新上线。这是最常见的分区Leader选举场景。</li><li>ReassignPartition Leader选举：当你手动运行kafka-reassign-partitions命令，或者是调用Admin的alterPartitionReassignments方法执行分区副本重分配时，可能触发此类选举。假设原来的AR是[1，2，3]，Leader是1，当执行副本重分配后，副本集合AR被设置成[4，5，6]，显然，Leader必须要变更，此时会发生Reassign Partition Leader选举。</li><li>PreferredReplicaPartition Leader选举：当你手动运行kafka-preferred-replica-election命令，或自动触发了Preferred Leader选举时，该类策略被激活。所谓的Preferred Leader，指的是AR中的第一个副本。比如AR是[3，2，1]，那么，Preferred Leader就是3。</li><li>ControlledShutdownPartition Leader选举：当Broker正常关闭时，该Broker上的所有Leader副本都会下线，因此，需要为受影响的分区执行相应的Leader选举。</li></ul><p>这4类选举策略的大致思想是类似的，即从AR中挑选首个在ISR中的副本，作为新Leader。</p><h2 id="17-Kafka的哪些场景中使用了零拷贝（Zero-Copy）？"><a href="#17-Kafka的哪些场景中使用了零拷贝（Zero-Copy）？" class="headerlink" title="17. Kafka的哪些场景中使用了零拷贝（Zero Copy）？"></a>17. Kafka的哪些场景中使用了零拷贝（Zero Copy）？</h2><p>在Kafka中，体现Zero Copy使用场景的地方有两处：基于mmap的索引和日志文件读写所用的TransportLayer。</p><p>先说第一个。索引都是基于MappedByteBuffer的，也就是让用户态和内核态共享内核态的数据缓冲区，此时，数据不需要复制到用户态空间。不过，mmap虽然避免了不必要的拷贝，但不一定就能保证很高的性能。在不同的操作系统下，mmap的创建和销毁成本可能是不一样的。很高的创建和销毁开销会抵消Zero Copy带来的性能优势。由于这种不确定性，在Kafka中，只有索引应用了mmap，最核心的日志并未使用mmap机制。</p><p>再说第二个。TransportLayer是Kafka传输层的接口。它的某个实现类使用了FileChannel的transferTo方法。该方法底层使用sendfile实现了Zero Copy。对Kafka而言，如果I&#x2F;O通道使用普通的PLAINTEXT，那么，Kafka就可以利用Zero Copy特性，直接将页缓存中的数据发送到网卡的Buffer中，避免中间的多次拷贝。相反，如果I&#x2F;O通道启用了SSL，那么，Kafka便无法利用Zero Copy特性了。</p><h2 id="18-为什么Kafka不支持读写分离？"><a href="#18-为什么Kafka不支持读写分离？" class="headerlink" title="18. 为什么Kafka不支持读写分离？"></a>18. 为什么Kafka不支持读写分离？</h2><p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。</p><p>Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:</p><ul><li><strong>数据一致性问题</strong>。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。</li><li><strong>延时问题</strong>。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历<code>网络→主节点内存→网络→从节点内存</code>这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历<code>网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘</code>这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="http://dockone.io/article/10853">http://dockone.io/article/10853</a></p><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000023716306">https://segmentfault.com/a/1190000023716306</a></p><p><a target="_blank" rel="noopener" href="https://dongzl.github.io/2020/03/16/13-Solve-MQ-Problem-With-Kafka/index.html">https://dongzl.github.io/2020/03/16/13-Solve-MQ-Problem-With-Kafka/index.html</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2021/01/16/2021-01-16-RAFT%E7%AE%97%E6%B3%95/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2021/01/16/2021-01-16-RAFT%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">RAFT算法</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-01-16 19:30:00" itemprop="dateCreated datePublished" datetime="2021-01-16T19:30:00+08:00">2021-01-16</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>当今的数据中心和应用程序在高度动态的环境中运行，为了应对高度动态的环境，它们通过额外的服务器进行横向扩展，并且根据需求进行扩展和收缩。同时，服务器和网络故障也很常见。</p><p>因此，系统必须在正常操作期间处理服务器的上下线。它们必须对变故做出反应并在几秒钟内自动适应；对客户来说的话，明显的中断通常是不可接受的。</p><p>幸运的是，分布式共识可以帮助应对这些挑战。</p><h3 id="1-1-拜占庭将军"><a href="#1-1-拜占庭将军" class="headerlink" title="# 1.1 拜占庭将军"></a><a href="#_1-1-%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B">#</a> 1.1 拜占庭将军</h3><p>在介绍共识算法之前，先介绍一个简化版拜占庭将军的例子来帮助理解共识算法。</p><blockquote><p>假设多位拜占庭将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成是否要进攻的一致性决定？</p></blockquote><p>解决方案大致可以理解成：先在所有的将军中选出一个大将军，用来做出所有的决定。</p><p>举例如下：假如现在一共有 3 个将军 A，B 和 C，每个将军都有一个随机时间的倒计时器，倒计时一结束，这个将军就把自己当成大将军候选人，然后派信使传递选举投票的信息给将军 B 和 C，如果将军 B 和 C 还没有把自己当作候选人（自己的倒计时还没有结束），并且没有把选举票投给其他人，它们就会把票投给将军 A，信使回到将军 A 时，将军 A 知道自己收到了足够的票数，成为大将军。在有了大将军之后，是否需要进攻就由大将军 A 决定，然后再去派信使通知另外两个将军，自己已经成为了大将军。如果一段时间还没收到将军 B 和 C 的回复（信使可能会被暗杀），那就再重派一个信使，直到收到回复。</p><h3 id="1-2-共识算法"><a href="#1-2-共识算法" class="headerlink" title="# 1.2 共识算法"></a><a href="#_1-2-%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95">#</a> 1.2 共识算法</h3><p>共识是可容错系统中的一个基本问题：即使面对故障，服务器也可以在共享状态上达成一致。</p><p>共识算法允许一组节点像一个整体一样一起工作，即使其中的一些节点出现故障也能够继续工作下去，其正确性主要是源于复制状态机的性质：一组<code>Server</code>的状态机计算相同状态的副本，即使有一部分的<code>Server</code>宕机了它们仍然能够继续运行。</p><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/paxos-rsm-architecture.png" alt="rsm-architecture.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图-1 复制状态机架构</span><br></pre></td></tr></table></figure><p>一般通过使用复制日志来实现复制状态机。每个<code>Server</code>存储着一份包括命令序列的日志文件，状态机会按顺序执行这些命令。因为每个日志包含相同的命令，并且顺序也相同，所以每个状态机处理相同的命令序列。由于状态机是确定性的，所以处理相同的状态，得到相同的输出。</p><p>因此共识算法的工作就是保持复制日志的一致性。服务器上的共识模块从客户端接收命令并将它们添加到日志中。它与其他服务器上的共识模块通信，以确保即使某些服务器发生故障。每个日志最终包含相同顺序的请求。一旦命令被正确地复制，它们就被称为已提交。每个服务器的状态机按照日志顺序处理已提交的命令，并将输出返回给客户端，因此，这些服务器形成了一个单一的、高度可靠的状态机。</p><p>适用于实际系统的共识算法通常具有以下特性：</p><ul><li>安全。确保在非拜占庭条件（也就是上文中提到的简易版拜占庭）下的安全性，包括网络延迟、分区、包丢失、复制和重新排序。</li><li>高可用。只要大多数服务器都是可操作的，并且可以相互通信，也可以与客户端进行通信，那么这些服务器就可以看作完全功能可用的。因此，一个典型的由五台服务器组成的集群可以容忍任何两台服务器端故障。假设服务器因停止而发生故障；它们稍后可能会从稳定存储上的状态中恢复并重新加入集群。</li><li>一致性不依赖时序。错误的时钟和极端的消息延迟，在最坏的情况下也只会造成可用性问题，而不会产生一致性问题。</li><li>在集群中大多数服务器响应，命令就可以完成，不会被少数运行缓慢的服务器来影响整体系统性能。</li></ul><h2 id="2-基础"><a href="#2-基础" class="headerlink" title="# 2 基础"></a><a href="#_2-%E5%9F%BA%E7%A1%80">#</a> 2 基础</h2><h3 id="2-1-节点类型"><a href="#2-1-节点类型" class="headerlink" title="# 2.1 节点类型"></a><a href="#_2-1-%E8%8A%82%E7%82%B9%E7%B1%BB%E5%9E%8B">#</a> 2.1 节点类型</h3><p>一个 Raft 集群包括若干服务器，以典型的 5 服务器集群举例。在任意的时间，每个服务器一定会处于以下三个状态中的一个：</p><ul><li><code>Leader</code>：负责发起心跳，响应客户端，创建日志，同步日志。</li><li><code>Candidate</code>：Leader 选举过程中的临时角色，由 Follower 转化而来，发起投票参与竞选。</li><li><code>Follower</code>：接受 Leader 的心跳和日志同步数据，投票给 Candidate。</li></ul><p>在正常的情况下，只有一个服务器是 Leader，剩下的服务器是 Follower。Follower 是被动的，它们不会发送任何请求，只是响应来自 Leader 和 Candidate 的请求。</p><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/paxos-server-state.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图-2：服务器的状态</span><br></pre></td></tr></table></figure><h3 id="2-2-任期"><a href="#2-2-任期" class="headerlink" title="# 2.2 任期"></a><a href="#_2-2-%E4%BB%BB%E6%9C%9F">#</a> 2.2 任期</h3><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/paxos-term.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图-3：任期</span><br></pre></td></tr></table></figure><p>如图 3 所示，raft 算法将时间划分为任意长度的任期（term），任期用连续的数字表示，看作当前 term 号。每一个任期的开始都是一次选举，在选举开始时，一个或多个 Candidate 会尝试成为 Leader。如果一个 Candidate 赢得了选举，它就会在该任期内担任 Leader。如果没有选出 Leader，将会开启另一个任期，并立刻开始下一次选举。raft 算法保证在给定的一个任期最少要有一个 Leader。</p><p>每个节点都会存储当前的 term 号，当服务器之间进行通信时会交换当前的 term 号；如果有服务器发现自己的 term 号比其他人小，那么他会更新到较大的 term 值。如果一个 Candidate 或者 Leader 发现自己的 term 过期了，他会立即退回成 Follower。如果一台服务器收到的请求的 term 号是过期的，那么它会拒绝此次请求。</p><h3 id="2-3-日志"><a href="#2-3-日志" class="headerlink" title="# 2.3 日志"></a><a href="#_2-3-%E6%97%A5%E5%BF%97">#</a> 2.3 日志</h3><ul><li><code>entry</code>：每一个事件成为 entry，只有 Leader 可以创建 entry。entry 的内容为<code>&lt;term,index,cmd&gt;</code>其中 cmd 是可以应用到状态机的操作。</li><li><code>log</code>：由 entry 构成的数组，每一个 entry 都有一个表明自己在 log 中的 index。只有 Leader 才可以改变其他节点的 log。entry 总是先被 Leader 添加到自己的 log 数组中，然后再发起共识请求，获得同意后才会被 Leader 提交给状态机。Follower 只能从 Leader 获取新日志和当前的 commitIndex，然后把对应的 entry 应用到自己的状态机中。</li></ul><h2 id="3-领导人选举"><a href="#3-领导人选举" class="headerlink" title="# 3 领导人选举"></a><a href="#_3-%E9%A2%86%E5%AF%BC%E4%BA%BA%E9%80%89%E4%B8%BE">#</a> 3 领导人选举</h2><p>raft 使用心跳机制来触发 Leader 的选举。</p><p>如果一台服务器能够收到来自 Leader 或者 Candidate 的有效信息，那么它会一直保持为 Follower 状态，并且刷新自己的 electionElapsed，重新计时。</p><p>Leader 会向所有的 Follower 周期性发送心跳来保证自己的 Leader 地位。如果一个 Follower 在一个周期内没有收到心跳信息，就叫做选举超时，然后它就会认为此时没有可用的 Leader，并且开始进行一次选举以选出一个新的 Leader。</p><p>为了开始新的选举，Follower 会自增自己的 term 号并且转换状态为 Candidate。然后他会向所有节点发起 RequestVoteRPC 请求， Candidate 的状态会持续到以下情况发生：</p><ul><li>赢得选举</li><li>其他节点赢得选举</li><li>一轮选举结束，无人胜出</li></ul><p>赢得选举的条件是：一个 Candidate 在一个任期内收到了来自集群内的多数选票<code>（N/2+1）</code>，就可以成为 Leader。</p><p>在 Candidate 等待选票的时候，它可能收到其他节点声明自己是 Leader 的心跳，此时有两种情况：</p><ul><li>该 Leader 的 term 号大于等于自己的 term 号，说明对方已经成为 Leader，则自己回退为 Follower。</li><li>该 Leader 的 term 号小于自己的 term 号，那么会拒绝该请求并让该节点更新 term。</li></ul><p>由于可能同一时刻出现多个 Candidate，导致没有 Candidate 获得大多数选票，如果没有其他手段来重新分配选票的话，那么可能会无限重复下去。</p><p>raft 使用了随机的选举超时时间来避免上述情况。每一个 Candidate 在发起选举后，都会随机化一个新的枚举超时时间，这种机制使得各个服务器能够分散开来，在大多数情况下只有一个服务器会率先超时；它会在其他服务器超时之前赢得选举。</p><h2 id="4-日志复制"><a href="#4-日志复制" class="headerlink" title="# 4 日志复制"></a><a href="#_4-%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6">#</a> 4 日志复制</h2><p>一旦选出了 Leader，它就开始接受客户端的请求。每一个客户端的请求都包含一条需要被复制状态机（<code>Replicated State Mechine</code>）执行的命令。</p><p>Leader 收到客户端请求后，会生成一个 entry，包含<code>&lt;index,term,cmd&gt;</code>，再将这个 entry 添加到自己的日志末尾后，向所有的节点广播该 entry，要求其他服务器复制这条 entry。</p><p>如果 Follower 接受该 entry，则会将 entry 添加到自己的日志后面，同时返回给 Leader 同意。</p><p>如果 Leader 收到了多数的成功响应，Leader 会将这个 entry 应用到自己的状态机中，之后可以成为这个 entry 是 committed 的，并且向客户端返回执行结果。</p><p>raft 保证以下两个性质：</p><ul><li>在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们一定有相同的 cmd</li><li>在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们前面的 entry 也一定相同</li></ul><p>通过“仅有 Leader 可以生存 entry”来保证第一个性质，第二个性质需要一致性检查来进行保证。</p><p>一般情况下，Leader 和 Follower 的日志保持一致，然后，Leader 的崩溃会导致日志不一样，这样一致性检查会产生失败。Leader 通过强制 Follower 复制自己的日志来处理日志的不一致。这就意味着，在 Follower 上的冲突日志会被领导者的日志覆盖。</p><p>为了使得 Follower 的日志和自己的日志一致，Leader 需要找到 Follower 与它日志一致的地方，然后删除 Follower 在该位置之后的日志，接着把这之后的日志发送给 Follower。</p><p><code>Leader</code> 给每一个<code>Follower</code> 维护了一个 <code>nextIndex</code>，它表示 <code>Leader</code> 将要发送给该追随者的下一条日志条目的索引。当一个 <code>Leader</code> 开始掌权时，它会将 <code>nextIndex</code> 初始化为它的最新的日志条目索引数+1。如果一个 <code>Follower</code> 的日志和 <code>Leader</code> 的不一致，<code>AppendEntries</code> 一致性检查会在下一次 <code>AppendEntries RPC</code> 时返回失败。在失败之后，<code>Leader</code> 会将 <code>nextIndex</code> 递减然后重试 <code>AppendEntries RPC</code>。最终 <code>nextIndex</code> 会达到一个 <code>Leader</code> 和 <code>Follower</code> 日志一致的地方。这时，<code>AppendEntries</code> 会返回成功，<code>Follower</code> 中冲突的日志条目都被移除了，并且添加所缺少的上了 <code>Leader</code> 的日志条目。一旦 <code>AppendEntries</code> 返回成功，<code>Follower</code> 和 <code>Leader</code> 的日志就一致了，这样的状态会保持到该任期结束。</p><h2 id="5-安全性"><a href="#5-安全性" class="headerlink" title="# 5 安全性"></a><a href="#_5-%E5%AE%89%E5%85%A8%E6%80%A7">#</a> 5 安全性</h2><h3 id="5-1-选举限制"><a href="#5-1-选举限制" class="headerlink" title="# 5.1 选举限制"></a><a href="#_5-1-%E9%80%89%E4%B8%BE%E9%99%90%E5%88%B6">#</a> 5.1 选举限制</h3><p>Leader 需要保证自己存储全部已经提交的日志条目。这样才可以使日志条目只有一个流向：从 Leader 流向 Follower，Leader 永远不会覆盖已经存在的日志条目。</p><p>每个 Candidate 发送 RequestVoteRPC 时，都会带上最后一个 entry 的信息。所有节点收到投票信息时，会对该 entry 进行比较，如果发现自己的更新，则拒绝投票给该 Candidate。</p><p>判断日志新旧的方式：如果两个日志的 term 不同，term 大的更新；如果 term 相同，更长的 index 更新。</p><h3 id="5-2-节点崩溃"><a href="#5-2-节点崩溃" class="headerlink" title="# 5.2 节点崩溃"></a><a href="#_5-2-%E8%8A%82%E7%82%B9%E5%B4%A9%E6%BA%83">#</a> 5.2 节点崩溃</h3><p>如果 Leader 崩溃，集群中的节点在 electionTimeout 时间内没有收到 Leader 的心跳信息就会触发新一轮的选主，在选主期间整个集群对外是不可用的。</p><p>如果 Follower 和 Candidate 崩溃，处理方式会简单很多。之后发送给它的 RequestVoteRPC 和 AppendEntriesRPC 会失败。由于 raft 的所有请求都是幂等的，所以失败的话会无限的重试。如果崩溃恢复后，就可以收到新的请求，然后选择追加或者拒绝 entry。</p><h3 id="5-3-时间与可用性"><a href="#5-3-时间与可用性" class="headerlink" title="# 5.3 时间与可用性"></a><a href="#_5-3-%E6%97%B6%E9%97%B4%E4%B8%8E%E5%8F%AF%E7%94%A8%E6%80%A7">#</a> 5.3 时间与可用性</h3><p>raft 的要求之一就是安全性不依赖于时间：系统不能仅仅因为一些事件发生的比预想的快一些或者慢一些就产生错误。为了保证上述要求，最好能满足以下的时间条件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">broadcastTime &lt;&lt; electionTimeout &lt;&lt; MTBF</span><br></pre></td></tr></table></figure><ul><li><code>broadcastTime</code>：向其他节点并发发送消息的平均响应时间；</li><li><code>electionTimeout</code>：选举超时时间；</li><li><code>MTBF(mean time between failures)</code>：单台机器的平均健康时间；</li></ul><p><code>broadcastTime</code>应该比<code>electionTimeout</code>小一个数量级，为的是使<code>Leader</code>能够持续发送心跳信息（heartbeat）来阻止<code>Follower</code>开始选举；</p><p><code>electionTimeout</code>也要比<code>MTBF</code>小几个数量级，为的是使得系统稳定运行。当<code>Leader</code>崩溃时，大约会在整个<code>electionTimeout</code>的时间内不可用；我们希望这种情况仅占全部时间的很小一部分。</p><p>由于<code>broadcastTime</code>和<code>MTBF</code>是由系统决定的属性，因此需要决定<code>electionTimeout</code>的时间。</p><p>一般来说，broadcastTime 一般为 <code>0.5～20ms</code>，electionTimeout 可以设置为 <code>10～500ms</code>，MTBF 一般为一两个月。</p><h2 id="6-参考"><a href="#6-参考" class="headerlink" title="# 6 参考"></a><a href="#_6-%E5%8F%82%E8%80%83">#</a> 6 参考</h2><ul><li><a target="_blank" rel="noopener" href="https://tanxinyu.work/raft/">https://tanxinyu.work/raft/</a></li><li><a target="_blank" rel="noopener" href="https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn/blob/master/raft-thesis-zh_cn.md">https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn/blob/master/raft-thesis-zh_cn.md</a></li><li><a target="_blank" rel="noopener" href="https://github.com/ongardie/dissertation/blob/master/stanford.pdf">https://github.com/ongardie/dissertation/blob/master/stanford.pdf</a></li><li><a target="_blank" rel="noopener" href="https://knowledge-sharing.gitbooks.io/raft/content/chapter5.html">https://knowledge-sharing.gitbooks.io/raft/content/chapter5.html</a></li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2020/10/02/2020-01-10-redis-slave/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2020/10/02/2020-01-10-redis-slave/" class="post-title-link" itemprop="url">Redis高可用</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-10-02 13:30:00" itemprop="dateCreated datePublished" datetime="2020-10-02T13:30:00+08:00">2020-10-02</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="单机版Redis问题"><a href="#单机版Redis问题" class="headerlink" title="单机版Redis问题"></a>单机版Redis问题</h2><ul><li>机器故障需要做数据手动迁移</li><li>容量瓶颈</li><li>QPS瓶颈</li></ul><h2 id="引入正题"><a href="#引入正题" class="headerlink" title="引入正题"></a>引入正题</h2><p>前面列出的容量瓶颈和QPS瓶颈是redis分布式要解决的问题，本篇还是主要解决<br>redis怎么实现高可用，机器故障的问题</p><h2 id="主从复制介绍"><a href="#主从复制介绍" class="headerlink" title="主从复制介绍"></a>主从复制介绍</h2><p>作用：</p><ul><li>流量分流和负载均衡</li><li>提供多个数据分布</li><li>扩展redis读性能</li></ul><h3 id="简单总结"><a href="#简单总结" class="headerlink" title="简单总结"></a>简单总结</h3><ul><li>一个master可以有多个slave</li><li>一个slave只能有一个master</li><li>数据流向是单向的，master到slave</li></ul><h2 id="主从复制操作"><a href="#主从复制操作" class="headerlink" title="主从复制操作"></a>主从复制操作</h2><p>master节点:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp $&#123;redis_src&#125;/redis.conf redis-6379.conf</span><br><span class="line">vim redis-6379.conf</span><br></pre></td></tr></table></figure><p>改动项：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">daemonize yes</span><br><span class="line">pidfile /var/run/redis-6379.pid</span><br><span class="line">logfile &quot;6379.log&quot;</span><br><span class="line">logfile &quot;6379.log&quot;</span><br><span class="line">#save 900 1</span><br><span class="line">#save 300 10</span><br><span class="line">#save 60 10000</span><br><span class="line">dbfilename dump-6379.rdb</span><br><span class="line">dir /opt/soft/data</span><br></pre></td></tr></table></figure><p>slave节点:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp $&#123;redis_src&#125;/redis.conf redis-6380.conf</span><br><span class="line">vim redis-6380.conf</span><br></pre></td></tr></table></figure><p>改动项：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">daemonize yes</span><br><span class="line">pidfile /var/run/redis-6380.pid</span><br><span class="line">logfile &quot;6380.log&quot;</span><br><span class="line">logfile &quot;6380.log&quot;</span><br><span class="line">#save 900 1</span><br><span class="line">#save 300 10</span><br><span class="line">#save 60 10000</span><br><span class="line">dbfilename dump-6380.rdb</span><br><span class="line">dir /opt/soft/data</span><br><span class="line">salveof 127.0.0.1 6379  #master节点 ip port</span><br><span class="line">masterauth  #主节点设置密码时需要配置</span><br></pre></td></tr></table></figure><p>启动:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-server 6379.conf</span><br><span class="line">redis-server 6380.conf</span><br></pre></td></tr></table></figure><p>检查主从状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">redis-cli</span><br><span class="line">127.0.0.1:6379&gt; info replication</span><br><span class="line">127.0.0.1:6380&gt; info replication</span><br><span class="line">127.0.0.1:6379&gt; set hello world</span><br><span class="line">127.0.0.1:6380&gt; get hello</span><br></pre></td></tr></table></figure><h2 id="runid和复制偏移量"><a href="#runid和复制偏移量" class="headerlink" title="runid和复制偏移量"></a>runid和复制偏移量</h2><h3 id="runid"><a href="#runid" class="headerlink" title="runid"></a>runid</h3><p>redis每次启动后都会随机生成一个runid执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 6379 info server |grep run</span><br><span class="line">redis-cli -p 6380 info server |grep run</span><br></pre></td></tr></table></figure><blockquote><p>redis每次重启runid会发生变化，redis从节点每次会检测主节点runid变化来进行一次全量复制</p></blockquote><h3 id="偏移量"><a href="#偏移量" class="headerlink" title="偏移量"></a>偏移量</h3><p>主节点和从节点都会记录执行一条命令时数据写入的字节数，当偏移量达到一致时，数据才会同步完成</p><h2 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h2><p><img src="/img/in-post/2018-01-10/1.png"></p><p><strong>全量复制开销</strong></p><ul><li>bgsave时间</li><li>RDB文件网络传输时间</li><li>从节点清空数据时间</li><li>从节点加载RDB时间</li><li>如果配置AOF开启会有AOF重写时间</li></ul><h2 id="部分复制"><a href="#部分复制" class="headerlink" title="部分复制"></a>部分复制</h2><p><img src="/img/in-post/2018-01-10/2.png"></p><h2 id="开发运维中的问题"><a href="#开发运维中的问题" class="headerlink" title="开发运维中的问题"></a>开发运维中的问题</h2><p><strong>规避全量复制：</strong></p><p>1：第一次全量复制</p><ul><li>问题：第一次不可避免</li><li>解决：小主节点，低峰</li></ul><p>2：节点运行ID不匹配</p><ul><li>问题：主节点重启runid变化</li><li>解决：故障转移，例如哨兵或集群</li></ul><p>3：复制积压缓冲区不足</p><ul><li>问题：网络中断，部分复制无法满足</li><li>解决：增大复制缓冲区配置rel_backlog_size</li></ul><p><strong>规避复制风暴：</strong></p><p>1：单主节点复制风暴</p><ul><li>问题：主节点重启，多从节点复制</li><li>解决：更换复制拓扑(树形架构)</li></ul><p>1：单机器复制风暴</p><ul><li>问题：机器宕机后，大量全量复制</li><li>解决：主节点分散多机器</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2020/10/01/2020-01-08-redis/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2020/10/01/2020-01-08-redis/" class="post-title-link" itemprop="url">Redis持久化</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-10-01 13:30:00" itemprop="dateCreated datePublished" datetime="2020-10-01T13:30:00+08:00">2020-10-01</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>话不多说直奔主题…</p><h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><h3 id="主要触发机制"><a href="#主要触发机制" class="headerlink" title="主要触发机制"></a>主要触发机制</h3><h4 id="save"><a href="#save" class="headerlink" title="save"></a>save</h4><p><strong>cli命令:</strong> save</p><p><strong>文件策略：</strong> 如果存在老的RDB文件，新的将其替换掉</p><p><strong>时间复杂度：</strong> O(n)</p><p>我们把客户端和服务端用一个图来表示，save时会帮我们生成一个RDB文件<br><img src="/img/in-post/2019-01-08/1.png"></p><blockquote><p>由于它是同步命令，并且在单线程中执行,在数据量非常多的时候，此时执行save命令，他会将数据进行完整拷贝，可能会造成redis阻塞。</p></blockquote><h4 id="bgsave"><a href="#bgsave" class="headerlink" title="bgsave"></a>bgsave</h4><p><img src="/img/in-post/2019-01-08/2.png"></p><blockquote><p>通过在后台fork一个子进程完成复制</p></blockquote><h4 id="自动"><a href="#自动" class="headerlink" title="自动"></a>自动</h4><p>根据REDIS配置定时同步数据到RDB文件</p><table><tr><th>配置</th><th>Seconds</th><th>Changes</th></tr><tr><td>save</td><td>900</td><td>1</td></tr><tr><td>save</td><td>300</td><td>10</td></tr><tr><td>save</td><td>60</td><td>10000</td></tr></table><blockquote><p>eg:60秒中改变了10000次会发生备份RDB</p></blockquote><h4 id="触发机制-不容忽略的方式"><a href="#触发机制-不容忽略的方式" class="headerlink" title="触发机制-不容忽略的方式"></a>触发机制-不容忽略的方式</h4><ul><li>全量复制</li><li>Debug Reload</li><li>shutdown</li></ul><h3 id="save-or-bgsave"><a href="#save-or-bgsave" class="headerlink" title="save or bgsave ?"></a>save or bgsave ?</h3><table><tr><th>命令</th><th>save</th><th>bgsave</th></tr><tr><td>IO类型</td><td>同步</td><td>异步</td></tr><tr><td>阻塞</td><td>是</td><td>发生在fork时</td></tr><tr><td>复杂度</td><td>O(N)</td><td>O(N)</td></tr><tr><td>优点</td><td>不会消耗内存</td><td>不阻塞客户端命令</td></tr><tr><td>缺点</td><td>阻塞客户端命令</td><td>消耗内存</td></tr></table> ### 配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line">dir ./</span><br><span class="line">stop-writes-on-bgsave-error yes //bgsave出现问题会停止写入</span><br><span class="line">rdbcompression yes  //压缩模式</span><br><span class="line">rdbchecksum yes //对RDB进行校验和检验</span><br></pre></td></tr></table></figure> #### 最佳配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dbfilename dump-$&#123;port&#125;.rdb</span><br><span class="line">dir bigdiskpath //选择大的硬盘</span><br><span class="line">stop-writes-on-bgsave-error yes //bgsave出现问题会停止写入</span><br><span class="line">rdbcompression yes  //压缩模式</span><br><span class="line">rdbchecksum yes //对RDB进行校验和检验</span><br></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>RDB是Redis内存到硬盘的快照，用于持久化</li><li>save通常会阻塞Redis</li><li>bgsave不会阻塞Redis，但是会fork子进程</li><li>save自动配置满足其一就会被执行</li><li>有些触发机制不容忽视</li></ul><h3 id="RDB问题"><a href="#RDB问题" class="headerlink" title="RDB问题"></a>RDB问题</h3><p><strong>耗时耗性能</strong></p><blockquote><p>O(N)数据耗时<br><br>fork耗内存<br><br>Disk I&#x2F;O:IO性能</p></blockquote><p><strong>不可控丢失数据</strong></p><table><tr><th>时间戳</th><th>save</th></tr><tr><td>T1</td><td>执行多个命令</td></tr><tr><td>T2</td><td>满足RDB自动创建条件</td></tr><tr><td>T3</td><td>再次执行多条命令</td></tr><tr><td>T4</td><td>宕机</td></tr></table><blockquote><p>宕机会发生数据丢失</p></blockquote><h2 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h2><h3 id="三种策略"><a href="#三种策略" class="headerlink" title="三种策略"></a>三种策略</h3><h4 id="everysec"><a href="#everysec" class="headerlink" title="everysec"></a>everysec</h4><p><img src="/img/in-post/2019-01-08/4.png"></p><h4 id="always"><a href="#always" class="headerlink" title="always"></a>always</h4><p>同everysec流程，只不过always会把每条命令都写入到AOF文件中</p><h4 id="no"><a href="#no" class="headerlink" title="no"></a>no</h4><p>由操作系统来决定是否刷新</p><h4 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h4><table><tr><th>命令</th><th>always</th><th>everysec</th><th>no</th></tr><tr><td>优点</td><td>不丢失数据</td><td>每秒一次fsync丢1秒数据</td><td>不用管理</td></tr><tr><td>缺点</td><td>IO开销比较大</td><td>丢1秒数据</td><td>不可控</td></tr></table> ### AOF重写<h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><ul><li>减少硬盘占用量</li><li>加快回复速度</li></ul><h3 id="重写两种方式"><a href="#重写两种方式" class="headerlink" title="重写两种方式"></a>重写两种方式</h3><h4 id="bgrewriteaof"><a href="#bgrewriteaof" class="headerlink" title="bgrewriteaof"></a>bgrewriteaof</h4><p><strong>命令：bgrewriteaof</strong></p><p><img src="/img/in-post/2019-01-08/6.png"></p><p><strong>重写配置</strong></p><table><tr><th>配置名</th><th>含义</th></tr><tr><td>auto-aof-rewirte-min-size</td><td>auto-aof-rewirte-percentage</td></tr><tr><td>AOF文件重写尺寸</td><td>AOF文件增长率</td></tr></table> **统计**<table><tr><th>统计名</th><th>含义</th></tr><tr><td>auto-current-size</td><td>auto-base-size</td></tr><tr><td>AOF当前尺寸</td><td>AOF上次启动和重写的尺寸</td></tr></table> #### 自动触发时机<ul><li>auto-current-size &gt; auto-aof-rewirte-min-size</li><li>(auto-current-size - auto-base-size) &#x2F; auto-base-size &gt; auto-aof-rewirte-percentage</li></ul><h3 id="AOF重写流程"><a href="#AOF重写流程" class="headerlink" title="AOF重写流程"></a>AOF重写流程</h3><p><img src="/img/in-post/2019-01-08/8.jpg"></p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul><li>appendonly yes</li><li>appendfilename “appendonly-${port}.aof”</li><li>appendfsync everysec</li><li>dir &#x2F;bigdisk</li><li>no-appendfsync-on-rewrite no &#x2F;&#x2F;aof重写失败是否允许丢失数据</li><li>auto-aof-rewrite-percentage 100 &#x2F;&#x2F;增长率</li><li>auto-aof-rewrite-min-size 64mb &#x2F;&#x2F;最小尺寸</li></ul><h2 id="RDB-和-AOF-抉择"><a href="#RDB-和-AOF-抉择" class="headerlink" title="RDB 和 AOF 抉择"></a>RDB 和 AOF 抉择</h2><table><tr><th>命令</th><th>RDB</th><th>AOF</th></tr><tr><td>启动优先级</td><td>低</td><td>高</td></tr><tr><td>体积</td><td>小</td><td>大</td></tr><tr><td>恢复速度</td><td>快</td><td>慢</td></tr><tr><td>数据安全性</td><td>丢数据</td><td>根据策略决定</td></tr><tr><td>轻重</td><td>重</td><td>轻</td></tr></table></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2020/01/25/2020-01-25-redis-cluster-out/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2020/01/25/2020-01-25-redis-cluster-out/" class="post-title-link" itemprop="url">Redis cluster 故障转移</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-25 21:30:00" itemprop="dateCreated datePublished" datetime="2020-01-25T21:30:00+08:00">2020-01-25</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="故障发现"><a href="#故障发现" class="headerlink" title="故障发现"></a>故障发现</h2><p>通过ping&#x2F;pong消息实现故障发现，不依赖sentinel</p><h2 id="主观下线"><a href="#主观下线" class="headerlink" title="主观下线"></a>主观下线</h2><p>定义：某个节点认为另外一个节点不可用“偏见”</p><p>主观下线流程：<br><img src="/img/in-post/2019-01-25/1.png"></p><h2 id="客观下线"><a href="#客观下线" class="headerlink" title="客观下线"></a>客观下线</h2><p>定义：当半数以上持有槽的主节点都标记某节点主观下线</p><p>客观下线流程：<br><img src="/img/in-post/2019-01-25/2.png"></p><h2 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h2><h3 id="资格检查"><a href="#资格检查" class="headerlink" title="资格检查"></a>资格检查</h3><ul><li>每个从节点检查与故障节点的断线时间</li><li>超过cluster-node-timeout*cluster-slave-validity-factor取消资格</li><li>cluster-slave-validity-factor：默认为10</li></ul><h3 id="准备选举时间"><a href="#准备选举时间" class="headerlink" title="准备选举时间"></a>准备选举时间</h3><p><img src="/img/in-post/2019-01-25/3.png"></p><h3 id="选举投票"><a href="#选举投票" class="headerlink" title="选举投票"></a>选举投票</h3><p><img src="/img/in-post/2019-01-25/4.png"></p><h3 id="替换主节点"><a href="#替换主节点" class="headerlink" title="替换主节点"></a>替换主节点</h3><ul><li>当前从节点复制变为主节点。(slaveof no one)</li><li>执行clusterDelSlot撤销故障主节点负责的槽，并执行clusterAddSlot<br>把这些槽分配给自己</li><li>向群广播自己的pong消息，表明已替换了故障从节点</li></ul><h2 id="redis-cluster-开发常见问题"><a href="#redis-cluster-开发常见问题" class="headerlink" title="redis cluster 开发常见问题"></a>redis cluster 开发常见问题</h2><h3 id="集群完整性"><a href="#集群完整性" class="headerlink" title="集群完整性"></a>集群完整性</h3><p><code>cluster-require-full-coverage</code>默认为yes<br>问题：</p><ul><li>集群中16384个槽全部可用，保证完整性</li><li>节点故障转移或正在转移<br>大多数业务无法容忍，建议设置为no<blockquote><p>当其中一台机器发生故障，此时集群状态不可用，不可以set ket,不建议设置为yes</p></blockquote></li></ul><h3 id="宽带消耗"><a href="#宽带消耗" class="headerlink" title="宽带消耗"></a>宽带消耗</h3><p>官方建议：1000个节点</p><ul><li>消息频率 节点发现和节点最后通信时间超过cluster-node-timeout&#x2F;2时会发送ping消息</li><li>消息数据量 slots数据组(2k)和整个集群1&#x2F;10的状态数据(10个节点状态数据约1k)</li><li>节点部署机器规模 分布机器越多且每台机器划分的节点越均匀，整体的可用带宽越高<br>例子：200个节点，20个物理机器（每台10个节点）</li></ul><p>cluster-node-timeout&#x3D;15000 ping&#x2F;pong带宽约25MB</p><p>cluster-node-timeout&#x3D;20000 ping&#x2F;pong带低于15MB</p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><ul><li>避免多业务使用多集群，大业务可以多集群</li><li>cluster-node-timeout 带宽和故障转移速度的均衡</li><li>尽量均匀分配多个机器，保证带宽</li></ul><h3 id="PUB-x2F-SUB广播"><a href="#PUB-x2F-SUB广播" class="headerlink" title="PUB&#x2F;SUB广播"></a>PUB&#x2F;SUB广播</h3><p>问题：publish在集群每个节点广播：加重带宽<br>解决：单独走一套redis sentinel</p><h3 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h3><p><strong>数据倾斜：内存不均匀</strong></p><p><strong>节点和槽分配不均匀</strong></p><p><strong>不同槽对应键值数差异大</strong></p><ul><li>可能存在has_tag</li><li>cluster countkeysinslot {slot}获取槽对应键值个数</li></ul><p><strong>包含bigkey</strong></p><ul><li>例如大字符串，几百万元素的hash,set等</li><li>从节点，redis-cli –bigkeys</li><li>优化数据结构，拆分key</li></ul><p><strong>内存相关配置不一致</strong></p><ul><li>hash-max-ziplist-value, set-max-intset-entries等</li></ul><p><strong>请求倾斜：key热点</strong>重要的key或者bigkey<br>优化：</p><ul><li>避免big_key</li><li>热键不要使用hash_tag（避免落在一个节点）</li><li>当一致性不高时可以使用本地缓存+MQ</li></ul><h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>只读连接：集群模式的从节点不接受任何读写请求</p><ul><li>重定向到负责槽的主节点</li><li>readonly命令可以读：连接级的命令<br>读写分离：更加复杂</li><li>复制延迟，从节点故障，读取过期数据</li><li>修改客户端：cluster slaves {nodeid}</li></ul><h3 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h3><p>官方工具：redis-trib.rb import</p><ul><li>只能从单机迁移到集群</li><li>不支持在线迁移，source需要停写</li><li>不支持断点续传</li><li>单线程迁移，影响速度<br>在线迁移：</li></ul><p>唯品会：redis-migrate-tool</p><p>豌豆荚：redis-port</p><h3 id="集群VS单机"><a href="#集群VS单机" class="headerlink" title="集群VS单机"></a>集群VS单机</h3><p>集群限制<br></p><ul><li>key批量操作限制</li><li>key事物和lua支持有限，操作的key必须在同一个节点</li><li>key是数据分区的最小粒度：不支持bigkey分区</li><li>不支持多个数据库：集群模式下只有一个db0</li><li>复制只支持一层，不支持树形</li></ul><ol><li>Redis Cluster: 满足容量和性能的扩展性：很多业务不需要</li><li>很多场景Redis Sentinel足够好</li></ol></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2020/01/24/2020-01-24-redis-cluster-route/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2020/01/24/2020-01-24-redis-cluster-route/" class="post-title-link" itemprop="url">Redis cluster 客户端路由</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-24 21:30:00" itemprop="dateCreated datePublished" datetime="2020-01-24T21:30:00+08:00">2020-01-24</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="MOVED重定向"><a href="#MOVED重定向" class="headerlink" title="MOVED重定向"></a>MOVED重定向</h2><p><img src="/img/in-post/2019-01-24/1.png"></p><h3 id="槽命中：直接返回"><a href="#槽命中：直接返回" class="headerlink" title="槽命中：直接返回"></a>槽命中：直接返回</h3><p><img src="/img/in-post/2019-01-24/2.png"></p><p>算出key的slot值</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;127.0.0.1&gt; 6379 cluster keyslot hello</span><br></pre></td></tr></table></figure><p>返回结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(integer) 866</span><br></pre></td></tr></table></figure><h3 id="槽不命中：moved异常"><a href="#槽不命中：moved异常" class="headerlink" title="槽不命中：moved异常"></a>槽不命中：moved异常</h3><p>算出key的slot值</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;127.0.0.1&gt; 6379 cluster keyslot php</span><br></pre></td></tr></table></figure><p>返回结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(integer) 9244</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-24/3.png"></p><p>看一个小例子:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -c -p 7000    //集群模式</span><br><span class="line">127.0.0.1:7000&gt; cluster keyslot hello</span><br><span class="line">(integer) 866</span><br><span class="line">127.0.0.1:7000&gt; set hello word</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7000&gt; cluster keyslot php</span><br><span class="line">(integer) 9244</span><br><span class="line">127.0.0.1:7000&gt; set php best</span><br><span class="line">-&gt; Redirected to slot [9244] located at 127.0.0.1:7001</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7001&gt; get php</span><br><span class="line">&quot;best&quot;</span><br><span class="line">127.0.0.1:7001&gt; </span><br><span class="line">redis-cli -p 7000</span><br><span class="line">127.0.0.1:7000&gt; cluster keyslot php</span><br><span class="line">(integer) 9244</span><br><span class="line">127.0.0.1:7000&gt; set php best</span><br><span class="line">(error) MOVED 9244 127.0.0.1:7001</span><br><span class="line">127.0.0.1:7000&gt;</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-24/4.png"></p><h2 id="ASK重定向"><a href="#ASK重定向" class="headerlink" title="ASK重定向"></a>ASK重定向</h2><p><img src="/img/in-post/2019-01-24/5.png"></p><p>在集群缩容扩容的时候，要对槽进行迁移，槽迁移过程中要遍历进行migrate,迁移时间比较长，<br>此时在此过程中访问一个key,但是key已经迁移到目标节点，就需要一个新的方案来解决这个问题，redis cluster 对这个问题已经有解决方案</p><p>我们来看它的一个实现演示：<br><img src="/img/in-post/2019-01-24/6.png"></p><h2 id="moved-amp-ask"><a href="#moved-amp-ask" class="headerlink" title="moved &amp; ask"></a>moved &amp; ask</h2><ul><li>两者都是客户端重定向</li><li>moved:槽已确定迁移</li><li>ask:槽还在迁移中</li></ul><h2 id="smart客户端"><a href="#smart客户端" class="headerlink" title="smart客户端"></a>smart客户端</h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>追求性能：</p><ol><li>从集群中选一个可运行的节点，使用cluster slots 初始化槽和节点映射</li><li>将cluster slots结果映射到本地，为每个节点创建redisPool</li><li>执行命令</li></ol><p>基本流程：<br><img src="/img/in-post/2019-01-24/7.png"></p><blockquote><p>关于redis cluster 客户端使用可参考<br><a target="_blank" rel="noopener" href="https://github.com/enpsl/redis-go-cluster/tree/master/example">redis-go-cluster</a></p></blockquote><h3 id="批量操作优化"><a href="#批量操作优化" class="headerlink" title="批量操作优化"></a>批量操作优化</h3><p><strong>批量操作怎么实现?meget meset必须在一个槽</strong></p><h4 id="串行mget"><a href="#串行mget" class="headerlink" title="串行mget"></a>串行mget</h4><p><img src="/img/in-post/2019-01-24/8.png"></p><h4 id="串行IO"><a href="#串行IO" class="headerlink" title="串行IO"></a>串行IO</h4><p><img src="/img/in-post/2019-01-24/9.png"></p><h4 id="并行IO"><a href="#并行IO" class="headerlink" title="并行IO"></a>并行IO</h4><p><img src="/img/in-post/2019-01-24/10.png"></p><h4 id="hash-tag"><a href="#hash-tag" class="headerlink" title="hash_tag"></a>hash_tag</h4><p><img src="/img/in-post/2019-01-24/11.png"></p><h3 id="四种方案优缺点对比"><a href="#四种方案优缺点对比" class="headerlink" title="四种方案优缺点对比"></a>四种方案优缺点对比</h3><table><tr><td>方案</td><td>优点</td><td>缺点</td><td>网络IO</td></tr><tr><td>串行mget</td><td>编程简单，少量keys满足需求</td><td>大量keys请求延迟严重</td><td>O(keys)</td></tr><tr><td>串行IO</td><td>编程简单，少量节点满足需求</td><td>大量node延迟严重</td><td>O(nodes)</td></tr><tr><td>并行IO</td><td>利用并行特性，延迟取决于最慢的节点</td><td>编程复杂，超市定位问题难</td><td>O(max(node))</td></tr><tr><td>hash_tag</td><td>性能最高</td><td>读写增加tag维护成本，tag分布易出现数据倾斜</td><td>O(1))</td></tr></table></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2020/01/23/2020-01-23-redis-cluster-operator/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2020/01/23/2020-01-23-redis-cluster-operator/" class="post-title-link" itemprop="url">Redis cluster 伸缩</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-23 22:30:00" itemprop="dateCreated datePublished" datetime="2020-01-23T22:30:00+08:00">2020-01-23</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="集群伸缩原理"><a href="#集群伸缩原理" class="headerlink" title="集群伸缩原理"></a>集群伸缩原理</h2><p><img src="/img/in-post/2019-01-23/1.png"><br><img src="/img/in-post/2019-01-23/2.png"></p><center style="font-weight:700">集群伸缩=槽和数据在节点之间的移动</center><h2 id="扩容集群"><a href="#扩容集群" class="headerlink" title="扩容集群"></a>扩容集群</h2><h3 id="准备新节点"><a href="#准备新节点" class="headerlink" title="准备新节点"></a>准备新节点</h3><p>新节点：</p><ul><li>集群模式</li><li>配置和其它节点统一</li><li>启动后仍是孤儿节点</li></ul><p><img src="/img/in-post/2019-01-23/3.png"></p><h3 id="加入集群"><a href="#加入集群" class="headerlink" title="加入集群"></a>加入集群</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cluster meet 127.0.0.1 6385</span><br><span class="line">cluster meet 127.0.0.1 6386</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-23/4.png"></p><center style="font-weight:700">加入后的效果</center><p>加入集群的作用：</p><ul><li>为它迁移槽和数据实现扩容</li><li>作为从节点负责故障转移</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster add-node new_host:new_port existing_host:existing_port --cluster-slave --cluster-master-id &lt;arg&gt;</span><br></pre></td></tr></table></figure><blockquote><p>建议使用redis-trib.rb能够避免新节点已经加入了其它集群，造成故障</p></blockquote><h3 id="迁移槽和数据"><a href="#迁移槽和数据" class="headerlink" title="迁移槽和数据"></a>迁移槽和数据</h3><h4 id="槽迁移计划"><a href="#槽迁移计划" class="headerlink" title="槽迁移计划:"></a>槽迁移计划:</h4><p><img src="/img/in-post/2019-01-23/6.png"><br><img src="/img/in-post/2019-01-23/7.png"></p><h4 id="迁移数据："><a href="#迁移数据：" class="headerlink" title="迁移数据："></a>迁移数据：</h4><ol><li>对目标节点发送: cluster setslot{slot} importing {sourceNodeId}命令，让目标节点准备导入槽的数据。</li><li>对源节点发送: cluster setslot{slot} migrating {targetNodeId}命令，让源节点准备迁出槽的数据。</li><li>源节点循环执行: cluster getkeysinslot{slot}{count}命令，每次获取count个属于槽的键。</li><li>在源节点执行: migrate {targetIP}{targetPort} key 0 {timeout}命令把指定key迁移。</li><li>重复执行3-4直到槽下所有数据节点均迁移到目标节点。</li><li>向集群内所有主节点发送cluster setslot{slot} node {targetNodeId}命令，通知槽分配给目标节点。</li></ol><h4 id="数据迁移伪python代码"><a href="#数据迁移伪python代码" class="headerlink" title="数据迁移伪python代码:"></a>数据迁移伪python代码:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">move_slot</span>(<span class="params">source,target,slot</span>):</span><br><span class="line">    <span class="comment">#目标节点准备导入槽slot</span></span><br><span class="line">    target.cluster(<span class="string">&quot;setslot&quot;</span>,slot,<span class="string">&quot;importing&quot;</span>,source.nodeID)</span><br><span class="line">    <span class="comment">#目标节点准备全出槽slot</span></span><br><span class="line">    target.cluster(<span class="string">&quot;setslot&quot;</span>,slot,<span class="string">&quot;migrating&quot;</span>,source.nodeID) </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment">#批量从源节点获取键</span></span><br><span class="line">        keys = source.cluster(<span class="string">&quot;getkeysinslot&quot;</span>,slot,pipeline_size)</span><br><span class="line">        <span class="keyword">if</span> keys.length ==<span class="number">0</span>:</span><br><span class="line">            <span class="comment">#键列表为空时，退出循环</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="comment">#批量迁移键到目标节点</span></span><br><span class="line">    source.call(<span class="string">&quot;migrate&quot;</span>,target.host,target.port,<span class="string">&quot;&quot;</span>,timeout,<span class="string">&quot;keys&quot;</span>)</span><br><span class="line">    <span class="comment">#向集群所有主节点通知槽slot被分配给目标节点</span></span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> nodes:</span><br><span class="line">        <span class="keyword">if</span> node.flag ==<span class="string">&quot;slave&quot;</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        node.cluster(<span class="string">&quot;setslot&quot;</span>,slot,<span class="string">&quot;node&quot;</span>,target.nodeID)</span><br></pre></td></tr></table></figure><h4 id="pipline迁移"><a href="#pipline迁移" class="headerlink" title="pipline迁移"></a>pipline迁移</h4><p><img src="/img/in-post/2019-01-23/8.png"></p><blockquote><p>3.0.6 版本pipline数据迁移会有丢失数据bug，在3.2.8已解决</p></blockquote><h2 id="扩容演示"><a href="#扩容演示" class="headerlink" title="扩容演示"></a>扩容演示</h2><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><p><img src="/img/in-post/2019-01-23/9.png"><br>当前集群是三主三从结构，此时我们加入两个新节点7006,7007。7007是7006的从节点，我们需要从7001,7002节点把一部分数据迁移给7006。<br>配置准备:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">&#x27;s/7000/7006/g&#x27;</span> redis-7000.conf &gt; redis-7006.conf</span><br><span class="line">sed <span class="string">&#x27;s/7000/7007/g&#x27;</span> redis-7000.conf &gt; redis-7007.conf</span><br></pre></td></tr></table></figure><h3 id="meet"><a href="#meet" class="headerlink" title="meet:"></a>meet:</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 7000 cluster meet 127.0.0.1 7006</span><br><span class="line">redis-cli -p 7000 cluster meet 127.0.0.1 7007</span><br></pre></td></tr></table></figure><h3 id="replicate"><a href="#replicate" class="headerlink" title="replicate:"></a>replicate:</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 7007 cluster replicate d57d27051ce9db7752f894394b621368f9e0a058</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-23/10.png"></p><blockquote><p>此时7007已经属于7006的从节点</p></blockquote><h3 id="迁移数据：-1"><a href="#迁移数据：-1" class="headerlink" title="迁移数据："></a>迁移数据：</h3><blockquote><p>由于槽数量比较多，所以这里使用redis-trib来迁移</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster reshard 127.0.0.1 7000</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-23/11.png"><br>此时给我们提示出了当前集群的信息，由于我们现在是4个主节点，所以需要分成四等份来支持向master写入数据<br><img src="/img/in-post/2019-01-23/12.png"><br><img src="/img/in-post/2019-01-23/13.png"></p><p>槽迁移后的信息：<br><img src="/img/in-post/2019-01-23/14.png"></p><h2 id="收缩集群"><a href="#收缩集群" class="headerlink" title="收缩集群"></a>收缩集群</h2><h3 id="下线迁移槽"><a href="#下线迁移槽" class="headerlink" title="下线迁移槽"></a>下线迁移槽</h3><p><img src="/img/in-post/2019-01-23/15.png"></p><h3 id="忘记节点"><a href="#忘记节点" class="headerlink" title="忘记节点"></a>忘记节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli&gt;cluster forget &#123;downNodeId&#125;</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-23/16.png"></p><h3 id="关闭节点"><a href="#关闭节点" class="headerlink" title="关闭节点"></a>关闭节点</h3><h2 id="收缩集群演示"><a href="#收缩集群演示" class="headerlink" title="收缩集群演示"></a>收缩集群演示</h2><p>例：下线7006，7007</p><h3 id="迁移槽："><a href="#迁移槽：" class="headerlink" title="迁移槽："></a>迁移槽：</h3><p>迁移过程命令：</p><p>redis-cli –cluster reshard –cluster-from {7006nodeid} –cluster-to 7000{7000nodeid} –cluster-slots {slot num} 127.0.0.1:7006</p><p>redis-cli –cluster reshard –cluster-from {7006nodeid} –cluster-to 7001{7001nodeid} –cluster-slots {slot num} 127.0.0.1:7006</p><p>redis-cli –cluster reshard –cluster-from {7006nodeid} –cluster-to 7002{7002nodeid} –cluster-slots {slot num} 127.0.0.1:7006</p><p>迁移到7000示例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster reshard --cluster-from d57d27051ce9db7752f894394b621368f9e0a058 --cluster-to 092fd7c3cf19693eddec5c0fae9894d681023ce5 --cluster-slots 1365 127.0.0.1:7006</span><br></pre></td></tr></table></figure><p>之后选择yes即可</p><p><img src="/img/in-post/2019-01-23/17.png"><br>可观察出0-1364的槽节点以迁移完毕，重复上述步骤，迁移剩余的槽</p><p>迁移后：<br><img src="/img/in-post/2019-01-23/18.png"></p><h3 id="忘记节点："><a href="#忘记节点：" class="headerlink" title="忘记节点："></a>忘记节点：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster del-node 127.0.0.1:7000 d57d27051ce9db7752f894394b621368f9e0a058</span><br></pre></td></tr></table></figure><blockquote><p>需要先下线从节点在下线主节点，否则会发生故障转移</p></blockquote><h3 id="完成缩容"><a href="#完成缩容" class="headerlink" title="完成缩容"></a>完成缩容</h3><p><img src="/img/in-post/2019-01-23/19.png"></p></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2020/01/20/2020-01-20-redis-cluster/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2020/01/20/2020-01-20-redis-cluster/" class="post-title-link" itemprop="url">Redis cluster</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-20 22:30:00" itemprop="dateCreated datePublished" datetime="2020-01-20T22:30:00+08:00">2020-01-20</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="呼唤集群"><a href="#呼唤集群" class="headerlink" title="呼唤集群"></a>呼唤集群</h2><p>当系统应用需要有更大容量和QPS的支撑，此时就需要采用的集群的方式，也可以简单理解为加机器</p><p>数据分区:</p><p><img src="/img/in-post/2019-01-20/1.jpg"></p><h2 id="分布方式"><a href="#分布方式" class="headerlink" title="分布方式"></a>分布方式</h2><h3 id="顺序分布"><a href="#顺序分布" class="headerlink" title="顺序分布"></a>顺序分布</h3><p><img src="/img/in-post/2019-01-20/2.png"></p><h3 id="哈希分布"><a href="#哈希分布" class="headerlink" title="哈希分布"></a>哈希分布</h3><p><img src="/img/in-post/2019-01-20/3.png"></p><ul><li>节点取余</li><li>一致性hash</li><li>虚拟槽分区</li></ul><h4 id="节点取余"><a href="#节点取余" class="headerlink" title="节点取余"></a>节点取余</h4><p><img src="/img/in-post/2019-01-20/3.png"></p><ul><li>客户端分片: 哈希+取余</li><li>节点伸缩: 数据节点关系变化，导致数据迁移</li><li>迁移数量和添加节点数量相关：建议翻倍扩容</li></ul><h4 id="一致性hash"><a href="#一致性hash" class="headerlink" title="一致性hash"></a>一致性hash</h4><p><img src="/img/in-post/2019-01-20/5.png"></p><p>一致性hash扩容</p><p><img src="/img/in-post/2019-01-20/4.png"></p><ul><li>客户端分片：哈希+顺时针（优化取余）</li><li>节点伸缩：只影响临近节点，但是还是有数据迁移</li><li>翻倍伸缩：保证最小迁移数据和负载均衡</li></ul><h4 id="虚拟槽分布"><a href="#虚拟槽分布" class="headerlink" title="虚拟槽分布"></a>虚拟槽分布</h4><p><img src="/img/in-post/2019-01-20/2.jpg"></p><ul><li>预设虚拟槽：每个槽映射一个数据子集，一般比节点数大</li><li>良好的hash函数：如crc16</li><li>服务端管理节点，槽，数据：例如redis cluster</li></ul><h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><table><tr><th>分布方式</th><th>特点</th><th>典型产品</th></tr><tr><td>哈希分布</td><td>数据分散度高<br>key,value分布业务无关<br>无法顺序访问<br>支持批量操作</td><td>一致性hash memcache<br>redis cluster<br>其它缓存产品</td></tr><tr><td>顺序分布</td><td>数据分散度易倾斜<br>key,value业务相关<br>可顺序访问<br>支持批量操作</td><td>BigTable<br>HBase<br></td></tr></table> ## Redis Cluster<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><ul><li>节点</li><li>meet</li><li>指派槽</li><li>复制</li></ul><h3 id="特性："><a href="#特性：" class="headerlink" title="特性："></a>特性：</h3><ul><li>复制</li><li>分片</li><li>高可用</li></ul><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="原生安装"><a href="#原生安装" class="headerlink" title="原生安装"></a>原生安装</h4><p>1: 配置开启节点:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">port&#123;$port&#125;</span><br><span class="line">daemonize yes</span><br><span class="line">dir &quot;$&#123;redis-src&#125;/data/&quot;</span><br><span class="line">dbfilename &quot;dump-&#123;$port&#125;.rdb&quot;</span><br><span class="line">logfile &quot;&#123;$port&#125;.log&quot;</span><br><span class="line">cluster-enabled &quot;yes</span><br><span class="line">cluster-config-file nodes-&#123;$port&#125;.conf</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-20/6.png"></p><p>批量生成配置文件:</p><p><img src="/img/in-post/2019-01-20/7.png"></p><p>执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis-7000.conf</span><br><span class="line">redis-server redis-7001.conf</span><br><span class="line">redis-server redis-7002.conf</span><br><span class="line">redis-server redis-7003.conf</span><br><span class="line">redis-server redis-7004.conf</span><br><span class="line">redis-server redis-7005.conf</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-20/8.png"></p><p>2: meet</p><p><strong>cluster meet ip port</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7001</span><br><span class="line">redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7002</span><br><span class="line">redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7003</span><br><span class="line">redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7004</span><br><span class="line">redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7005</span><br></pre></td></tr></table></figure><p>先进行7000和7001的握手</p><p><img src="/img/in-post/2019-01-20/9.png"></p><p>发现7000和7001已经完成握手，继续meet其他的节点</p><p><img src="/img/in-post/2019-01-20/10.png"></p><p>此时执行<code>cluster nodes</code>和<code>cluster info</code>均发现6个节点相互关联，证明已经握手成功</p><p>3: 指派槽</p><p><strong>cluster addslots slot [slot…]</strong></p><p>由于一共要分配16384个槽，所以需要借助脚本去分配槽</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">start=<span class="variable">$1</span></span><br><span class="line">end=<span class="variable">$2</span></span><br><span class="line">port=<span class="variable">$3</span></span><br><span class="line"><span class="keyword">for</span> slot <span class="keyword">in</span> `<span class="built_in">seq</span> <span class="variable">$&#123;start&#125;</span> <span class="variable">$&#123;end&#125;</span>`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;slot:<span class="variable">$&#123;slot&#125;</span>&quot;</span></span><br><span class="line">    redis-cli -p <span class="variable">$&#123;port&#125;</span> cluster addslots <span class="variable">$&#123;slot&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>我们要配置的是三主三从，所以要把16384三等分</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0-5461 7000 5462-10922 7001 10923-16383 7002</span><br></pre></td></tr></table></figure><p>执行以下命令:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sh addslots.sh 0 5461 7000</span><br><span class="line">sh addslots.sh 5462 10922 7001</span><br><span class="line">sh addslots.sh 10923 16383 7002</span><br></pre></td></tr></table></figure><p>查看槽分配状态</p><p><img src="/img/in-post/2019-01-20/11.png"><br><img src="/img/in-post/2019-01-20/12.png"></p><blockquote><p>此时发现16384个槽确实已经分配完毕，槽分配完毕</p></blockquote><p>4: 主从</p><p>cluster replicate node-id</p><p>给7003分配到master7000主节点上：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 7003 cluster replicate 6d4942b15eb5e02bb6193453443ccb827c13c6df</span><br><span class="line">redis-cli -p 7004 cluster replicate 916f84dee5fbef724ddf2f90fddf51fd654113f1</span><br><span class="line">redis-cli -p 7005 cluster replicate fee14c1f872fc4c7d451f84a616cf735d220538b</span><br></pre></td></tr></table></figure><p>主从分配结果：<br><img src="/img/in-post/2019-01-20/13.png"><br><img src="/img/in-post/2019-01-20/14.png"></p><h4 id="官方工具"><a href="#官方工具" class="headerlink" title="官方工具"></a>官方工具</h4><p>由于原生安装过程比较麻烦，又容易出错，所以正常的生产环境使用官方工具安装，但是掌握原生安装的方式更容易让我们理解集群分配的原理</p><p><strong>ruby环境准备</strong></p><ol><li>下载编译安装ruby</li><li>安装rubygem redis</li><li>安装redis-trib.rb</li></ol><p><img src="/img/in-post/2019-01-20/15.png"></p><p>1: 配置开启节点:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">port&#123;$port&#125;</span><br><span class="line">daemonize yes</span><br><span class="line">dir &quot;$&#123;redis-src&#125;/data/&quot;</span><br><span class="line">dbfilename &quot;dump-&#123;$port&#125;.rdb&quot;</span><br><span class="line">logfile &quot;&#123;$port&#125;.log&quot;</span><br><span class="line">cluster-enabled &quot;yes</span><br><span class="line">cluster-config-file nodes-&#123;$port&#125;.conf</span><br></pre></td></tr></table></figure><p>执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis-7000.conf</span><br><span class="line">redis-server redis-7001.conf</span><br><span class="line">redis-server redis-7002.conf</span><br><span class="line">redis-server redis-7003.conf</span><br><span class="line">redis-server redis-7004.conf</span><br><span class="line">redis-server redis-7005.conf</span><br></pre></td></tr></table></figure><p>2: 集群创建</p><p><img src="/img/in-post/2019-01-20/16.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//1 表示1个主节点分配1个从节点</span><br><span class="line">redis-cli --cluster create --cluster-replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-20/17.png"></p><p>上图分别展示了槽分配，主从和节点信息，符合预期执行yes即可</p><p>分配成功信息：</p><p><img src="/img/in-post/2019-01-20/18.png"></p><p>集群验证：</p><p><img src="/img/in-post/2019-01-20/19.png"></p><blockquote><p>当然如果维护上百台集群显然也不是最好的方式，可以借助或构建云平台来管理集群</p></blockquote></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2020/01/19/2020-01-11-redis-sentinel/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2020/01/19/2020-01-11-redis-sentinel/" class="post-title-link" itemprop="url">Redis哨兵</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-19 23:30:00" itemprop="dateCreated datePublished" datetime="2020-01-19T23:30:00+08:00">2020-01-19</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="Redis-Sentinel基本架构"><a href="#Redis-Sentinel基本架构" class="headerlink" title="Redis Sentinel基本架构"></a>Redis Sentinel基本架构</h2><ol><li>多个sentinel发现并确认master有问题</li><li>选举出一个sentinel作为领导</li><li>选出一个salve作为master</li><li>通知其余slave成为新的master的slave</li><li>通知客户端主从变化</li><li>等待master复活成为新的master的slave</li></ol><h2 id="安装与配置"><a href="#安装与配置" class="headerlink" title="安装与配置"></a>安装与配置</h2><ol><li>配置开启主从节点</li><li>配置开启sentinel监控master节点</li></ol><p>Redis主节点<br>启动<code>redis-server redis-7000.conf</code></p><h3 id="redis配置"><a href="#redis配置" class="headerlink" title="redis配置:"></a>redis配置:</h3><p>主节点:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">port 7000</span><br><span class="line">daemonize yes</span><br><span class="line">pidfile /var/run/redis/7000.pid</span><br><span class="line">logfile 7000.log</span><br><span class="line">dir &quot;$&#123;redis-src&#125;/data/&quot;</span><br></pre></td></tr></table></figure><p>从节点:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">port 7001</span><br><span class="line">daemonize yes</span><br><span class="line">pidfile /var/run/redis/7001.pid</span><br><span class="line">logfile 7001.log</span><br><span class="line">dir &quot;$&#123;redis-src&#125;/data/&quot;</span><br><span class="line">slaveof 127.0.0.1 7000</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">port 7002</span><br><span class="line">daemonize yes</span><br><span class="line">pidfile /var/run/redis/7002.pid</span><br><span class="line">logfile 7002.log</span><br><span class="line">dir &quot;$&#123;redis-src&#125;/data/&quot;</span><br><span class="line">slaveof 127.0.0.1 7000</span><br></pre></td></tr></table></figure><h3 id="sentinel配置"><a href="#sentinel配置" class="headerlink" title="sentinel配置:"></a>sentinel配置:</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">port $&#123;port&#125;</span><br><span class="line">dir &quot;$&#123;redis-src&#125;/data/&quot;</span><br><span class="line">logfile $&#123;port&#125;.log</span><br><span class="line">sentinel monitor mymaster 127.0.0.1 7000 2 #监控主节点的名字 2对应当两个sentinel发现主节点有问题就发生故障转移</span><br><span class="line">sentinel down-after-millisenconds mymaster 30000 #ping30秒后不通认为有问题</span><br><span class="line">sentinel parallel-sync mymaster 1</span><br><span class="line">sentinel failover-timeout mymaster 180000</span><br></pre></td></tr></table></figure><h3 id="安装演示"><a href="#安装演示" class="headerlink" title="安装演示"></a>安装演示</h3><p><strong>配置redis</strong></p><blockquote><p>单机演示实际为能相互ping通的多台机器</p></blockquote><p>1：创建master节点配置</p><p><img src="/img/in-post/2019-01-19/1.png"></p><p>2：创建7000,7001节点配置</p><p><img src="/img/in-post/2019-01-19/2.png"><br><img src="/img/in-post/2019-01-19/3.png"></p><p>3：查看主从状态</p><p><img src="/img/in-post/2019-01-19/4.png"></p><blockquote><p>到此为止主从的配置搭建完毕了</p></blockquote><p><strong>配置sentinel</strong></p><p>通过官方提供的配置模板导入sentinel配置</p><p><img src="/img/in-post/2019-01-19/5.png"><br>配置信息：</p><p><img src="/img/in-post/2019-01-19/6.png"></p><p>查看Sentinel监控状态：</p><p><img src="/img/in-post/2019-01-19/7.png"></p><p>到此我们可以发现Sentinel已经检测到了matser节点的主从信息，由于我们只启动一个Sentinel所以Sentinel发现的数目为1</p><p>再去看看redis-sentinel-26379.conf的变化:</p><p><img src="/img/in-post/2019-01-19/8.png"></p><blockquote><p>发现他已经把7000的两个slave节点的信息配置自动写入到了配置文件中</p></blockquote><p>生成另外两个Sentinel配置</p><p><img src="/img/in-post/2019-01-19/9.png"></p><p>查看sentinel状态</p><p><img src="/img/in-post/2019-01-19/10.png"></p><blockquote><p>发现26380的Sentinel并没有发现其他节点</p></blockquote><p>查看原因：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat /var/log/redis/26379.log</span><br><span class="line">cat /var/log/redis/26380.log</span><br><span class="line">cat /var/log/redis/26381.log</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-19/11.png"><br><img src="/img/in-post/2019-01-19/12.png"></p><p>我们发现三个节点的pid都是一样的，所以需要配置pid<br>编辑26379,26380,26381.conf 去掉配置文件自动生成的myid,并加入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pidfile &quot;/var/run/redis/redis-sentinel-26379.pid&quot;</span><br><span class="line">pidfile &quot;/var/run/redis/redis-sentinel-26380.pid&quot;</span><br><span class="line">pidfile &quot;/var/run/redis/redis-sentinel-26381.pid&quot;</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-19/13.png"></p><p>状态已正常</p><h2 id="go客户端"><a href="#go客户端" class="headerlink" title="go客户端"></a>go客户端</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;github.com/gomodule/redigo/redis&quot;</span></span><br><span class="line">	<span class="string">&quot;github.com/letsfire/redigo&quot;</span></span><br><span class="line">	<span class="string">&quot;github.com/letsfire/redigo/mode&quot;</span></span><br><span class="line">	<span class="string">&quot;github.com/letsfire/redigo/mode/sentinel&quot;</span></span><br><span class="line">	<span class="string">&quot;strconv&quot;</span></span><br><span class="line">	<span class="string">&quot;time&quot;</span></span><br><span class="line">	<span class="string">&quot;log&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">var</span> (</span><br><span class="line">		i <span class="type">int</span></span><br><span class="line">		sentinelMode mode.IMode</span><br><span class="line">	)</span><br><span class="line">	sentinelMode = sentinel.New(</span><br><span class="line">		sentinel.Addrs([]<span class="type">string</span>&#123;<span class="string">&quot;127.0.0.1:26379&quot;</span>, <span class="string">&quot;127.0.0.1:26380&quot;</span>, <span class="string">&quot;127.0.0.1:26381&quot;</span>&#125;),</span><br><span class="line">		sentinel.PoolOpts(</span><br><span class="line">			mode.MaxActive(<span class="number">20</span>),       <span class="comment">// 最大连接数，默认0无限制</span></span><br><span class="line">			mode.MaxIdle(<span class="number">0</span>),         <span class="comment">// 最多保持空闲连接数，默认2*runtime.GOMAXPROCS(0)</span></span><br><span class="line">			mode.Wait(<span class="literal">false</span>),        <span class="comment">// 连接耗尽时是否等待，默认false</span></span><br><span class="line">			mode.IdleTimeout(<span class="number">0</span>),     <span class="comment">// 空闲连接超时时间，默认0不超时</span></span><br><span class="line">			mode.MaxConnLifetime(<span class="number">0</span>), <span class="comment">// 连接的生命周期，默认0不失效</span></span><br><span class="line">			mode.TestOnBorrow(<span class="literal">nil</span>),  <span class="comment">// 空间连接取出后检测是否健康，默认nil</span></span><br><span class="line">		),</span><br><span class="line">		sentinel.DialOpts(</span><br><span class="line">			redis.DialReadTimeout(time.Second),    <span class="comment">// 读取超时，默认time.Second</span></span><br><span class="line">			redis.DialWriteTimeout(time.Second),   <span class="comment">// 写入超时，默认time.Second</span></span><br><span class="line">			redis.DialConnectTimeout(time.Second), <span class="comment">// 连接超时，默认500*time.Millisecond</span></span><br><span class="line">			redis.DialPassword(<span class="string">&quot;&quot;</span>),                <span class="comment">// 鉴权密码，默认空</span></span><br><span class="line">			redis.DialDatabase(<span class="number">0</span>),                 <span class="comment">// 数据库号，默认0</span></span><br><span class="line">			redis.DialKeepAlive(time.Minute*<span class="number">5</span>),    <span class="comment">// 默认5*time.Minute</span></span><br><span class="line">			redis.DialNetDial(<span class="literal">nil</span>),                <span class="comment">// 自定义dial，默认nil</span></span><br><span class="line">			redis.DialUseTLS(<span class="literal">false</span>),               <span class="comment">// 是否用TLS，默认false</span></span><br><span class="line">			redis.DialTLSSkipVerify(<span class="literal">false</span>),        <span class="comment">// 服务器证书校验，默认false</span></span><br><span class="line">			redis.DialTLSConfig(<span class="literal">nil</span>),              <span class="comment">// 默认nil，详见tls.Config</span></span><br><span class="line">		),</span><br><span class="line">		<span class="comment">// 连接哨兵配置，用法于sentinel.DialOpts()一致</span></span><br><span class="line">		<span class="comment">// 默认未配置的情况则直接使用sentinel.DialOpts()的配置</span></span><br><span class="line">		<span class="comment">// sentinel.SentinelDialOpts()</span></span><br><span class="line">	)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">var</span> instance = redigo.New(sentinelMode)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span>  &#123;</span><br><span class="line">		res, err := instance.String(<span class="function"><span class="keyword">func</span><span class="params">(c redis.Conn)</span></span> (res <span class="keyword">interface</span>&#123;&#125;, err <span class="type">error</span>) &#123;</span><br><span class="line">			<span class="keyword">return</span> c.Do(<span class="string">&quot;set&quot;</span>, <span class="string">&quot;test&quot;</span> + strconv.Itoa(i), i)</span><br><span class="line">		&#125;)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Println(err)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			fmt.Println(res)</span><br><span class="line">		&#125;</span><br><span class="line">		i++</span><br><span class="line">		time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行以下命令，并模拟7000端口宕机</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go run client.go</span><br></pre></td></tr></table></figure><p><img src="/img/in-post/2019-01-19/16.png"></p><p>执行结果：</p><p><img src="/img/in-post/2019-01-19/14.png"><br><img src="/img/in-post/2019-01-19/15.png"></p><h2 id="日志分析"><a href="#日志分析" class="headerlink" title="日志分析"></a>日志分析</h2><p>查看7001.log</p><p><img src="/img/in-post/2019-01-19/17.png"></p><p>从日志中发现选举7002为master,执行<code>redis-cli -p 7002 info replication</code>验证下</p><p><img src="/img/in-post/2019-01-19/18.png"></p><p>看看sentinel日志的变化</p><p><img src="/img/in-post/2019-01-19/19.png"></p><h2 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h2><h3 id="三个定时任务"><a href="#三个定时任务" class="headerlink" title="三个定时任务"></a>三个定时任务</h3><ol><li>每10秒每个sentinel对master和slave执行info</li></ol><ul><li>发现slave节点</li><li>确定主从关系</li></ul><ol start="2"><li>每2秒每个sentinel通过master节点的channel节点交换信息(pub&#x2F;sub)</li></ol><ul><li>通过__sentinel__和:hello频道交互</li><li>交互对节点的看法和自身的信息</li></ul><ol start="3"><li>每1秒每个Sentinel对其它Sentinel和Redis执行ping</li></ol><ul><li>失败判定依据，心跳检测</li></ul><h3 id="主观下线和客观下线"><a href="#主观下线和客观下线" class="headerlink" title="主观下线和客观下线"></a>主观下线和客观下线</h3><ul><li>主观下线：每个sentinel节点对Redis节点失败的偏见</li><li>客观下线：所有sentinel节点对Redis节点失败达成共识（quorum:建议节点数&#x2F;2+1）</li></ul><h3 id="领导者选举"><a href="#领导者选举" class="headerlink" title="领导者选举"></a>领导者选举</h3><ul><li>原因：只有一个sentinel节点完成故障转移</li><li>选举：通过sentinel is-master-down-by-addr命令都希望成为领导者</li></ul><ol><li>每个主观下线的Sentinel节点向其他Sentinel节点发送命令，要求它设置为领导者</li><li>收到命令的Sentinel节点如果没有同意通过其他Sentinel节点发送的命令，那么该同意将被拒绝</li><li>如果该Sentinel节点发现通过的票数已经超过Sentinel集合半数且超过quorum，那么它将成为领导者</li><li>如果此过程中有多个Sentinel节点成为领导者，那么将等待一段时间重新选举</li></ol><h3 id="故障转移-1"><a href="#故障转移-1" class="headerlink" title="故障转移"></a>故障转移</h3><ol><li>从slave节点选出一个”合适的”节点作为新的master节点</li><li>对上面的slave节点执行<code>slaveof no one</code> 命令让其成为master节点</li><li>向剩余的slave节点发送命令，让他们成为新master节点的slave节点，复制规则和parallel-syncs参数有关</li><li>更新原来的master节点并配置为slave,并保持对其”关注”，当其恢复后，命令他去复制新的master节点</li></ol><h3 id="选择”合适的”slave节点"><a href="#选择”合适的”slave节点" class="headerlink" title="选择”合适的”slave节点"></a>选择”合适的”slave节点</h3><ol><li>选择slave-priority(slave节点优先级)最高的slave节点。如果存在则返回，不存在则继续</li><li>选择复制偏移量最大的slave节点(复制的最完整)如果存在则返回，不存在则继续</li><li>选择runid最小的slave节点</li></ol></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://enpsl.github.io/2019/10/25/2019-10-25-hexo-deploy/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="enpsl"><meta itemprop="description" content="my blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="彭诗亮的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> <a href="/2019/10/25/2019-10-25-hexo-deploy/" class="post-title-link" itemprop="url">hexo 部署小记</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-10-25 13:30:00" itemprop="dateCreated datePublished" datetime="2019-10-25T13:30:00+08:00">2019-10-25</time></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="hexo部署流程"><a href="#hexo部署流程" class="headerlink" title="hexo部署流程"></a>hexo部署流程</h2><ul><li>开启本地web服务:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure></li><li>生成静态文件:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure></li><li>文件压缩:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gulp</span><br></pre></td></tr></table></figure></li><li>文件部署到远程服务器:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure></li></ul><h2 id="gulp安装："><a href="#gulp安装：" class="headerlink" title="gulp安装："></a>gulp安装：</h2><h3 id="安装-gulp"><a href="#安装-gulp" class="headerlink" title="安装 gulp"></a>安装 gulp</h3><p>使用 npm install xxx –save命令分别安装如下工具</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;gulp&quot;</span>: <span class="string">&quot;^3.9.1&quot;</span>,</span><br><span class="line"><span class="string">&quot;gulp-htmlclean&quot;</span>: <span class="string">&quot;^2.7.6&quot;</span>,</span><br><span class="line"><span class="string">&quot;gulp-htmlmin&quot;</span>: <span class="string">&quot;^1.3.0&quot;</span>,</span><br><span class="line"><span class="string">&quot;gulp-imagemin&quot;</span>: <span class="string">&quot;^2.4.0&quot;</span>,</span><br><span class="line"><span class="string">&quot;gulp-minify-css&quot;</span>: <span class="string">&quot;^1.2.4&quot;</span>,</span><br><span class="line"><span class="string">&quot;gulp-uglify&quot;</span>: <span class="string">&quot;^1.5.3&quot;</span>,</span><br></pre></td></tr></table></figure><h3 id="建立-gulpfile-js-文件"><a href="#建立-gulpfile-js-文件" class="headerlink" title="建立 gulpfile.js 文件"></a>建立 gulpfile.js 文件</h3><p>在 Hexo 的根目录建立 gulpfile.js</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> gulp = <span class="built_in">require</span>(<span class="string">&#x27;gulp&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> minifycss = <span class="built_in">require</span>(<span class="string">&#x27;gulp-minify-css&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> uglify = <span class="built_in">require</span>(<span class="string">&#x27;gulp-uglify&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> htmlmin = <span class="built_in">require</span>(<span class="string">&#x27;gulp-htmlmin&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> htmlclean = <span class="built_in">require</span>(<span class="string">&#x27;gulp-htmlclean&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> imagemin = <span class="built_in">require</span>(<span class="string">&#x27;gulp-imagemin&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 压缩html</span></span><br><span class="line">gulp.<span class="title function_">task</span>(<span class="string">&#x27;minify-html&#x27;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.<span class="title function_">src</span>(<span class="string">&#x27;./public/**/*.html&#x27;</span>)</span><br><span class="line">        .<span class="title function_">pipe</span>(<span class="title function_">htmlclean</span>())</span><br><span class="line">        .<span class="title function_">pipe</span>(<span class="title function_">htmlmin</span>(&#123;</span><br><span class="line">            <span class="attr">removeComments</span>: <span class="literal">true</span>,</span><br><span class="line">            <span class="attr">minifyJS</span>: <span class="literal">true</span>,</span><br><span class="line">            <span class="attr">minifyCSS</span>: <span class="literal">true</span>,</span><br><span class="line">            <span class="attr">minifyURLs</span>: <span class="literal">true</span>,</span><br><span class="line">        &#125;))</span><br><span class="line">        .<span class="title function_">pipe</span>(gulp.<span class="title function_">dest</span>(<span class="string">&#x27;./public&#x27;</span>))</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 压缩css</span></span><br><span class="line">gulp.<span class="title function_">task</span>(<span class="string">&#x27;minify-css&#x27;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.<span class="title function_">src</span>(<span class="string">&#x27;./public/**/*.css&#x27;</span>)</span><br><span class="line">        .<span class="title function_">pipe</span>(<span class="title function_">minifycss</span>(&#123;</span><br><span class="line">            <span class="attr">compatibility</span>: <span class="string">&#x27;ie8&#x27;</span></span><br><span class="line">        &#125;))</span><br><span class="line">        .<span class="title function_">pipe</span>(gulp.<span class="title function_">dest</span>(<span class="string">&#x27;./public&#x27;</span>));</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 压缩js</span></span><br><span class="line">gulp.<span class="title function_">task</span>(<span class="string">&#x27;minify-js&#x27;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.<span class="title function_">src</span>(<span class="string">&#x27;./public/js/**/*.js&#x27;</span>)</span><br><span class="line">        .<span class="title function_">pipe</span>(<span class="title function_">uglify</span>())</span><br><span class="line">        .<span class="title function_">pipe</span>(gulp.<span class="title function_">dest</span>(<span class="string">&#x27;./public&#x27;</span>));</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 压缩图片</span></span><br><span class="line">gulp.<span class="title function_">task</span>(<span class="string">&#x27;minify-images&#x27;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.<span class="title function_">src</span>(<span class="string">&#x27;./public/images/**/*.*&#x27;</span>)</span><br><span class="line">        .<span class="title function_">pipe</span>(<span class="title function_">imagemin</span>(</span><br><span class="line">            [imagemin.<span class="title function_">gifsicle</span>(&#123;<span class="string">&#x27;optimizationLevel&#x27;</span>: <span class="number">3</span>&#125;),</span><br><span class="line">                imagemin.<span class="title function_">jpegtran</span>(&#123;<span class="string">&#x27;progressive&#x27;</span>: <span class="literal">true</span>&#125;),</span><br><span class="line">                imagemin.<span class="title function_">optipng</span>(&#123;<span class="string">&#x27;optimizationLevel&#x27;</span>: <span class="number">7</span>&#125;),</span><br><span class="line">                imagemin.<span class="title function_">svgo</span>()],</span><br><span class="line">            &#123;<span class="string">&#x27;verbose&#x27;</span>: <span class="literal">true</span>&#125;))</span><br><span class="line">        .<span class="title function_">pipe</span>(gulp.<span class="title function_">dest</span>(<span class="string">&#x27;./public/images&#x27;</span>))</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 默认任务</span></span><br><span class="line">gulp.<span class="title function_">task</span>(<span class="string">&#x27;default&#x27;</span>, [</span><br><span class="line">    <span class="string">&#x27;minify-html&#x27;</span>,<span class="string">&#x27;minify-css&#x27;</span>,<span class="string">&#x27;minify-js&#x27;</span>,<span class="string">&#x27;minify-images&#x27;</span></span><br><span class="line">]);</span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><nav class="pagination"><a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left" aria-label="上一页"></i></a> <a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span></nav></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">enpsl</p><div class="site-description" itemprop="description">my blog</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">50</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">标签</span></a></div></nav></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">enpsl</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script></body></html>